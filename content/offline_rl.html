<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.6.40">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="dcterms.date" content="2025-02-10">

<title>Trajectory Transformer (TT) from code – blog</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==" crossorigin="anonymous"></script><script src="../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../site_libs/clipboard/clipboard.min.js"></script>
<script src="../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../site_libs/quarto-search/fuse.min.js"></script>
<script src="../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../">
<script src="../site_libs/quarto-html/quarto.js"></script>
<script src="../site_libs/quarto-html/popper.min.js"></script>
<script src="../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../site_libs/quarto-html/anchor.min.js"></script>
<link href="../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting-dark-f8dc6eab18fde03278982b0b35885446.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../site_libs/bootstrap/bootstrap-31203b635be0d1e0e0f8e50f4e183f41.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="dark">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<script async="" src="https://www.googletagmanager.com/gtag/js?id=G-8WZNC2WP40"></script>

<script type="text/javascript">

window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'G-8WZNC2WP40', { 'anonymize_ip': true});
</script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" integrity="sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==" crossorigin="anonymous"></script>

<script type="application/javascript">define('jquery', [],function() {return window.jQuery;})</script>
<script src="https://unpkg.com/@jupyter-widgets/html-manager@*/dist/embed-amd.js" crossorigin="anonymous"></script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

<link rel="stylesheet" href="../styles.css">
</head>

<body class="nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a class="navbar-brand" href="../index.html">
    <span class="navbar-title">blog</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" role="menu" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item">
    <a class="nav-link" href="../index.html"> 
<span class="menu-text">Home</span></a>
  </li>  
</ul>
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item">
    <a class="nav-link" href="https://github.com/abrarsheikh"> 
<span class="menu-text">Github</span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
            <div class="quarto-navbar-tools">
</div>
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#introduction" id="toc-introduction" class="nav-link active" data-scroll-target="#introduction"><span class="header-section-number">1</span> Introduction</a>
  <ul class="collapse">
  <li><a href="#overview-of-offline-rl-and-its-differences-from-traditional-rl" id="toc-overview-of-offline-rl-and-its-differences-from-traditional-rl" class="nav-link" data-scroll-target="#overview-of-offline-rl-and-its-differences-from-traditional-rl"><span class="header-section-number">1.1</span> Overview of Offline RL and Its Differences from Traditional RL</a></li>
  </ul></li>
  <li><a href="#introduction-to-gymnasium-and-minari" id="toc-introduction-to-gymnasium-and-minari" class="nav-link" data-scroll-target="#introduction-to-gymnasium-and-minari"><span class="header-section-number">2</span> Introduction to Gymnasium and Minari</a>
  <ul class="collapse">
  <li><a href="#gymnasium-a-standard-for-rl-environments" id="toc-gymnasium-a-standard-for-rl-environments" class="nav-link" data-scroll-target="#gymnasium-a-standard-for-rl-environments"><span class="header-section-number">2.1</span> Gymnasium: A Standard for RL Environments</a></li>
  <li><a href="#minari-standardized-datasets-for-offline-rl" id="toc-minari-standardized-datasets-for-offline-rl" class="nav-link" data-scroll-target="#minari-standardized-datasets-for-offline-rl"><span class="header-section-number">2.2</span> Minari: Standardized Datasets for Offline RL</a></li>
  <li><a href="#bringing-it-all-together-gymnasium-minari-in-offline-rl" id="toc-bringing-it-all-together-gymnasium-minari-in-offline-rl" class="nav-link" data-scroll-target="#bringing-it-all-together-gymnasium-minari-in-offline-rl"><span class="header-section-number">2.3</span> Bringing It All Together: Gymnasium + Minari in Offline RL</a></li>
  </ul></li>
  <li><a href="#loading-data" id="toc-loading-data" class="nav-link" data-scroll-target="#loading-data"><span class="header-section-number">3</span> Loading Data</a></li>
  <li><a href="#key-terminology" id="toc-key-terminology" class="nav-link" data-scroll-target="#key-terminology"><span class="header-section-number">4</span> Key Terminology</a></li>
  <li><a href="#hyperparameters" id="toc-hyperparameters" class="nav-link" data-scroll-target="#hyperparameters"><span class="header-section-number">5</span> Hyperparameters</a></li>
  <li><a href="#discretizer" id="toc-discretizer" class="nav-link" data-scroll-target="#discretizer"><span class="header-section-number">6</span> Discretizer</a>
  <ul class="collapse">
  <li><a href="#what-is-discretization" id="toc-what-is-discretization" class="nav-link" data-scroll-target="#what-is-discretization"><span class="header-section-number">6.1</span> What is Discretization?</a></li>
  <li><a href="#why-is-discretization-needed-in-tt" id="toc-why-is-discretization-needed-in-tt" class="nav-link" data-scroll-target="#why-is-discretization-needed-in-tt"><span class="header-section-number">6.2</span> Why is Discretization Needed in TT?</a></li>
  <li><a href="#key-reasons-for-discretization-in-tt" id="toc-key-reasons-for-discretization-in-tt" class="nav-link" data-scroll-target="#key-reasons-for-discretization-in-tt"><span class="header-section-number">6.3</span> Key reasons for discretization in TT:</a></li>
  <li><a href="#how-does-discretization-work-in-tt" id="toc-how-does-discretization-work-in-tt" class="nav-link" data-scroll-target="#how-does-discretization-work-in-tt"><span class="header-section-number">6.4</span> How Does Discretization Work in TT?</a></li>
  <li><a href="#how-tt-uses-discretized-inputs" id="toc-how-tt-uses-discretized-inputs" class="nav-link" data-scroll-target="#how-tt-uses-discretized-inputs"><span class="header-section-number">6.5</span> How TT Uses Discretized Inputs</a></li>
  <li><a href="#bin-size-trade-offs" id="toc-bin-size-trade-offs" class="nav-link" data-scroll-target="#bin-size-trade-offs"><span class="header-section-number">6.6</span> Bin Size trade offs</a></li>
  </ul></li>
  <li><a href="#pytorch-dataset" id="toc-pytorch-dataset" class="nav-link" data-scroll-target="#pytorch-dataset"><span class="header-section-number">7</span> Pytorch Dataset</a>
  <ul class="collapse">
  <li><a href="#rewards-to-go-rtg" id="toc-rewards-to-go-rtg" class="nav-link" data-scroll-target="#rewards-to-go-rtg"><span class="header-section-number">7.1</span> Rewards-to-Go (RTG)</a></li>
  </ul></li>
  <li><a href="#model" id="toc-model" class="nav-link" data-scroll-target="#model"><span class="header-section-number">8</span> Model</a>
  <ul class="collapse">
  <li><a href="#tokenization-in-tt-why-and-how-offsetting-is-done" id="toc-tokenization-in-tt-why-and-how-offsetting-is-done" class="nav-link" data-scroll-target="#tokenization-in-tt-why-and-how-offsetting-is-done"><span class="header-section-number">8.1</span> Tokenization in TT: Why and How Offsetting is Done</a></li>
  <li><a href="#einlinear-einstein-notation-as-a-shorthand-for-mlp" id="toc-einlinear-einstein-notation-as-a-shorthand-for-mlp" class="nav-link" data-scroll-target="#einlinear-einstein-notation-as-a-shorthand-for-mlp"><span class="header-section-number">8.2</span> EinLinear: Einstein Notation as a Shorthand for MLP</a></li>
  <li><a href="#causal-masking-why-and-how" id="toc-causal-masking-why-and-how" class="nav-link" data-scroll-target="#causal-masking-why-and-how"><span class="header-section-number">8.3</span> Causal Masking: Why and How?</a></li>
  <li><a href="#kv-cache-why-and-how-it-works" id="toc-kv-cache-why-and-how-it-works" class="nav-link" data-scroll-target="#kv-cache-why-and-how-it-works"><span class="header-section-number">8.4</span> KV Cache: Why and How It Works</a></li>
  </ul></li>
  <li><a href="#sampling-techniques" id="toc-sampling-techniques" class="nav-link" data-scroll-target="#sampling-techniques"><span class="header-section-number">9</span> Sampling Techniques</a>
  <ul class="collapse">
  <li><a href="#greedy-sampling" id="toc-greedy-sampling" class="nav-link" data-scroll-target="#greedy-sampling"><span class="header-section-number">9.1</span> Greedy Sampling</a></li>
  <li><a href="#top-k-sampling" id="toc-top-k-sampling" class="nav-link" data-scroll-target="#top-k-sampling"><span class="header-section-number">9.2</span> Top-K Sampling</a></li>
  <li><a href="#temperature-scaling" id="toc-temperature-scaling" class="nav-link" data-scroll-target="#temperature-scaling"><span class="header-section-number">9.3</span> Temperature Scaling</a></li>
  </ul></li>
  <li><a href="#beam-search" id="toc-beam-search" class="nav-link" data-scroll-target="#beam-search"><span class="header-section-number">10</span> Beam Search</a>
  <ul class="collapse">
  <li><a href="#how-beam-search-works-in-tt" id="toc-how-beam-search-works-in-tt" class="nav-link" data-scroll-target="#how-beam-search-works-in-tt"><span class="header-section-number">10.1</span> How Beam Search Works in TT:</a></li>
  <li><a href="#understanding-stochasticity-in-beam-search" id="toc-understanding-stochasticity-in-beam-search" class="nav-link" data-scroll-target="#understanding-stochasticity-in-beam-search"><span class="header-section-number">10.2</span> Understanding Stochasticity in Beam Search</a></li>
  <li><a href="#beam-search-objectives-in-tt" id="toc-beam-search-objectives-in-tt" class="nav-link" data-scroll-target="#beam-search-objectives-in-tt"><span class="header-section-number">10.3</span> Beam Search Objectives in TT</a></li>
  </ul></li>
  <li><a href="#rollout" id="toc-rollout" class="nav-link" data-scroll-target="#rollout"><span class="header-section-number">11</span> Rollout</a>
  <ul class="collapse">
  <li><a href="#in-the-context-of-tt-rollouts-are-used-to" id="toc-in-the-context-of-tt-rollouts-are-used-to" class="nav-link" data-scroll-target="#in-the-context-of-tt-rollouts-are-used-to"><span class="header-section-number">11.1</span> In the context of TT, rollouts are used to:</a></li>
  <li><a href="#how-a-rollout-uses-the-policy-model-beam-search" id="toc-how-a-rollout-uses-the-policy-model-beam-search" class="nav-link" data-scroll-target="#how-a-rollout-uses-the-policy-model-beam-search"><span class="header-section-number">11.2</span> How a Rollout Uses the Policy Model &amp; Beam Search</a></li>
  <li><a href="#how-rollouts-enable-long-term-planning" id="toc-how-rollouts-enable-long-term-planning" class="nav-link" data-scroll-target="#how-rollouts-enable-long-term-planning"><span class="header-section-number">11.3</span> How Rollouts Enable Long-Term Planning</a></li>
  </ul></li>
  <li><a href="#model-training" id="toc-model-training" class="nav-link" data-scroll-target="#model-training"><span class="header-section-number">12</span> Model Training</a>
  <ul class="collapse">
  <li><a href="#loss-function-cross-entropy-loss-action-weighting-and-masking" id="toc-loss-function-cross-entropy-loss-action-weighting-and-masking" class="nav-link" data-scroll-target="#loss-function-cross-entropy-loss-action-weighting-and-masking"><span class="header-section-number">12.1</span> Loss Function: Cross-Entropy Loss, Action Weighting, and Masking</a></li>
  <li><a href="#vectorized-environments-in-gym-what-and-why" id="toc-vectorized-environments-in-gym-what-and-why" class="nav-link" data-scroll-target="#vectorized-environments-in-gym-what-and-why"><span class="header-section-number">12.2</span> Vectorized Environments in Gym: What and Why?</a></li>
  <li><a href="#learning-rate-scheduler-weight-decay-and-gradient-clipping" id="toc-learning-rate-scheduler-weight-decay-and-gradient-clipping" class="nav-link" data-scroll-target="#learning-rate-scheduler-weight-decay-and-gradient-clipping"><span class="header-section-number">12.3</span> Learning Rate Scheduler, Weight Decay, and Gradient Clipping</a></li>
  <li><a href="#predictive-accuracy-what-it-is-and-why-its-not-important-for-tt" id="toc-predictive-accuracy-what-it-is-and-why-its-not-important-for-tt" class="nav-link" data-scroll-target="#predictive-accuracy-what-it-is-and-why-its-not-important-for-tt"><span class="header-section-number">12.4</span> Predictive Accuracy: What It Is and Why It’s Not Important for TT</a></li>
  <li><a href="#evaluation-in-tt-key-metrics-purpose" id="toc-evaluation-in-tt-key-metrics-purpose" class="nav-link" data-scroll-target="#evaluation-in-tt-key-metrics-purpose"><span class="header-section-number">12.5</span> Evaluation in TT: Key Metrics &amp; Purpose</a></li>
  <li><a href="#hardware-training-details" id="toc-hardware-training-details" class="nav-link" data-scroll-target="#hardware-training-details"><span class="header-section-number">12.6</span> Hardware &amp; Training Details</a></li>
  </ul></li>
  <li><a href="#future-work" id="toc-future-work" class="nav-link" data-scroll-target="#future-work"><span class="header-section-number">13</span> <strong>Future Work</strong></a>
  <ul class="collapse">
  <li><a href="#expand-to-more-environments" id="toc-expand-to-more-environments" class="nav-link" data-scroll-target="#expand-to-more-environments"><span class="header-section-number">13.1</span> <strong>Expand to More Environments</strong></a></li>
  <li><a href="#speed-up-rollouts" id="toc-speed-up-rollouts" class="nav-link" data-scroll-target="#speed-up-rollouts"><span class="header-section-number">13.2</span> <strong>Speed Up Rollouts</strong></a></li>
  <li><a href="#improve-training-efficiency" id="toc-improve-training-efficiency" class="nav-link" data-scroll-target="#improve-training-efficiency"><span class="header-section-number">13.3</span> <strong>Improve Training Efficiency</strong></a></li>
  <li><a href="#enable-visualization" id="toc-enable-visualization" class="nav-link" data-scroll-target="#enable-visualization"><span class="header-section-number">13.4</span> <strong>Enable Visualization</strong></a></li>
  <li><a href="#benchmark-against-other-rl-methods" id="toc-benchmark-against-other-rl-methods" class="nav-link" data-scroll-target="#benchmark-against-other-rl-methods"><span class="header-section-number">13.5</span> <strong>Benchmark Against Other RL Methods</strong></a></li>
  <li><a href="#other-learning-techniques" id="toc-other-learning-techniques" class="nav-link" data-scroll-target="#other-learning-techniques"><span class="header-section-number">13.6</span> Other learning techniques</a></li>
  </ul></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">Trajectory Transformer (TT) from code</h1>
  <div class="quarto-categories">
    <div class="quarto-category">Machine Learning</div>
    <div class="quarto-category">Reinforcement Learning</div>
  </div>
  </div>



<div class="quarto-title-meta">

    
    <div>
    <div class="quarto-title-meta-heading">Published</div>
    <div class="quarto-title-meta-contents">
      <p class="date">February 10, 2025</p>
    </div>
  </div>
  
    
  </div>
  


</header>


<section id="introduction" class="level2" data-number="1">
<h2 data-number="1" class="anchored" data-anchor-id="introduction"><span class="header-section-number">1</span> Introduction</h2>
<p>In this notebook, we explore the <a href="https://arxiv.org/abs/2106.02039">Trajectory Transformer (TT)</a>, a sequence modeling approach to <a href="https://en.wikipedia.org/wiki/Reinforcement_learning">reinforcement learning (RL)</a> introduced in the paper <em>Offline RL as One Big Sequence Modeling Problem</em> by Janner et al.&nbsp;TT reframes RL as a sequence modeling task, leveraging <a href="https://en.wikipedia.org/wiki/Transformer_(machine_learning_model)">Transformer architectures</a> to model trajectories of states, actions, and rewards. By doing so, it unifies different aspects of RL—policy learning, value estimation, and model-based planning—under a single framework.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="img/offline_rl/tt.png" class="img-fluid figure-img"></p>
<figcaption>TT</figcaption>
</figure>
</div>
<p>This notebook provides a detailed walkthrough of TT, an offline RL model that formulates trajectory generation as a sequence modeling problem. The goal is to help readers understand TT’s inner workings, from data processing and model training to beam search-based rollouts and evaluation.</p>
<p>What to Expect in This Notebook?</p>
<ul>
<li><strong>Offline RL &amp; TT Basics</strong> – Overview of discretization, tokenization, and trajectory modeling.</li>
<li><strong>Training TT</strong> – Cross-entropy loss, weighted action importance, and optimization techniques (LR scheduling, weight decay, gradient clipping).</li>
<li><strong>Rollouts &amp; Beam Search</strong> – How TT predicts future trajectories, explores high-reward sequences, and enables long-term planning.</li>
<li><strong>Evaluation</strong> – Rollout-based metrics (mean reward, variance, done ratio) to assess trajectory quality, stability, and efficiency.</li>
</ul>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Why This Notebook?
</div>
</div>
<div class="callout-body-container callout-body">
<p>Much of the code in this notebook is inspired by the <a href="https://github.com/jannerm/trajectory-transformer">original TT implementation</a>, with significant updates and refinements. Additionally:</p>
<ul>
<li>The KV cache and vectorized rollouts are adapted from the <a href="https://github.com/Howuhh/faster-trajectory-transformer/tree/main">faster-trajectory-transformer</a> repository.</li>
<li>Both the original TT repo and faster-trajectory-transformer are non-functional due to:
<ul>
<li>D4RL being deprecated.</li>
<li>Use of outdated Gym versions.</li>
<li>Reliance on older MuJoCo versions that no longer run.</li>
</ul></li>
</ul>
<p>This notebook modernizes the implementation, ensuring it runs with current libraries, while providing a clearer, more accessible explanation of TT’s mechanics.</p>
</div>
</div>
<div class="callout callout-style-default callout-caution callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Caution
</div>
</div>
<div class="callout-body-container callout-body">
<p>This notebook does not introduce new concepts or bespoke code. Instead, it presents existing concepts and code in a more accessible manner for new machine learning engineers and scientists in this field.</p>
</div>
</div>
<div class="callout callout-style-default callout-warning callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Warning
</div>
</div>
<div class="callout-body-container callout-body">
<p>Some of the code cells in this notebook are collapsed by default for brevity.</p>
</div>
</div>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Tips for Following This Notebook
</div>
</div>
<div class="callout-body-container callout-body">
<ol type="1">
<li><p><strong>Take Your Time</strong>: This notebook is lengthy and cannot be completed in one sitting. Approach it slowly, and take breaks as needed to fully understand each section.</p></li>
<li><p><strong>Run the Notebook</strong>: To get the most out of this notebook, run it to train a model and reproduce the results. Try using different Gym environments to see what you observe and how the TT performs in various settings.</p></li>
<li><p><strong>Supplementary Resource</strong>: This document is not a replacement for the original paper. While it provides a detailed walkthrough of TT’s implementation and usage, it does not cover all the theoretical foundations and experimental results presented in the paper. Readers should refer to the original paper for a comprehensive understanding of the underlying concepts and the broader context of TT’s development.</p></li>
<li><p><strong>Understand the Code</strong>: Take the time to read and understand the code snippets provided. Each section builds on the previous one, so a solid understanding of the code will help you follow along more easily.</p></li>
<li><p><strong>Experiment and Modify</strong>: Don’t hesitate to experiment with the code. Modify parameters, try different environments, and observe how these changes affect the results. This hands-on approach will deepen your understanding of TT.</p></li>
<li><p><strong>Use Visualizations</strong>: Pay attention to the visualizations provided in the notebook. They can help you better understand the behavior of the model and the results of your experiments.</p></li>
</ol>
</div>
</div>
<section id="overview-of-offline-rl-and-its-differences-from-traditional-rl" class="level3" data-number="1.1">
<h3 data-number="1.1" class="anchored" data-anchor-id="overview-of-offline-rl-and-its-differences-from-traditional-rl"><span class="header-section-number">1.1</span> Overview of Offline RL and Its Differences from Traditional RL</h3>
<p>RL traditionally operates in an online setting, where an agent actively interacts with an environment, collecting data to learn an optimal policy. This approach, while effective, has several limitations:</p>
<ul>
<li><strong>Data inefficiency</strong>: Many RL algorithms require millions of interactions to learn good policies.</li>
<li><strong>Safety concerns</strong>: Direct exploration can be costly or dangerous in real-world applications like robotics, healthcare, and autonomous driving.</li>
<li><strong>Expensive data collection</strong>: Gathering high-quality data in real-world systems is often impractical.</li>
</ul>
<p><a href="https://bair.berkeley.edu/blog/2020/12/07/offline-rl/">Offline RL</a> (also known as batch RL) addresses these challenges by learning solely from a pre-collected dataset of past interactions, without any further environment interaction. The key differences between traditional RL and offline RL are:</p>
<table class="caption-top table">
<colgroup>
<col style="width: 17%">
<col style="width: 41%">
<col style="width: 41%">
</colgroup>
<thead>
<tr class="header">
<th>Feature</th>
<th>Traditional (Online) RL</th>
<th>Offline RL</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Data Collection</td>
<td>Agent interacts with the environment continuously</td>
<td>Fixed dataset with no new data collection</td>
</tr>
<tr class="even">
<td>Exploration</td>
<td>Active, the agent learns by trial and error</td>
<td>No exploration, learning is constrained by dataset</td>
</tr>
<tr class="odd">
<td>Safety</td>
<td>Can lead to unsafe exploration</td>
<td>No risk, as learning is purely from past data</td>
</tr>
<tr class="even">
<td>Practicality</td>
<td>Hard to apply in real-world settings</td>
<td>More feasible for real-world applications</td>
</tr>
</tbody>
</table>
<section id="why-do-we-need-offline-rl" class="level4" data-number="1.1.1">
<h4 data-number="1.1.1" class="anchored" data-anchor-id="why-do-we-need-offline-rl"><span class="header-section-number">1.1.1</span> Why Do We Need Offline RL?</h4>
<p>Offline RL is crucial for scenarios where active exploration is either unsafe or expensive. Some examples include:</p>
<p><em>“Imagine trying to train a self-driving car without ever letting it touch the road. Instead of real-world driving, you have to learn everything from past recorded trips—navigating intersections, avoiding pedestrians, and handling bad weather—all from historical data. Sounds impossible? This is exactly the challenge that Offline RL aims to solve.”</em></p>
<p>TT takes this a step further, leveraging the same Transformer architecture that powers language models like GPT to model sequences of actions, states, and rewards—treating RL as a prediction problem rather than a trial-and-error game.</p>
<p>Despite its benefits, offline RL faces unique challenges:</p>
<ul>
<li><strong>Out-of-Distribution (OOD) Actions</strong>: Since the agent cannot explore, it might learn to make decisions outside the dataset distribution, leading to extrapolation errors.</li>
<li><strong>Limited Coverage</strong>: If the dataset does not contain enough diverse experiences, the learned policy may not generalize well.</li>
</ul>
</section>
<section id="motivating-the-need-for-the-tt" class="level4" data-number="1.1.2">
<h4 data-number="1.1.2" class="anchored" data-anchor-id="motivating-the-need-for-the-tt"><span class="header-section-number">1.1.2</span> Motivating the Need for the TT</h4>
<p>The TT offers a novel approach to offline RL by treating RL as a sequence modeling problem, inspired by successes in <a href="https://en.wikipedia.org/wiki/Natural_language_processing">natural language processing (NLP)</a>. Instead of relying on traditional RL components like <a href="https://en.wikipedia.org/wiki/Q-learning">Q-learning</a> or <a href="https://spinningup.openai.com/en/latest/spinningup/rl_intro3.html">policy optimization</a>, TT models full trajectories as sequences and generates optimal action sequences through <a href="https://en.wikipedia.org/wiki/Beam_search">beam search planning</a>.</p>
</section>
<section id="advantages-of-tt-in-offline-rl" class="level4" data-number="1.1.3">
<h4 data-number="1.1.3" class="anchored" data-anchor-id="advantages-of-tt-in-offline-rl"><span class="header-section-number">1.1.3</span> Advantages of TT in Offline RL</h4>
<ul>
<li><strong>Handles long-horizon dependencies</strong>: Unlike traditional RL models that rely on stepwise decisions, TT captures entire sequences of states, actions, and rewards.</li>
<li><strong>Avoids OOD actions</strong>: Since TT directly models trajectories from data, it naturally generates in-distribution actions, reducing extrapolation errors.</li>
<li><strong>Unifies multiple RL approaches</strong>: TT can be used for imitation learning, goal-conditioned RL, and offline RL under a single framework.</li>
</ul>
<p>By leveraging sequence modeling, TT sidesteps many challenges of conventional offline RL, offering a more scalable and flexible alternative to existing methods.</p>
<p>Unlike traditional RL models that interact with the environment, TT reframes RL as a sequence modeling problem, treating trajectories as text-like sequences—similar to how GPT-4 generates coherent text.</p>
<div id="cell-3" class="cell" data-execution_count="1">
<details class="code-fold">
<summary>Imports for the project</summary>
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1"></a><span class="im">import</span> torch</span>
<span id="cb1-2"><a href="#cb1-2"></a><span class="im">import</span> torch.nn <span class="im">as</span> nn</span>
<span id="cb1-3"><a href="#cb1-3"></a><span class="im">import</span> torch.optim <span class="im">as</span> optim</span>
<span id="cb1-4"><a href="#cb1-4"></a><span class="im">from</span> typing <span class="im">import</span> Any</span>
<span id="cb1-5"><a href="#cb1-5"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb1-6"><a href="#cb1-6"></a><span class="im">import</span> gymnasium <span class="im">as</span> gym</span>
<span id="cb1-7"><a href="#cb1-7"></a><span class="im">from</span> gymnasium <span class="im">import</span> spaces</span>
<span id="cb1-8"><a href="#cb1-8"></a><span class="im">from</span> typing <span class="im">import</span> List</span>
<span id="cb1-9"><a href="#cb1-9"></a><span class="im">import</span> torch.nn.functional <span class="im">as</span> F</span>
<span id="cb1-10"><a href="#cb1-10"></a><span class="im">from</span> typing <span class="im">import</span> Tuple, Any</span>
<span id="cb1-11"><a href="#cb1-11"></a><span class="im">from</span> torch.utils.tensorboard <span class="im">import</span> SummaryWriter</span>
<span id="cb1-12"><a href="#cb1-12"></a><span class="im">from</span> torch.utils.data <span class="im">import</span> DataLoader, Dataset, Subset, SubsetRandomSampler</span>
<span id="cb1-13"><a href="#cb1-13"></a><span class="im">from</span> typing <span class="im">import</span> Optional</span>
<span id="cb1-14"><a href="#cb1-14"></a><span class="im">from</span> tqdm.auto <span class="im">import</span> tqdm, trange</span>
<span id="cb1-15"><a href="#cb1-15"></a><span class="im">from</span> minari <span class="im">import</span> EpisodeData, MinariDataset</span>
<span id="cb1-16"><a href="#cb1-16"></a><span class="im">import</span> minari</span>
<span id="cb1-17"><a href="#cb1-17"></a><span class="im">from</span> gymnasium <span class="im">import</span> Env</span>
<span id="cb1-18"><a href="#cb1-18"></a><span class="im">import</span> os</span>
<span id="cb1-19"><a href="#cb1-19"></a><span class="im">import</span> time</span>
<span id="cb1-20"><a href="#cb1-20"></a><span class="im">from</span> stable_baselines3.common.vec_env <span class="im">import</span> DummyVecEnv</span>
<span id="cb1-21"><a href="#cb1-21"></a><span class="im">import</span> math</span>
<span id="cb1-22"><a href="#cb1-22"></a><span class="im">import</span> warnings</span>
<span id="cb1-23"><a href="#cb1-23"></a><span class="im">import</span> pickle</span>
<span id="cb1-24"><a href="#cb1-24"></a><span class="im">import</span> random</span>
<span id="cb1-25"><a href="#cb1-25"></a><span class="im">import</span> glob</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: Gym version v0.24.1 has a number of critical issues with `gym.make` such that environment observation and action spaces are incorrectly evaluated, raising incorrect errors and warning . It is recommend to downgrading to v0.23.1 or upgrading to v0.25.1</code></pre>
</div>
</div>
<div class="callout callout-style-default callout-important callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Important
</div>
</div>
<div class="callout-body-container callout-body">
<p>If you are running this notebook on a CUDA-enabled machine, it will use the entire dataset for training and regular parameters. On non-CUDA machines, the notebook heavily subsamples the dataset and adjusts hyperparameters to ensure it can run on local development machines with lower performance. This behavior is controlled using the <code>local</code> variable, which you can override as needed.</p>
</div>
</div>
<div id="cell-5" class="cell">
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1"></a><span class="co"># local variable is used to run the code faster on local machine</span></span>
<span id="cb3-2"><a href="#cb3-2"></a>local <span class="op">=</span> <span class="kw">not</span> torch.cuda.is_available()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="cell-6" class="cell">
<details class="code-fold">
<summary>Seed everything for reproducibility</summary>
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1"></a>seed <span class="op">=</span> <span class="dv">42</span></span>
<span id="cb4-2"><a href="#cb4-2"></a>os.environ[<span class="st">"PYTHONHASHSEED"</span>] <span class="op">=</span> <span class="bu">str</span>(seed)</span>
<span id="cb4-3"><a href="#cb4-3"></a>np.random.seed(seed)</span>
<span id="cb4-4"><a href="#cb4-4"></a>random.seed(seed)</span>
<span id="cb4-5"><a href="#cb4-5"></a>torch.manual_seed(seed)</span>
<span id="cb4-6"><a href="#cb4-6"></a></span>
<span id="cb4-7"><a href="#cb4-7"></a>device <span class="op">=</span> torch.device(</span>
<span id="cb4-8"><a href="#cb4-8"></a>    <span class="st">"mps"</span></span>
<span id="cb4-9"><a href="#cb4-9"></a>    <span class="cf">if</span> torch.backends.mps.is_available()</span>
<span id="cb4-10"><a href="#cb4-10"></a>    <span class="cf">else</span> <span class="st">"cuda"</span> <span class="cf">if</span> torch.cuda.is_available() <span class="cf">else</span> <span class="st">"cpu"</span></span>
<span id="cb4-11"><a href="#cb4-11"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
</section>
</section>
</section>
<section id="introduction-to-gymnasium-and-minari" class="level2" data-number="2">
<h2 data-number="2" class="anchored" data-anchor-id="introduction-to-gymnasium-and-minari"><span class="header-section-number">2</span> Introduction to Gymnasium and Minari</h2>
<p>In this project, we use <a href="https://gymnasium.farama.org/">Gymnasium</a> for environments and <a href="https://minari.farama.org/">Minari</a> for datasets, two essential libraries in RL. If you’re new to RL, understanding these libraries will help you get started with training and evaluating RL models efficiently. If you are already familiar with these libraries feel free to skip this section.</p>
<section id="gymnasium-a-standard-for-rl-environments" class="level3" data-number="2.1">
<h3 data-number="2.1" class="anchored" data-anchor-id="gymnasium-a-standard-for-rl-environments"><span class="header-section-number">2.1</span> Gymnasium: A Standard for RL Environments</h3>
<section id="what-is-gymnasium" class="level4" data-number="2.1.1">
<h4 data-number="2.1.1" class="anchored" data-anchor-id="what-is-gymnasium"><span class="header-section-number">2.1.1</span> What is Gymnasium?</h4>
<p><a href="https://gymnasium.farama.org/">Gymnasium</a> (formerly OpenAI Gym) is a widely used library for simulating RL environments. It provides a standardized interface to interact with different RL tasks, making it easy to test and compare different RL algorithms.</p>
</section>
<section id="key-concepts-in-gymnasium" class="level4" data-number="2.1.2">
<h4 data-number="2.1.2" class="anchored" data-anchor-id="key-concepts-in-gymnasium"><span class="header-section-number">2.1.2</span> Key Concepts in Gymnasium</h4>
<p><strong>Environments:</strong></p>
<ul>
<li>An environment represents a problem setting where an agent interacts and learns.</li>
<li>Examples include robotic control (Mujoco), video games (Atari), and navigation tasks (GridWorld).</li>
</ul>
<p><strong>Agent-Environment Loop:</strong></p>
<ul>
<li>RL involves an agent taking actions in an environment, receiving rewards, and transitioning to new states.</li>
<li>Gymnasium provides the standard <code>step()</code> function to execute this interaction.</li>
</ul>
<p><strong>Gymnasium API:</strong></p>
<ul>
<li><code>env = gymnasium.make("CartPole-v1")</code> → Creates an environment.</li>
<li><code>obs, reward, done, truncated, info = env.step(action)</code> → Takes an action and returns the next observation, reward, and status flags.</li>
<li><code>env.reset()</code> → Resets the environment to its initial state.</li>
</ul>
<p><strong>Observation and Action Spaces:</strong></p>
<ul>
<li><code>env.observation_space</code>: Defines what states look like (e.g., position, velocity).</li>
<li><code>env.action_space</code>: Defines valid actions an agent can take.</li>
</ul>
<p><strong>Rendering:</strong></p>
<p><code>env.render()</code> can visualize the environment (useful for debugging and understanding agent behavior).</p>
<p>Gymnasium helps us simulate real-world scenarios, allowing RL models to learn efficiently in controlled settings.</p>
</section>
</section>
<section id="minari-standardized-datasets-for-offline-rl" class="level3" data-number="2.2">
<h3 data-number="2.2" class="anchored" data-anchor-id="minari-standardized-datasets-for-offline-rl"><span class="header-section-number">2.2</span> Minari: Standardized Datasets for Offline RL</h3>
<section id="what-is-minari" class="level4" data-number="2.2.1">
<h4 data-number="2.2.1" class="anchored" data-anchor-id="what-is-minari"><span class="header-section-number">2.2.1</span> What is Minari?</h4>
<p><a href="https://minari.farama.org">Minari</a> is a dataset library designed for offline RL, where agents learn solely from pre-collected experience datasets instead of interacting with the environment in real time. It provides high-quality, standardized datasets for different RL tasks.</p>
</section>
<section id="why-use-minari" class="level4" data-number="2.2.2">
<h4 data-number="2.2.2" class="anchored" data-anchor-id="why-use-minari"><span class="header-section-number">2.2.2</span> Why Use Minari?</h4>
<p>In offline RL, training directly in Gymnasium is not feasible because the agent cannot collect new data. Instead, Minari offers:</p>
<ul>
<li>Curated datasets with state-action-reward trajectories from past interactions.</li>
<li>Reproducibility, ensuring fair comparisons across different RL methods.</li>
<li>Seamless integration with Gymnasium, so datasets match Gym environments.</li>
</ul>
</section>
<section id="key-concepts-in-minari" class="level4" data-number="2.2.3">
<h4 data-number="2.2.3" class="anchored" data-anchor-id="key-concepts-in-minari"><span class="header-section-number">2.2.3</span> Key Concepts in Minari</h4>
<p><strong>Datasets in Offline RL:</strong></p>
<ul>
<li>Each dataset contains <strong>trajectories</strong> (sequences of (state, action, reward, next_state)).</li>
<li>These are generated using pre-trained policies (expert, medium, or random behavior).</li>
</ul>
<p><strong>Loading a Minari Dataset:</strong></p>
<div class="sourceCode" id="cb5"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1"></a><span class="im">import</span> minari</span>
<span id="cb5-2"><a href="#cb5-2"></a></span>
<span id="cb5-3"><a href="#cb5-3"></a>dataset <span class="op">=</span> minari.load_dataset(<span class="st">"halfcheetah-expert-v2"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p><strong>Using Minari for Training:</strong></p>
<p>Instead of interacting with the environment (<code>env.step()</code>), the agent learns by sampling from the dataset. This is similar to supervised learning, where the agent trains on past experiences rather than live exploration.</p>
</section>
</section>
<section id="bringing-it-all-together-gymnasium-minari-in-offline-rl" class="level3" data-number="2.3">
<h3 data-number="2.3" class="anchored" data-anchor-id="bringing-it-all-together-gymnasium-minari-in-offline-rl"><span class="header-section-number">2.3</span> Bringing It All Together: Gymnasium + Minari in Offline RL</h3>
<ul>
<li>Gymnasium provides a standard interface for RL environments (but in offline RL, the agent doesn’t interact with it).
<ul>
<li>In out project we will use Gymnasium interface to interact with the environment during beam search.</li>
</ul></li>
<li>Minari provides pre-recorded experience datasets, allowing the agent to learn without exploration.</li>
<li>Our project trains a TT model using Minari datasets to understand and optimize decision-making without direct environment interaction.</li>
</ul>
</section>
</section>
<section id="loading-data" class="level2" data-number="3">
<h2 data-number="3" class="anchored" data-anchor-id="loading-data"><span class="header-section-number">3</span> Loading Data</h2>
<p>In this implementation, I initialize the environment and fetch the dataset from Minari. We’ll use the <a href="https://gymnasium.farama.org/environments/mujoco/half_cheetah/">HalfCheetah Gym environment</a> and its corresponding <a href="https://minari.farama.org/main/datasets/mujoco/halfcheetah/expert-v0/">datasets from Minari</a> to demonstrate TT. Some Gym environments use dictionaries to represent observation and action spaces, but neural networks work with ndarrays. To address this, I’ve implemented helper functions to convert observations and actions between dictionaries and flat arrays. The notebook is designed to work with any Gym environment, not just HalfCheetah, so the implementation is more flexible and a bit more complex as a result.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="img/offline_rl/half_cheetah.gif" class="img-fluid figure-img"></p>
<figcaption>half_cheetah</figcaption>
</figure>
</div>
<div id="cell-9" class="cell" data-execution_count="3">
<details class="code-fold">
<summary>Define environment related utilities</summary>
<div class="sourceCode cell-code" id="cb6"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1"></a><span class="kw">def</span> get_space_dim(space):</span>
<span id="cb6-2"><a href="#cb6-2"></a>    <span class="cf">if</span> <span class="bu">isinstance</span>(space, spaces.Discrete):</span>
<span id="cb6-3"><a href="#cb6-3"></a>        <span class="cf">return</span> <span class="dv">1</span></span>
<span id="cb6-4"><a href="#cb6-4"></a>    <span class="cf">elif</span> <span class="bu">isinstance</span>(space, spaces.Box):</span>
<span id="cb6-5"><a href="#cb6-5"></a>        <span class="cf">return</span> space.shape[<span class="dv">0</span>]</span>
<span id="cb6-6"><a href="#cb6-6"></a>    <span class="cf">elif</span> <span class="bu">isinstance</span>(space, spaces.Dict):</span>
<span id="cb6-7"><a href="#cb6-7"></a>        <span class="cf">return</span> <span class="bu">sum</span>([get_space_dim(v) <span class="cf">for</span> v <span class="kw">in</span> space.values()])</span>
<span id="cb6-8"><a href="#cb6-8"></a>    <span class="cf">else</span>:</span>
<span id="cb6-9"><a href="#cb6-9"></a>        <span class="cf">raise</span> <span class="pp">ValueError</span>(<span class="st">"Unsupported observation space"</span>)</span>
<span id="cb6-10"><a href="#cb6-10"></a></span>
<span id="cb6-11"><a href="#cb6-11"></a></span>
<span id="cb6-12"><a href="#cb6-12"></a><span class="kw">def</span> flatten_space(s_dict: Any, space: spaces.Space) <span class="op">-&gt;</span> np.ndarray:</span>
<span id="cb6-13"><a href="#cb6-13"></a>    <span class="cf">if</span> <span class="bu">isinstance</span>(space, spaces.Discrete):</span>
<span id="cb6-14"><a href="#cb6-14"></a>        <span class="cf">return</span> s_dict</span>
<span id="cb6-15"><a href="#cb6-15"></a>    <span class="cf">elif</span> <span class="bu">isinstance</span>(space, spaces.Box):</span>
<span id="cb6-16"><a href="#cb6-16"></a>        <span class="cf">return</span> s_dict</span>
<span id="cb6-17"><a href="#cb6-17"></a>    <span class="cf">elif</span> <span class="bu">isinstance</span>(space, spaces.Dict):</span>
<span id="cb6-18"><a href="#cb6-18"></a>        <span class="cf">return</span> np.concatenate(</span>
<span id="cb6-19"><a href="#cb6-19"></a>            [flatten_space(s_dict[k], space.spaces[k]) <span class="cf">for</span> k <span class="kw">in</span> space.spaces.keys()],</span>
<span id="cb6-20"><a href="#cb6-20"></a>            axis<span class="op">=-</span><span class="dv">1</span>,</span>
<span id="cb6-21"><a href="#cb6-21"></a>        )</span>
<span id="cb6-22"><a href="#cb6-22"></a>    <span class="cf">else</span>:</span>
<span id="cb6-23"><a href="#cb6-23"></a>        <span class="cf">raise</span> <span class="pp">ValueError</span>(<span class="st">"Unsupported observation space"</span>)</span>
<span id="cb6-24"><a href="#cb6-24"></a></span>
<span id="cb6-25"><a href="#cb6-25"></a></span>
<span id="cb6-26"><a href="#cb6-26"></a><span class="kw">def</span> unflatten_space(s_flat: np.ndarray, space: spaces.Space) <span class="op">-&gt;</span> <span class="bu">dict</span>:</span>
<span id="cb6-27"><a href="#cb6-27"></a>    <span class="cf">if</span> <span class="bu">isinstance</span>(space, spaces.Discrete):</span>
<span id="cb6-28"><a href="#cb6-28"></a>        <span class="cf">return</span> s_flat</span>
<span id="cb6-29"><a href="#cb6-29"></a>    <span class="cf">elif</span> <span class="bu">isinstance</span>(space, spaces.Box):</span>
<span id="cb6-30"><a href="#cb6-30"></a>        <span class="cf">return</span> s_flat</span>
<span id="cb6-31"><a href="#cb6-31"></a>    <span class="cf">elif</span> <span class="bu">isinstance</span>(space, spaces.Dict):</span>
<span id="cb6-32"><a href="#cb6-32"></a>        s_dict <span class="op">=</span> {}</span>
<span id="cb6-33"><a href="#cb6-33"></a>        start <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb6-34"><a href="#cb6-34"></a>        <span class="cf">for</span> k, v <span class="kw">in</span> space.spaces.items():</span>
<span id="cb6-35"><a href="#cb6-35"></a>            end <span class="op">=</span> start <span class="op">+</span> get_space_dim(v)</span>
<span id="cb6-36"><a href="#cb6-36"></a>            s_dict[k] <span class="op">=</span> unflatten_space(s_flat[:, start:end], v)</span>
<span id="cb6-37"><a href="#cb6-37"></a>            start <span class="op">=</span> end</span>
<span id="cb6-38"><a href="#cb6-38"></a>        <span class="cf">return</span> s_dict</span>
<span id="cb6-39"><a href="#cb6-39"></a>    <span class="cf">else</span>:</span>
<span id="cb6-40"><a href="#cb6-40"></a>        <span class="cf">raise</span> <span class="pp">ValueError</span>(<span class="st">"Unsupported observation space"</span>)</span>
<span id="cb6-41"><a href="#cb6-41"></a></span>
<span id="cb6-42"><a href="#cb6-42"></a></span>
<span id="cb6-43"><a href="#cb6-43"></a><span class="co"># Test the flatten_space_dict and unflatten_space_dict functions</span></span>
<span id="cb6-44"><a href="#cb6-44"></a>test_dict <span class="op">=</span> {<span class="st">"obs"</span>: np.array([[<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">3</span>], [<span class="dv">4</span>, <span class="dv">5</span>, <span class="dv">6</span>]]), <span class="st">"act"</span>: np.array([[<span class="dv">0</span>], [<span class="dv">1</span>]])}</span>
<span id="cb6-45"><a href="#cb6-45"></a>test_space <span class="op">=</span> spaces.Dict(</span>
<span id="cb6-46"><a href="#cb6-46"></a>    {<span class="st">"obs"</span>: spaces.Box(low<span class="op">=</span><span class="dv">0</span>, high<span class="op">=</span><span class="dv">10</span>, shape<span class="op">=</span>(<span class="dv">3</span>,)), <span class="st">"act"</span>: spaces.Discrete(<span class="dv">2</span>)}</span>
<span id="cb6-47"><a href="#cb6-47"></a>)</span>
<span id="cb6-48"><a href="#cb6-48"></a>test_flat <span class="op">=</span> flatten_space(test_dict, test_space)</span>
<span id="cb6-49"><a href="#cb6-49"></a>test_unflat <span class="op">=</span> unflatten_space(test_flat, test_space)</span>
<span id="cb6-50"><a href="#cb6-50"></a></span>
<span id="cb6-51"><a href="#cb6-51"></a><span class="cf">assert</span> np.isclose(</span>
<span id="cb6-52"><a href="#cb6-52"></a>    test_flat, np.array([[<span class="dv">0</span>, <span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">3</span>], [<span class="dv">1</span>, <span class="dv">4</span>, <span class="dv">5</span>, <span class="dv">6</span>]])</span>
<span id="cb6-53"><a href="#cb6-53"></a>).<span class="bu">all</span>(), <span class="ss">f"Flattened array </span><span class="sc">{</span>test_flat<span class="sc">}</span><span class="ss"> is not as expected."</span></span>
<span id="cb6-54"><a href="#cb6-54"></a><span class="cf">assert</span> np.isclose(</span>
<span id="cb6-55"><a href="#cb6-55"></a>    test_unflat[<span class="st">"obs"</span>], test_dict[<span class="st">"obs"</span>]</span>
<span id="cb6-56"><a href="#cb6-56"></a>).<span class="bu">all</span>(), <span class="ss">f"Unflattened observation </span><span class="sc">{</span>test_unflat[<span class="st">'obs'</span>]<span class="sc">}</span><span class="ss"> is not as expected."</span></span>
<span id="cb6-57"><a href="#cb6-57"></a><span class="cf">assert</span> np.isclose(</span>
<span id="cb6-58"><a href="#cb6-58"></a>    test_unflat[<span class="st">"act"</span>], test_dict[<span class="st">"act"</span>]</span>
<span id="cb6-59"><a href="#cb6-59"></a>).<span class="bu">all</span>(), <span class="ss">f"Unflattened action </span><span class="sc">{</span>test_unflat[<span class="st">'act'</span>]<span class="sc">}</span><span class="ss"> is not as expected."</span></span>
<span id="cb6-60"><a href="#cb6-60"></a></span>
<span id="cb6-61"><a href="#cb6-61"></a><span class="co"># test discrete space</span></span>
<span id="cb6-62"><a href="#cb6-62"></a>test_dict <span class="op">=</span> np.array([[<span class="dv">0</span>], [<span class="dv">1</span>]])</span>
<span id="cb6-63"><a href="#cb6-63"></a>test_space <span class="op">=</span> spaces.Discrete(<span class="dv">2</span>)</span>
<span id="cb6-64"><a href="#cb6-64"></a>test_flat <span class="op">=</span> flatten_space(test_dict, test_space)</span>
<span id="cb6-65"><a href="#cb6-65"></a>test_unflat <span class="op">=</span> unflatten_space(test_flat, test_space)</span>
<span id="cb6-66"><a href="#cb6-66"></a></span>
<span id="cb6-67"><a href="#cb6-67"></a><span class="cf">assert</span> np.isclose(</span>
<span id="cb6-68"><a href="#cb6-68"></a>    test_flat, test_dict</span>
<span id="cb6-69"><a href="#cb6-69"></a>).<span class="bu">all</span>(), <span class="ss">f"Flattened array </span><span class="sc">{</span>test_flat<span class="sc">}</span><span class="ss"> is not as expected."</span></span>
<span id="cb6-70"><a href="#cb6-70"></a><span class="cf">assert</span> np.isclose(</span>
<span id="cb6-71"><a href="#cb6-71"></a>    test_unflat, test_dict</span>
<span id="cb6-72"><a href="#cb6-72"></a>).<span class="bu">all</span>(), <span class="ss">f"Unflattened array </span><span class="sc">{</span>test_unflat<span class="sc">}</span><span class="ss"> is not as expected."</span></span>
<span id="cb6-73"><a href="#cb6-73"></a></span>
<span id="cb6-74"><a href="#cb6-74"></a><span class="co"># test box space</span></span>
<span id="cb6-75"><a href="#cb6-75"></a>test_dict <span class="op">=</span> np.array([[<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">3</span>], [<span class="dv">4</span>, <span class="dv">5</span>, <span class="dv">6</span>]])</span>
<span id="cb6-76"><a href="#cb6-76"></a>test_space <span class="op">=</span> spaces.Box(low<span class="op">=</span><span class="dv">0</span>, high<span class="op">=</span><span class="dv">10</span>, shape<span class="op">=</span>(<span class="dv">3</span>,))</span>
<span id="cb6-77"><a href="#cb6-77"></a>test_flat <span class="op">=</span> flatten_space(test_dict, test_space)</span>
<span id="cb6-78"><a href="#cb6-78"></a>test_unflat <span class="op">=</span> unflatten_space(test_flat, test_space)</span>
<span id="cb6-79"><a href="#cb6-79"></a></span>
<span id="cb6-80"><a href="#cb6-80"></a><span class="cf">assert</span> np.isclose(</span>
<span id="cb6-81"><a href="#cb6-81"></a>    test_flat, test_dict</span>
<span id="cb6-82"><a href="#cb6-82"></a>).<span class="bu">all</span>(), <span class="ss">f"Flattened array </span><span class="sc">{</span>test_flat<span class="sc">}</span><span class="ss"> is not as expected."</span></span>
<span id="cb6-83"><a href="#cb6-83"></a><span class="cf">assert</span> np.isclose(</span>
<span id="cb6-84"><a href="#cb6-84"></a>    test_unflat, test_dict</span>
<span id="cb6-85"><a href="#cb6-85"></a>).<span class="bu">all</span>(), <span class="ss">f"Unflattened array </span><span class="sc">{</span>test_unflat<span class="sc">}</span><span class="ss"> is not as expected."</span></span>
<span id="cb6-86"><a href="#cb6-86"></a></span>
<span id="cb6-87"><a href="#cb6-87"></a><span class="bu">print</span>(<span class="st">"All tests passed successfully."</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>All tests passed successfully.</code></pre>
</div>
</div>
<div class="callout callout-style-default callout-important callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Important
</div>
</div>
<div class="callout-body-container callout-body">
<p>To control which environment to run set <code>dataset_ref</code> and <code>env_name</code> from <a href="https://minari.farama.org/">Minari</a>.</p>
</div>
</div>
<div id="cell-11" class="cell">
<div class="sourceCode cell-code" id="cb8"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1"></a>dataset_ref <span class="op">=</span> <span class="st">"mujoco/halfcheetah/expert-v0"</span></span>
<span id="cb8-2"><a href="#cb8-2"></a>env_name <span class="op">=</span> <span class="st">"HalfCheetah"</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="callout callout-style-default callout-important callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Important
</div>
</div>
<div class="callout-body-container callout-body">
<p>By default, when <code>local=True</code>, the notebook will train on all episodes in the dataset. If you would like to train on a subsample, you can control this behavior using the <code>n_episodes</code> parameter.</p>
</div>
</div>
<div id="cell-13" class="cell">
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1"></a><span class="co"># other parameters</span></span>
<span id="cb9-2"><a href="#cb9-2"></a>n_episodes: Optional[<span class="bu">int</span>] <span class="op">=</span> <span class="va">None</span> <span class="cf">if</span> <span class="kw">not</span> local <span class="cf">else</span> <span class="dv">10</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="cell-14" class="cell">
<details class="code-fold">
<summary>Load the dataset and environment</summary>
<div class="sourceCode cell-code" id="cb10"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1"></a>base_m_dataset <span class="op">=</span> minari.load_dataset(dataset_ref, download<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb10-2"><a href="#cb10-2"></a>wrapped_env <span class="op">=</span> base_m_dataset.recover_environment(render_mode<span class="op">=</span><span class="st">"rgb_array"</span>)</span>
<span id="cb10-3"><a href="#cb10-3"></a>env <span class="op">=</span> wrapped_env.unwrapped</span>
<span id="cb10-4"><a href="#cb10-4"></a>env.name <span class="op">=</span> env_name</span>
<span id="cb10-5"><a href="#cb10-5"></a></span>
<span id="cb10-6"><a href="#cb10-6"></a><span class="cf">if</span> n_episodes:</span>
<span id="cb10-7"><a href="#cb10-7"></a>    m_dataset <span class="op">=</span> base_m_dataset.sample_episodes(n_episodes)</span>
<span id="cb10-8"><a href="#cb10-8"></a><span class="cf">else</span>:</span>
<span id="cb10-9"><a href="#cb10-9"></a>    m_dataset <span class="op">=</span> base_m_dataset</span>
<span id="cb10-10"><a href="#cb10-10"></a></span>
<span id="cb10-11"><a href="#cb10-11"></a><span class="bu">print</span>(<span class="ss">f"Number of episodes: </span><span class="sc">{</span><span class="bu">len</span>(m_dataset)<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb10-12"><a href="#cb10-12"></a></span>
<span id="cb10-13"><a href="#cb10-13"></a><span class="co"># Environment parameters</span></span>
<span id="cb10-14"><a href="#cb10-14"></a>observation_dim <span class="op">=</span> get_space_dim(env.observation_space)</span>
<span id="cb10-15"><a href="#cb10-15"></a>action_dim <span class="op">=</span> get_space_dim(env.action_space)</span>
<span id="cb10-16"><a href="#cb10-16"></a>reward_dim <span class="op">=</span> <span class="dv">1</span></span>
<span id="cb10-17"><a href="#cb10-17"></a>value_dim <span class="op">=</span> <span class="dv">1</span></span>
<span id="cb10-18"><a href="#cb10-18"></a>transition_dim <span class="op">=</span> observation_dim <span class="op">+</span> action_dim <span class="op">+</span> reward_dim <span class="op">+</span> value_dim</span>
<span id="cb10-19"><a href="#cb10-19"></a></span>
<span id="cb10-20"><a href="#cb10-20"></a><span class="bu">print</span>(<span class="ss">f"Observation dim: </span><span class="sc">{</span>observation_dim<span class="sc">}</span><span class="ss">, Action dim: </span><span class="sc">{</span>action_dim<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb10-21"><a href="#cb10-21"></a><span class="bu">print</span>(<span class="ss">f"Reward dim: </span><span class="sc">{</span>reward_dim<span class="sc">}</span><span class="ss">, Value dim: </span><span class="sc">{</span>value_dim<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb10-22"><a href="#cb10-22"></a><span class="bu">print</span>(<span class="ss">f"Transition dim: </span><span class="sc">{</span>transition_dim<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb10-23"><a href="#cb10-23"></a><span class="bu">print</span>(<span class="ss">f"One episode from the dataset: </span><span class="sc">{</span>m_dataset[<span class="dv">0</span>]<span class="sc">}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stderr">
<pre><code>/Users/abrar/Library/Caches/pypoetry/virtualenvs/blog-FROQ9Grm-py3.11/lib/python3.11/site-packages/minari/dataset/minari_dataset.py:204: UserWarning: Installed mujoco version 3.1.6 does not meet the requirement ==3.2.3.
We recommend to install the required version with `pip install "mujoco==3.2.3"`
  warnings.warn(</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Number of episodes: 10
Observation dim: 17, Action dim: 6
Reward dim: 1, Value dim: 1
Transition dim: 25
One episode from the dataset: EpisodeData(id=502, total_steps=1000, observations=ndarray of shape (1001, 17) and dtype float64, actions=ndarray of shape (1000, 6) and dtype float32, rewards=ndarray of 1000 floats, terminations=ndarray of 1000 bools, truncations=ndarray of 1000 bools, infos=dict with the following keys: [])</code></pre>
</div>
</div>
</section>
<section id="key-terminology" class="level2" data-number="4">
<h2 data-number="4" class="anchored" data-anchor-id="key-terminology"><span class="header-section-number">4</span> Key Terminology</h2>
<ol type="1">
<li><p><strong>State/Observation</strong>: Represents the current condition of the environment. In TT, states are discretized into tokens and modeled as part of a sequence. A state is a vector <code>[s1, s2, s3, ...]</code>, where the number of state variables is referred to as <strong><code>observation_dim</code></strong>. For example, in <strong>HalfCheetah</strong>, <code>observation_dim = 17</code>.</p></li>
<li><p><strong>Action</strong>: A decision taken by the agent that affects the environment. Actions are also vectorized, e.g., <code>[a1, a2, ...]</code>, and modeled alongside states in TT. The number of action variables is called <strong><code>action_dim</code></strong>. For <strong>HalfCheetah</strong>, <code>action_dim = 6</code>.</p></li>
<li><p><strong>Reward</strong>: A scalar signal <code>r</code> that quantifies the <strong>immediate outcome</strong> of an action. TT uses rewards to guide trajectory optimization. Typically, <strong><code>reward_dim = 1</code></strong>, but this is not always the case.</p></li>
<li><p><strong>Value</strong>: The expected <strong>cumulative future reward</strong> from a given state. In TT, values (<code>v</code>) are used during <strong>beam search</strong> for trajectory optimization. Like rewards, values are scalars, so <strong><code>value_dim = 1</code></strong>.</p></li>
<li><p><strong>Transition</strong>: A single step in the environment, represented as a tuple <code>(state, action, reward, value)</code>, e.g., <code>[s1, s2, s3, ..., a1, a2, ..., r, v]</code>. The total number of variables in a transition is <strong><code>transition_dim = observation_dim + action_dim + reward_dim + value_dim</code></strong>. The number of consecutive transitions used for training is referred to as <strong><code>n_transitions</code></strong>.</p></li>
<li><p><strong>Sequence/Trajectory</strong>: A sequence of multiple transitions that serve as input to the model, e.g., <code>[s1, s2, s3, a1, a2, r, v, s1, s2, s3, a1, a2, r, v, ...]</code>. In TT, trajectories are <strong>modeled as discrete token sequences</strong>.</p></li>
<li><p><strong>Episode</strong>: A complete run from an <strong>initial state to termination</strong>. A sequence is a <strong>subset of an episode</strong>, but TT trains on <strong>multiple episodes</strong> to learn <strong>generalizable trajectory patterns</strong>.</p></li>
<li><p><strong>Rollout</strong>: The process of <strong>generating a trajectory</strong> by autoregressively sampling tokens (states, actions, rewards) using TT. Rollouts can be <strong>greedy</strong> (deterministic), <strong>stochastic</strong> (using temperature or top-k sampling), or <strong>beam-searched</strong> (optimizing reward-to-go). TT rollouts allow <strong>policy evaluation, trajectory forecasting, and planning</strong> in offline RL.</p></li>
</ol>
</section>
<section id="hyperparameters" class="level2" data-number="5">
<h2 data-number="5" class="anchored" data-anchor-id="hyperparameters"><span class="header-section-number">5</span> Hyperparameters</h2>
<div id="cell-17" class="cell">
<div class="sourceCode cell-code" id="cb13"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb13-1"><a href="#cb13-1"></a><span class="co"># Model parameters</span></span>
<span id="cb13-2"><a href="#cb13-2"></a><span class="co"># n_transitions is the number of transitions in a sequence, one transition is (s, a, r, v)</span></span>
<span id="cb13-3"><a href="#cb13-3"></a>n_transitions <span class="op">=</span> <span class="dv">10</span></span>
<span id="cb13-4"><a href="#cb13-4"></a><span class="co"># seq_len is the length of the sequence as seen by the model</span></span>
<span id="cb13-5"><a href="#cb13-5"></a>seq_len <span class="op">=</span> n_transitions <span class="op">*</span> transition_dim</span>
<span id="cb13-6"><a href="#cb13-6"></a><span class="co"># vocab_size is the number of bins used for discretization</span></span>
<span id="cb13-7"><a href="#cb13-7"></a><span class="co"># it also represents the size of the vocabulary for the embedding</span></span>
<span id="cb13-8"><a href="#cb13-8"></a>vocab_size <span class="op">=</span> <span class="dv">100</span></span>
<span id="cb13-9"><a href="#cb13-9"></a>max_bins <span class="op">=</span> vocab_size</span>
<span id="cb13-10"><a href="#cb13-10"></a>discount_factor <span class="op">=</span> <span class="fl">0.99</span></span>
<span id="cb13-11"><a href="#cb13-11"></a>embedding_dim <span class="op">=</span> <span class="dv">128</span> <span class="cf">if</span> <span class="kw">not</span> local <span class="cf">else</span> <span class="dv">32</span></span>
<span id="cb13-12"><a href="#cb13-12"></a><span class="co"># number of heads in the multihead attention</span></span>
<span id="cb13-13"><a href="#cb13-13"></a>n_heads <span class="op">=</span> <span class="dv">4</span> <span class="cf">if</span> <span class="kw">not</span> local <span class="cf">else</span> <span class="dv">4</span></span>
<span id="cb13-14"><a href="#cb13-14"></a><span class="co"># number of blocks in the transformer</span></span>
<span id="cb13-15"><a href="#cb13-15"></a>n_blocks <span class="op">=</span> <span class="dv">4</span> <span class="cf">if</span> <span class="kw">not</span> local <span class="cf">else</span> <span class="dv">4</span></span>
<span id="cb13-16"><a href="#cb13-16"></a>n_epochs <span class="op">=</span> <span class="dv">70</span> <span class="cf">if</span> <span class="kw">not</span> local <span class="cf">else</span> <span class="dv">5</span></span>
<span id="cb13-17"><a href="#cb13-17"></a>batch_size <span class="op">=</span> <span class="dv">256</span> <span class="cf">if</span> <span class="kw">not</span> local <span class="cf">else</span> <span class="dv">128</span></span>
<span id="cb13-18"><a href="#cb13-18"></a><span class="co"># whether to use separate heads for each transition dimension</span></span>
<span id="cb13-19"><a href="#cb13-19"></a>use_sep_heads <span class="op">=</span> <span class="va">True</span></span>
<span id="cb13-20"><a href="#cb13-20"></a>lr <span class="op">=</span> <span class="fl">0.0006</span></span>
<span id="cb13-21"><a href="#cb13-21"></a>weight_decay <span class="op">=</span> <span class="fl">0.1</span></span>
<span id="cb13-22"><a href="#cb13-22"></a>betas <span class="op">=</span> (<span class="fl">0.9</span>, <span class="fl">0.95</span>)</span>
<span id="cb13-23"><a href="#cb13-23"></a>clip_grad <span class="op">=</span> <span class="fl">1.0</span></span>
<span id="cb13-24"><a href="#cb13-24"></a><span class="co"># how often to evaluate the model. During evaluation, the model is used during rollouts</span></span>
<span id="cb13-25"><a href="#cb13-25"></a>eval_every <span class="op">=</span> <span class="dv">5</span> <span class="cf">if</span> <span class="kw">not</span> local <span class="cf">else</span> <span class="dv">5</span></span>
<span id="cb13-26"><a href="#cb13-26"></a>strategy <span class="op">=</span> <span class="st">"uniform"</span>  <span class="co"># "quantile" or "uniform" for discritization</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="cell-18" class="cell">
<details class="code-fold">
<summary>Setup data directories</summary>
<div class="sourceCode cell-code" id="cb14"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1"></a><span class="co"># create a directory to save the model</span></span>
<span id="cb14-2"><a href="#cb14-2"></a>base_dir <span class="op">=</span> <span class="ss">f"data/</span><span class="sc">{</span>dataset_ref<span class="sc">}</span><span class="ss">"</span></span>
<span id="cb14-3"><a href="#cb14-3"></a>checkpoint_path <span class="op">=</span> <span class="ss">f"</span><span class="sc">{</span>base_dir<span class="sc">}</span><span class="ss">/"</span></span>
<span id="cb14-4"><a href="#cb14-4"></a>load_checkpoint <span class="op">=</span> (</span>
<span id="cb14-5"><a href="#cb14-5"></a>    <span class="va">False</span>  <span class="co"># set to False if you want to train from scratch even if a checkpoint exists</span></span>
<span id="cb14-6"><a href="#cb14-6"></a>)</span>
<span id="cb14-7"><a href="#cb14-7"></a></span>
<span id="cb14-8"><a href="#cb14-8"></a><span class="co"># if load_checkpoint is False and a checkpoint exists, delete it</span></span>
<span id="cb14-9"><a href="#cb14-9"></a><span class="cf">if</span> load_checkpoint <span class="kw">is</span> <span class="va">False</span> <span class="kw">and</span> os.path.exists(checkpoint_path):</span>
<span id="cb14-10"><a href="#cb14-10"></a>    <span class="co"># remove only model checkpoints</span></span>
<span id="cb14-11"><a href="#cb14-11"></a>    <span class="cf">for</span> f <span class="kw">in</span> os.listdir(checkpoint_path):</span>
<span id="cb14-12"><a href="#cb14-12"></a>        <span class="cf">if</span> f.startswith(<span class="st">"model"</span>):</span>
<span id="cb14-13"><a href="#cb14-13"></a>            os.remove(os.path.join(checkpoint_path, f))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
</section>
<section id="discretizer" class="level2" data-number="6">
<h2 data-number="6" class="anchored" data-anchor-id="discretizer"><span class="header-section-number">6</span> Discretizer</h2>
<section id="what-is-discretization" class="level3" data-number="6.1">
<h3 data-number="6.1" class="anchored" data-anchor-id="what-is-discretization"><span class="header-section-number">6.1</span> What is Discretization?</h3>
<p>Discretization is the process of converting continuous variables (e.g., states, actions, rewards) into discrete tokens that can be processed by a model designed for categorical data, such as a Transformer. Instead of representing values as continuous numbers, they are quantized into a fixed set of bins, allowing TT to model RL problems as a sequence modeling task, similar to how language models process words.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="img/offline_rl/discretization.jpeg" class="img-fluid figure-img"></p>
<figcaption>https://fritz.ai/hands-on-with-feature-engineering-techniques-variable-discretization/</figcaption>
</figure>
</div>
</section>
<section id="why-is-discretization-needed-in-tt" class="level3" data-number="6.2">
<h3 data-number="6.2" class="anchored" data-anchor-id="why-is-discretization-needed-in-tt"><span class="header-section-number">6.2</span> Why is Discretization Needed in TT?</h3>
<p>The TT applies autoregressive sequence modeling, which typically operates over discrete token sequences (like words in NLP). Since RL states and actions are usually continuous, discretization is necessary to make them compatible with Transformer architectures.</p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<p><a href="https://en.wikipedia.org/wiki/Autoregressive_model">Autoregressive sequence modeling</a> is a method where each element in a sequence is predicted based on the previous elements, one step at a time, allowing the model to generate or forecast sequences by building on its own prior outputs.</p>
</div>
</div>
</section>
<section id="key-reasons-for-discretization-in-tt" class="level3" data-number="6.3">
<h3 data-number="6.3" class="anchored" data-anchor-id="key-reasons-for-discretization-in-tt"><span class="header-section-number">6.3</span> Key reasons for discretization in TT:</h3>
<ol type="1">
<li><strong>Enables Direct Application of Transformers</strong>: Transformers require discrete inputs, and discretization allows TT to treat RL data like a language modeling problem.</li>
<li><strong>Improves Long-Horizon Prediction</strong>: Standard RL models often struggle with compounding errors in continuous spaces. Discretization reduces error accumulation and improves stability in trajectory prediction.</li>
<li><strong>Avoids Gaussian Assumptions</strong>: Traditional model-based RL methods assume Gaussian-distributed transitions, which can limit expressivity. TT, using discretization, models more complex distributions without restrictive assumptions.</li>
<li><strong>Unifies State, Action, and Reward Modeling</strong>: Discretizing all components enables TT to model joint distributions over states, actions, and rewards, leading to better trajectory optimization.</li>
</ol>
</section>
<section id="how-does-discretization-work-in-tt" class="level3" data-number="6.4">
<h3 data-number="6.4" class="anchored" data-anchor-id="how-does-discretization-work-in-tt"><span class="header-section-number">6.4</span> How Does Discretization Work in TT?</h3>
<p>Each continuous state and action dimension is divided into a fixed number of bins (tokens). TT then models trajectories as sequences of these discrete tokens. The paper explores two discretization methods:</p>
<ul>
<li><strong>Uniform Discretization</strong>:
<ul>
<li>Divides the range of each variable into equally spaced intervals.</li>
<li>Preserves Euclidean distance but can be sensitive to outliers.</li>
</ul></li>
<li><strong>Quantile Discretization</strong>:
<ul>
<li>Divides data so that each bin contains an equal number of data points.</li>
<li>Ensures all tokens are well-represented in the dataset, improving learning stability.</li>
</ul></li>
</ul>
</section>
<section id="how-tt-uses-discretized-inputs" class="level3" data-number="6.5">
<h3 data-number="6.5" class="anchored" data-anchor-id="how-tt-uses-discretized-inputs"><span class="header-section-number">6.5</span> How TT Uses Discretized Inputs</h3>
<ul>
<li>A trajectory (state, action, reward, value, etc.) is broken into discrete tokens.</li>
<li>The Transformer learns sequence patterns over these tokens, predicting the most probable future trajectory.</li>
<li>During inference, TT generates the next token step-by-step, similar to how language models predict the next word.</li>
</ul>
</section>
<section id="bin-size-trade-offs" class="level3" data-number="6.6">
<h3 data-number="6.6" class="anchored" data-anchor-id="bin-size-trade-offs"><span class="header-section-number">6.6</span> Bin Size trade offs</h3>
<ul>
<li>Choosing a large bin size reduces reconstruction loss, preserving more information from continuous inputs. However, this increases the number of discrete tokens, requiring a larger vocabulary size for the embedding map. While this gives the model more expressive capacity, it comes at the cost of higher memory usage and longer training time.</li>
<li>Conversely, choosing a small bin size results in fewer tokens, leading to faster training and lower memory requirements. However, this comes at the cost of higher reconstruction loss, causing a loss of precision in trajectory representation and potentially degrading model performance.</li>
<li>The trade-off lies in balancing model expressiveness and training efficiency while minimizing information loss.</li>
</ul>
<p>By discretizing continuous RL data, TT effectively applies Transformer-based sequence modeling to RL, achieving strong long-horizon planning and offline RL performance.</p>
<div id="cell-20" class="cell" data-execution_count="6">
<div class="sourceCode cell-code" id="cb15"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb15-1"><a href="#cb15-1"></a><span class="kw">class</span> KBinsDiscretizer:</span>
<span id="cb15-2"><a href="#cb15-2"></a>    <span class="co">"""</span></span>
<span id="cb15-3"><a href="#cb15-3"></a><span class="co">    This class is responsible for encoding and decoding continuous values into discrete bins.</span></span>
<span id="cb15-4"><a href="#cb15-4"></a><span class="co">    Number of bins are fixed for all the features.</span></span>
<span id="cb15-5"><a href="#cb15-5"></a><span class="co">    """</span></span>
<span id="cb15-6"><a href="#cb15-6"></a></span>
<span id="cb15-7"><a href="#cb15-7"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, dataset: np.ndarray, n_bins: <span class="bu">int</span>, strategy: <span class="bu">str</span> <span class="op">=</span> <span class="st">"ordinal"</span>):</span>
<span id="cb15-8"><a href="#cb15-8"></a>        <span class="va">self</span>.n_bins <span class="op">=</span> n_bins</span>
<span id="cb15-9"><a href="#cb15-9"></a>        <span class="va">self</span>.strategy <span class="op">=</span> strategy</span>
<span id="cb15-10"><a href="#cb15-10"></a></span>
<span id="cb15-11"><a href="#cb15-11"></a>        <span class="co"># bin_edges shape: (n_features, n_bins + 1)</span></span>
<span id="cb15-12"><a href="#cb15-12"></a>        <span class="va">self</span>.bin_edges <span class="op">=</span> <span class="va">self</span>._find_bin_edges(dataset)</span>
<span id="cb15-13"><a href="#cb15-13"></a>        <span class="co"># bin_centers shape: (n_features, n_bins)</span></span>
<span id="cb15-14"><a href="#cb15-14"></a>        <span class="va">self</span>.bin_centers <span class="op">=</span> (<span class="va">self</span>.bin_edges[:, :<span class="op">-</span><span class="dv">1</span>] <span class="op">+</span> <span class="va">self</span>.bin_edges[:, <span class="dv">1</span>:]) <span class="op">*</span> <span class="fl">0.5</span></span>
<span id="cb15-15"><a href="#cb15-15"></a>        <span class="va">self</span>.bin_centers_torch <span class="op">=</span> torch.from_numpy(<span class="va">self</span>.bin_centers).<span class="bu">float</span>()</span>
<span id="cb15-16"><a href="#cb15-16"></a></span>
<span id="cb15-17"><a href="#cb15-17"></a>    <span class="kw">def</span> _find_bin_edges(<span class="va">self</span>, dataset: np.ndarray):</span>
<span id="cb15-18"><a href="#cb15-18"></a>        <span class="co"># dataset shape: (n_samples, n_features)</span></span>
<span id="cb15-19"><a href="#cb15-19"></a>        bin_edges <span class="op">=</span> []</span>
<span id="cb15-20"><a href="#cb15-20"></a>        <span class="cf">if</span> <span class="va">self</span>.strategy <span class="op">==</span> <span class="st">"uniform"</span>:</span>
<span id="cb15-21"><a href="#cb15-21"></a>            <span class="co"># min and max values for each feature, shpae: (n_features,)</span></span>
<span id="cb15-22"><a href="#cb15-22"></a>            mins, maxs <span class="op">=</span> np.<span class="bu">min</span>(dataset, axis<span class="op">=</span><span class="dv">0</span>), np.<span class="bu">max</span>(dataset, axis<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb15-23"><a href="#cb15-23"></a>            <span class="co"># bin_edges shape: (n_features, n_bins + 1)</span></span>
<span id="cb15-24"><a href="#cb15-24"></a>            bin_edges <span class="op">=</span> np.linspace(mins, maxs, <span class="va">self</span>.n_bins <span class="op">+</span> <span class="dv">1</span>).T</span>
<span id="cb15-25"><a href="#cb15-25"></a>        <span class="cf">elif</span> <span class="va">self</span>.strategy <span class="op">==</span> <span class="st">"quantile"</span>:</span>
<span id="cb15-26"><a href="#cb15-26"></a>            quantiles <span class="op">=</span> np.linspace(<span class="dv">0</span>, <span class="dv">100</span>, <span class="va">self</span>.n_bins <span class="op">+</span> <span class="dv">1</span>)</span>
<span id="cb15-27"><a href="#cb15-27"></a>            <span class="co"># bin_edges shape: (n_features, n_bins + 1)</span></span>
<span id="cb15-28"><a href="#cb15-28"></a>            bin_edges <span class="op">=</span> np.percentile(dataset, quantiles, axis<span class="op">=</span><span class="dv">0</span>).T</span>
<span id="cb15-29"><a href="#cb15-29"></a>        <span class="cf">else</span>:</span>
<span id="cb15-30"><a href="#cb15-30"></a>            <span class="cf">raise</span> <span class="pp">ValueError</span>(<span class="ss">f"Unknown strategy: </span><span class="sc">{</span><span class="va">self</span><span class="sc">.</span>strategy<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb15-31"><a href="#cb15-31"></a>        <span class="cf">return</span> bin_edges</span>
<span id="cb15-32"><a href="#cb15-32"></a></span>
<span id="cb15-33"><a href="#cb15-33"></a>    <span class="kw">def</span> encode(</span>
<span id="cb15-34"><a href="#cb15-34"></a>        <span class="va">self</span>, X: np.ndarray, subslice: Optional[Tuple[<span class="bu">int</span>, <span class="bu">int</span>]] <span class="op">=</span> <span class="va">None</span></span>
<span id="cb15-35"><a href="#cb15-35"></a>    ) <span class="op">-&gt;</span> np.ndarray:</span>
<span id="cb15-36"><a href="#cb15-36"></a>        <span class="co"># use subslice to encode only a part of the features in the X</span></span>
<span id="cb15-37"><a href="#cb15-37"></a>        <span class="cf">if</span> X.ndim <span class="op">==</span> <span class="dv">1</span>:</span>
<span id="cb15-38"><a href="#cb15-38"></a>            <span class="co"># this is to handle the case where we have a single feature</span></span>
<span id="cb15-39"><a href="#cb15-39"></a>            X <span class="op">=</span> X[<span class="va">None</span>]</span>
<span id="cb15-40"><a href="#cb15-40"></a>        <span class="co"># data shape: (n_samples, n_features)</span></span>
<span id="cb15-41"><a href="#cb15-41"></a>        edges <span class="op">=</span> <span class="va">self</span>.bin_edges</span>
<span id="cb15-42"><a href="#cb15-42"></a>        <span class="cf">if</span> subslice <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span>:</span>
<span id="cb15-43"><a href="#cb15-43"></a>            start, end <span class="op">=</span> subslice</span>
<span id="cb15-44"><a href="#cb15-44"></a>            edges <span class="op">=</span> edges[start:end]</span>
<span id="cb15-45"><a href="#cb15-45"></a></span>
<span id="cb15-46"><a href="#cb15-46"></a>        <span class="co"># Xt represents discretized data, shape: (n_samples, n_features)</span></span>
<span id="cb15-47"><a href="#cb15-47"></a>        Xt <span class="op">=</span> np.zeros(X.shape, dtype<span class="op">=</span>np.<span class="bu">long</span>)</span>
<span id="cb15-48"><a href="#cb15-48"></a></span>
<span id="cb15-49"><a href="#cb15-49"></a>        <span class="co"># See documentation of numpy.isclose for an explanation of ``rtol`` and ``atol``.</span></span>
<span id="cb15-50"><a href="#cb15-50"></a>        rtol <span class="op">=</span> <span class="fl">1.0e-5</span></span>
<span id="cb15-51"><a href="#cb15-51"></a>        atol <span class="op">=</span> <span class="fl">1.0e-8</span></span>
<span id="cb15-52"><a href="#cb15-52"></a></span>
<span id="cb15-53"><a href="#cb15-53"></a>        <span class="cf">for</span> jj <span class="kw">in</span> <span class="bu">range</span>(X.shape[<span class="dv">1</span>]):</span>
<span id="cb15-54"><a href="#cb15-54"></a>            <span class="co"># Values which are close to a bin edge are susceptible to numeric</span></span>
<span id="cb15-55"><a href="#cb15-55"></a>            <span class="co"># instability. Add eps to X so these values are binned correctly</span></span>
<span id="cb15-56"><a href="#cb15-56"></a>            <span class="co"># with respect to their decimal truncation.</span></span>
<span id="cb15-57"><a href="#cb15-57"></a>            eps <span class="op">=</span> atol <span class="op">+</span> rtol <span class="op">*</span> np.<span class="bu">abs</span>(X[:, jj])</span>
<span id="cb15-58"><a href="#cb15-58"></a>            <span class="co"># why [1:]? bins = edges - 1, but its unclear why we leave out the first element and not the last</span></span>
<span id="cb15-59"><a href="#cb15-59"></a>            Xt[:, jj] <span class="op">=</span> np.digitize(X[:, jj] <span class="op">+</span> eps, edges[jj][<span class="dv">1</span>:])</span>
<span id="cb15-60"><a href="#cb15-60"></a></span>
<span id="cb15-61"><a href="#cb15-61"></a>        <span class="co"># clip the values to be within the range [0, n_bins - 1]</span></span>
<span id="cb15-62"><a href="#cb15-62"></a>        np.clip(Xt, <span class="dv">0</span>, <span class="va">self</span>.n_bins <span class="op">-</span> <span class="dv">1</span>, out<span class="op">=</span>Xt)</span>
<span id="cb15-63"><a href="#cb15-63"></a></span>
<span id="cb15-64"><a href="#cb15-64"></a>        <span class="cf">return</span> Xt</span>
<span id="cb15-65"><a href="#cb15-65"></a></span>
<span id="cb15-66"><a href="#cb15-66"></a>    <span class="kw">def</span> decode(</span>
<span id="cb15-67"><a href="#cb15-67"></a>        <span class="va">self</span>, Xt: np.ndarray, subslice: Optional[Tuple[<span class="bu">int</span>, <span class="bu">int</span>]] <span class="op">=</span> <span class="va">None</span></span>
<span id="cb15-68"><a href="#cb15-68"></a>    ) <span class="op">-&gt;</span> np.ndarray:</span>
<span id="cb15-69"><a href="#cb15-69"></a>        <span class="co"># use subslice to decode only a part of the features in the Xt</span></span>
<span id="cb15-70"><a href="#cb15-70"></a>        <span class="cf">if</span> Xt.ndim <span class="op">==</span> <span class="dv">1</span>:</span>
<span id="cb15-71"><a href="#cb15-71"></a>            <span class="co"># this is to handle the case where we have a single feature</span></span>
<span id="cb15-72"><a href="#cb15-72"></a>            Xt <span class="op">=</span> Xt[<span class="va">None</span>]</span>
<span id="cb15-73"><a href="#cb15-73"></a>        <span class="co"># data shape: (n_samples, n_features)</span></span>
<span id="cb15-74"><a href="#cb15-74"></a>        centers <span class="op">=</span> <span class="va">self</span>.bin_centers</span>
<span id="cb15-75"><a href="#cb15-75"></a>        <span class="cf">if</span> subslice <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span>:</span>
<span id="cb15-76"><a href="#cb15-76"></a>            start, end <span class="op">=</span> subslice</span>
<span id="cb15-77"><a href="#cb15-77"></a>            centers <span class="op">=</span> centers[start:end]</span>
<span id="cb15-78"><a href="#cb15-78"></a></span>
<span id="cb15-79"><a href="#cb15-79"></a>        X <span class="op">=</span> np.zeros(Xt.shape, dtype<span class="op">=</span>np.float64)</span>
<span id="cb15-80"><a href="#cb15-80"></a>        <span class="cf">for</span> jj <span class="kw">in</span> <span class="bu">range</span>(Xt.shape[<span class="dv">1</span>]):</span>
<span id="cb15-81"><a href="#cb15-81"></a>            X[:, jj] <span class="op">=</span> centers[jj, np.int_(Xt[:, jj])]</span>
<span id="cb15-82"><a href="#cb15-82"></a></span>
<span id="cb15-83"><a href="#cb15-83"></a>        <span class="cf">return</span> X</span>
<span id="cb15-84"><a href="#cb15-84"></a></span>
<span id="cb15-85"><a href="#cb15-85"></a>    <span class="kw">def</span> expectation(</span>
<span id="cb15-86"><a href="#cb15-86"></a>        <span class="va">self</span>, probs: np.ndarray, subslice: Optional[Tuple[<span class="bu">int</span>, <span class="bu">int</span>]] <span class="op">=</span> <span class="va">None</span></span>
<span id="cb15-87"><a href="#cb15-87"></a>    ) <span class="op">-&gt;</span> np.ndarray:</span>
<span id="cb15-88"><a href="#cb15-88"></a>        <span class="co"># given the probabilities of each bin, calculate the expectation of the feature values</span></span>
<span id="cb15-89"><a href="#cb15-89"></a>        <span class="co"># perticularly useful when we have a distribution over the bins, maybe from a model after softmax</span></span>
<span id="cb15-90"><a href="#cb15-90"></a>        <span class="co"># from logits.</span></span>
<span id="cb15-91"><a href="#cb15-91"></a>        <span class="co"># probs shape: (n_samples, n_features, n_bins)</span></span>
<span id="cb15-92"><a href="#cb15-92"></a>        <span class="cf">if</span> probs.ndim <span class="op">==</span> <span class="dv">1</span>:</span>
<span id="cb15-93"><a href="#cb15-93"></a>            <span class="co"># this is to handle the case where we have a single feature</span></span>
<span id="cb15-94"><a href="#cb15-94"></a>            probs <span class="op">=</span> probs[<span class="va">None</span>]</span>
<span id="cb15-95"><a href="#cb15-95"></a>        <span class="co"># probs shape: (batch_size, n_features, n_bins)</span></span>
<span id="cb15-96"><a href="#cb15-96"></a>        <span class="co"># bin_centers shape: (n_features, n_bins) -&gt; (1, n_features, n_bins)</span></span>
<span id="cb15-97"><a href="#cb15-97"></a>        <span class="cf">if</span> torch.is_tensor(probs):</span>
<span id="cb15-98"><a href="#cb15-98"></a>            bin_centers <span class="op">=</span> <span class="va">self</span>.bin_centers_torch.unsqueeze(<span class="dv">0</span>)</span>
<span id="cb15-99"><a href="#cb15-99"></a>        <span class="cf">else</span>:</span>
<span id="cb15-100"><a href="#cb15-100"></a>            <span class="co"># bin_centers shape: (n_features, n_bins) -&gt; (1, n_features, n_bins)</span></span>
<span id="cb15-101"><a href="#cb15-101"></a>            bin_centers <span class="op">=</span> np.expand_dims(<span class="va">self</span>.bin_centers, axis<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb15-102"><a href="#cb15-102"></a></span>
<span id="cb15-103"><a href="#cb15-103"></a>        <span class="cf">if</span> subslice <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span>:</span>
<span id="cb15-104"><a href="#cb15-104"></a>            start, end <span class="op">=</span> subslice</span>
<span id="cb15-105"><a href="#cb15-105"></a>            bin_centers <span class="op">=</span> bin_centers[:, start:end]</span>
<span id="cb15-106"><a href="#cb15-106"></a></span>
<span id="cb15-107"><a href="#cb15-107"></a>        <span class="co"># use formula E[X] = sum(p(x) * x) for all x</span></span>
<span id="cb15-108"><a href="#cb15-108"></a>        <span class="co"># (batch_size, n_features, n_bins) * (1, n_features, n_bins) -&gt; sum (batch_size, n_features, n_bins) -&gt; (batch_size, n_features)</span></span>
<span id="cb15-109"><a href="#cb15-109"></a>        X <span class="op">=</span> (probs <span class="op">*</span> bin_centers).<span class="bu">sum</span>(axis<span class="op">=-</span><span class="dv">1</span>)</span>
<span id="cb15-110"><a href="#cb15-110"></a>        <span class="cf">return</span> X</span>
<span id="cb15-111"><a href="#cb15-111"></a></span>
<span id="cb15-112"><a href="#cb15-112"></a>    <span class="kw">def</span> to(<span class="va">self</span>, device):</span>
<span id="cb15-113"><a href="#cb15-113"></a>        <span class="va">self</span>.bin_centers_torch <span class="op">=</span> <span class="va">self</span>.bin_centers_torch.to(device)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="cell-21" class="cell" data-execution_count="7">
<details class="code-fold">
<summary>Test the KBinsDiscretizer class</summary>
<div class="sourceCode cell-code" id="cb16"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb16-1"><a href="#cb16-1"></a><span class="co"># Test array</span></span>
<span id="cb16-2"><a href="#cb16-2"></a>test_arr <span class="op">=</span> np.array([[<span class="dv">1</span>, <span class="dv">2</span>], [<span class="dv">3</span>, <span class="dv">4</span>], [<span class="dv">5</span>, <span class="dv">6</span>]])</span>
<span id="cb16-3"><a href="#cb16-3"></a></span>
<span id="cb16-4"><a href="#cb16-4"></a><span class="co"># Initialize the discretizer</span></span>
<span id="cb16-5"><a href="#cb16-5"></a>discretizer <span class="op">=</span> KBinsDiscretizer(test_arr, <span class="dv">1000</span>, strategy<span class="op">=</span><span class="st">"uniform"</span>)</span>
<span id="cb16-6"><a href="#cb16-6"></a></span>
<span id="cb16-7"><a href="#cb16-7"></a><span class="co"># Encode and decode the test array</span></span>
<span id="cb16-8"><a href="#cb16-8"></a>encoded <span class="op">=</span> discretizer.encode(test_arr)</span>
<span id="cb16-9"><a href="#cb16-9"></a>decoded <span class="op">=</span> discretizer.decode(encoded)</span>
<span id="cb16-10"><a href="#cb16-10"></a></span>
<span id="cb16-11"><a href="#cb16-11"></a><span class="co"># Check if the decoded array is close to the original array</span></span>
<span id="cb16-12"><a href="#cb16-12"></a><span class="cf">assert</span> np.isclose(</span>
<span id="cb16-13"><a href="#cb16-13"></a>    decoded, test_arr, atol<span class="op">=</span><span class="fl">1e-2</span></span>
<span id="cb16-14"><a href="#cb16-14"></a>).<span class="bu">all</span>(), <span class="ss">f"Decoded array </span><span class="sc">{</span>decoded<span class="sc">}</span><span class="ss"> is not close to the original array </span><span class="sc">{</span>test_arr<span class="sc">}</span><span class="ss">"</span></span>
<span id="cb16-15"><a href="#cb16-15"></a></span>
<span id="cb16-16"><a href="#cb16-16"></a><span class="co"># Generate random probabilities</span></span>
<span id="cb16-17"><a href="#cb16-17"></a>probs <span class="op">=</span> F.softmax(torch.from_numpy(np.random.rand(<span class="dv">3</span>, <span class="dv">2</span>, <span class="dv">1000</span>)), dim<span class="op">=-</span><span class="dv">1</span>).numpy()</span>
<span id="cb16-18"><a href="#cb16-18"></a></span>
<span id="cb16-19"><a href="#cb16-19"></a><span class="co"># Calculate the expectation</span></span>
<span id="cb16-20"><a href="#cb16-20"></a>expectation <span class="op">=</span> discretizer.expectation(probs)</span>
<span id="cb16-21"><a href="#cb16-21"></a></span>
<span id="cb16-22"><a href="#cb16-22"></a><span class="co"># Check if the expectation is close to the mean of the test array</span></span>
<span id="cb16-23"><a href="#cb16-23"></a>expected_mean <span class="op">=</span> np.tile(np.mean(test_arr, axis<span class="op">=</span><span class="dv">0</span>), (<span class="dv">3</span>, <span class="dv">1</span>))</span>
<span id="cb16-24"><a href="#cb16-24"></a><span class="cf">assert</span> np.isclose(</span>
<span id="cb16-25"><a href="#cb16-25"></a>    expectation, expected_mean, atol<span class="op">=</span><span class="fl">1e-1</span></span>
<span id="cb16-26"><a href="#cb16-26"></a>).<span class="bu">all</span>(), <span class="ss">f"Expectation </span><span class="sc">{</span>expectation<span class="sc">}</span><span class="ss"> is not close to the expected mean </span><span class="sc">{</span>expected_mean<span class="sc">}</span><span class="ss">"</span></span>
<span id="cb16-27"><a href="#cb16-27"></a></span>
<span id="cb16-28"><a href="#cb16-28"></a><span class="bu">print</span>(<span class="st">"All tests passed successfully."</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>All tests passed successfully.</code></pre>
</div>
</div>
</section>
</section>
<section id="pytorch-dataset" class="level2" data-number="7">
<h2 data-number="7" class="anchored" data-anchor-id="pytorch-dataset"><span class="header-section-number">7</span> Pytorch Dataset</h2>
<p>Minari datasets store offline RL trajectories, nore specifically it contain list of episodes, but they need to be structured into a PyTorch-compatible format for training of the TT. This conversion is essential for:</p>
<ul>
<li><strong>Batch Processing</strong>: PyTorch’s <code>Dataset</code> and <code>DataLoader</code> enable efficient mini-batch training, improving speed and scalability.</li>
<li><strong>Discretization &amp; Sequence Formatting</strong>: TT requires discretized trajectory sequences, which involves converting continuous states, actions, and rewards into discrete tokens that can be processed like a language model.</li>
<li><strong>Loss Masking &amp; Padding</strong>: Not all trajectories are of the same length. The conversion ensures proper padding and masking, preventing short sequences from corrupting training.</li>
<li><strong>Efficient Sampling</strong>: Instead of loading full trajectories, PyTorch datasets allow sampling smaller transition sequences, making training more memory-efficient.</li>
</ul>
<section id="rewards-to-go-rtg" class="level3" data-number="7.1">
<h3 data-number="7.1" class="anchored" data-anchor-id="rewards-to-go-rtg"><span class="header-section-number">7.1</span> Rewards-to-Go (RTG)</h3>
<p>Rewards-to-Go (RTG) is the discounted cumulative sum of future rewards from a given time step until the end of the trajectory. It represents the expected return from a state, assuming the agent follows the observed trajectory.</p>
<section id="formula" class="level4" data-number="7.1.1">
<h4 data-number="7.1.1" class="anchored" data-anchor-id="formula"><span class="header-section-number">7.1.1</span> Formula:</h4>
<p><span class="math display">\[
R_t = r_{t} + \gamma r_{t+1} + \gamma^2 r_{t+2} + \ldots + \gamma^{T-t} r_T
\]</span></p>
<p>where <span class="math inline">\((\gamma)\)</span> (discount factor) determines how much future rewards influence current decisions.</p>
</section>
<section id="why-is-rtg-important-in-tt" class="level4" data-number="7.1.2">
<h4 data-number="7.1.2" class="anchored" data-anchor-id="why-is-rtg-important-in-tt"><span class="header-section-number">7.1.2</span> Why is RTG Important in TT?</h4>
<p>RTG is only relevant for reward-maximizing beam search. In contrast, it is not used during imitation learning or goal-conditioned RL, where the focus is on replicating behavior or reaching a target state rather than optimizing for rewards.</p>
<ol type="1">
<li><strong>Encodes Long-Term Future Returns</strong>: Helps the model learn which actions lead to high rewards over time.</li>
<li><strong>No Need for Value Functions</strong>: Unlike traditional RL, TT doesn’t learn separate value functions; RTG is used directly as input.</li>
<li><strong>Improves Planning</strong>: During inference, TT biases beam search towards high RTG sequences, optimizing decision-making.</li>
</ol>
<p>By including RTG as a token in TT, the model can predict high-reward trajectories more effectively, making it powerful for offline RL and long-horizon planning.</p>
<div id="cell-23" class="cell" data-execution_count="8">
<div class="sourceCode cell-code" id="cb18"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb18-1"><a href="#cb18-1"></a><span class="kw">def</span> join_trajectory(env: Env, episode: EpisodeData, discount: <span class="bu">float</span> <span class="op">=</span> <span class="fl">0.99</span>):</span>
<span id="cb18-2"><a href="#cb18-2"></a>    <span class="co"># Convert the object of type EpisodeData to a numpy array. EpisodeData</span></span>
<span id="cb18-3"><a href="#cb18-3"></a>    <span class="co"># contains the following fields: observations, actions, rewards, other</span></span>
<span id="cb18-4"><a href="#cb18-4"></a>    <span class="co"># and each of these fields is a numpy array. We need to concatenate</span></span>
<span id="cb18-5"><a href="#cb18-5"></a>    <span class="co"># these arrays along the last axis to get a single array for each time.</span></span>
<span id="cb18-6"><a href="#cb18-6"></a></span>
<span id="cb18-7"><a href="#cb18-7"></a>    success <span class="op">=</span> episode.terminations</span>
<span id="cb18-8"><a href="#cb18-8"></a>    <span class="co"># end of the trajectory is the first success or the end of the episode</span></span>
<span id="cb18-9"><a href="#cb18-9"></a>    success_indices <span class="op">=</span> np.where(success)[<span class="dv">0</span>]</span>
<span id="cb18-10"><a href="#cb18-10"></a>    <span class="cf">if</span> <span class="bu">len</span>(success_indices) <span class="op">&gt;</span> <span class="dv">0</span>:</span>
<span id="cb18-11"><a href="#cb18-11"></a>        last_success_idx <span class="op">=</span> success_indices[<span class="dv">0</span>]</span>
<span id="cb18-12"><a href="#cb18-12"></a>        trajectory_len <span class="op">=</span> last_success_idx <span class="op">+</span> <span class="dv">1</span></span>
<span id="cb18-13"><a href="#cb18-13"></a>    <span class="cf">else</span>:</span>
<span id="cb18-14"><a href="#cb18-14"></a>        last_success_idx <span class="op">=</span> <span class="op">-</span><span class="dv">1</span></span>
<span id="cb18-15"><a href="#cb18-15"></a>        trajectory_len <span class="op">=</span> <span class="bu">len</span>(episode.rewards)</span>
<span id="cb18-16"><a href="#cb18-16"></a>    <span class="co"># shape (trajectory_len, observation_dim)</span></span>
<span id="cb18-17"><a href="#cb18-17"></a>    observations <span class="op">=</span> episode.observations</span>
<span id="cb18-18"><a href="#cb18-18"></a>    <span class="co"># shape (trajectory_len, action_dim)</span></span>
<span id="cb18-19"><a href="#cb18-19"></a>    actions <span class="op">=</span> episode.actions</span>
<span id="cb18-20"><a href="#cb18-20"></a>    <span class="co"># shape (trajectory_len, action_dim)</span></span>
<span id="cb18-21"><a href="#cb18-21"></a>    rewards <span class="op">=</span> episode.rewards[:trajectory_len]</span>
<span id="cb18-22"><a href="#cb18-22"></a></span>
<span id="cb18-23"><a href="#cb18-23"></a>    <span class="co"># use values to store the rewards to go</span></span>
<span id="cb18-24"><a href="#cb18-24"></a>    <span class="co"># for a given time step, the value is the sum of rewards from that time step</span></span>
<span id="cb18-25"><a href="#cb18-25"></a>    <span class="co"># to the end of the trajectory, discounted by discount factor at each time step</span></span>
<span id="cb18-26"><a href="#cb18-26"></a>    values <span class="op">=</span> np.zeros_like(rewards, dtype<span class="op">=</span>np.float32)</span>
<span id="cb18-27"><a href="#cb18-27"></a>    <span class="co"># calculate discounts for each time step</span></span>
<span id="cb18-28"><a href="#cb18-28"></a>    discounts <span class="op">=</span> discount <span class="op">**</span> np.arange(trajectory_len)</span>
<span id="cb18-29"><a href="#cb18-29"></a>    <span class="co"># calculate rewards to go with discount</span></span>
<span id="cb18-30"><a href="#cb18-30"></a>    <span class="cf">for</span> t <span class="kw">in</span> <span class="bu">range</span>(trajectory_len):</span>
<span id="cb18-31"><a href="#cb18-31"></a>        values[t] <span class="op">=</span> (rewards[t <span class="op">+</span> <span class="dv">1</span> :].T <span class="op">*</span> discounts[: <span class="op">-</span>t <span class="op">-</span> <span class="dv">1</span>]).<span class="bu">sum</span>()</span>
<span id="cb18-32"><a href="#cb18-32"></a></span>
<span id="cb18-33"><a href="#cb18-33"></a>    <span class="co"># drop the last state because we don't have a reward for it</span></span>
<span id="cb18-34"><a href="#cb18-34"></a>    states <span class="op">=</span> flatten_space(observations, env.observation_space)</span>
<span id="cb18-35"><a href="#cb18-35"></a>    states <span class="op">=</span> states[:trajectory_len]</span>
<span id="cb18-36"><a href="#cb18-36"></a>    actions <span class="op">=</span> flatten_space(actions, env.action_space)</span>
<span id="cb18-37"><a href="#cb18-37"></a>    actions <span class="op">=</span> actions[:trajectory_len]</span>
<span id="cb18-38"><a href="#cb18-38"></a>    rewards <span class="op">=</span> rewards[:, <span class="va">None</span>]</span>
<span id="cb18-39"><a href="#cb18-39"></a>    values <span class="op">=</span> values[:, <span class="va">None</span>]</span>
<span id="cb18-40"><a href="#cb18-40"></a></span>
<span id="cb18-41"><a href="#cb18-41"></a>    <span class="co"># shape (trajectory_len, observation_dim + action_dim + reward_dim + value_dim)</span></span>
<span id="cb18-42"><a href="#cb18-42"></a>    joined <span class="op">=</span> np.concatenate([states, actions, rewards, values], axis<span class="op">=-</span><span class="dv">1</span>)</span>
<span id="cb18-43"><a href="#cb18-43"></a></span>
<span id="cb18-44"><a href="#cb18-44"></a>    <span class="cf">return</span> joined</span>
<span id="cb18-45"><a href="#cb18-45"></a></span>
<span id="cb18-46"><a href="#cb18-46"></a></span>
<span id="cb18-47"><a href="#cb18-47"></a><span class="kw">class</span> DiscretizeDataset(Dataset):</span>
<span id="cb18-48"><a href="#cb18-48"></a>    <span class="co"># Each input into the sequence model needs to be (batch_size, tokens)</span></span>
<span id="cb18-49"><a href="#cb18-49"></a>    <span class="co"># output should be in groups of transitions</span></span>
<span id="cb18-50"><a href="#cb18-50"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(</span>
<span id="cb18-51"><a href="#cb18-51"></a>        <span class="va">self</span>,</span>
<span id="cb18-52"><a href="#cb18-52"></a>        env: Env,</span>
<span id="cb18-53"><a href="#cb18-53"></a>        m_dataset: MinariDataset,</span>
<span id="cb18-54"><a href="#cb18-54"></a>        n_transitions: <span class="bu">int</span>,</span>
<span id="cb18-55"><a href="#cb18-55"></a>        discount: <span class="bu">float</span> <span class="op">=</span> <span class="fl">0.99</span>,</span>
<span id="cb18-56"><a href="#cb18-56"></a>        max_bins: <span class="bu">int</span> <span class="op">=</span> <span class="dv">1000</span>,</span>
<span id="cb18-57"><a href="#cb18-57"></a>        strategy: <span class="bu">str</span> <span class="op">=</span> <span class="st">"quantile"</span>,</span>
<span id="cb18-58"><a href="#cb18-58"></a>        cache_path: Optional[<span class="bu">str</span>] <span class="op">=</span> <span class="va">None</span>,</span>
<span id="cb18-59"><a href="#cb18-59"></a>        load_checkpoint: <span class="bu">bool</span> <span class="op">=</span> <span class="va">True</span>,</span>
<span id="cb18-60"><a href="#cb18-60"></a>    ):</span>
<span id="cb18-61"><a href="#cb18-61"></a>        <span class="va">self</span>.m_dataset <span class="op">=</span> m_dataset</span>
<span id="cb18-62"><a href="#cb18-62"></a>        <span class="va">self</span>.n_transitions <span class="op">=</span> n_transitions</span>
<span id="cb18-63"><a href="#cb18-63"></a></span>
<span id="cb18-64"><a href="#cb18-64"></a>        ds_len <span class="op">=</span> <span class="bu">len</span>(<span class="va">self</span>.m_dataset)</span>
<span id="cb18-65"><a href="#cb18-65"></a></span>
<span id="cb18-66"><a href="#cb18-66"></a>        <span class="va">self</span>.cache_name <span class="op">=</span> (</span>
<span id="cb18-67"><a href="#cb18-67"></a>            <span class="ss">f"joined_trajectories_</span><span class="sc">{</span>n_transitions<span class="sc">}</span><span class="ss">_</span><span class="sc">{</span>max_bins<span class="sc">}</span><span class="ss">_</span><span class="sc">{</span>strategy<span class="sc">}</span><span class="ss">_</span><span class="sc">{</span>ds_len<span class="sc">}</span><span class="ss">.pkl"</span></span>
<span id="cb18-68"><a href="#cb18-68"></a>        )</span>
<span id="cb18-69"><a href="#cb18-69"></a>        cache_path <span class="op">=</span> os.path.join(cache_path, <span class="va">self</span>.cache_name) <span class="cf">if</span> cache_path <span class="cf">else</span> <span class="va">None</span></span>
<span id="cb18-70"><a href="#cb18-70"></a></span>
<span id="cb18-71"><a href="#cb18-71"></a>        <span class="cf">if</span> load_checkpoint <span class="kw">and</span> cache_path <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span> <span class="kw">and</span> os.path.exists(cache_path):</span>
<span id="cb18-72"><a href="#cb18-72"></a>            <span class="bu">print</span>(<span class="ss">f"Loading cached dataset from </span><span class="sc">{</span>cache_path<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb18-73"><a href="#cb18-73"></a>            <span class="cf">with</span> <span class="bu">open</span>(cache_path, <span class="st">"rb"</span>) <span class="im">as</span> f:</span>
<span id="cb18-74"><a href="#cb18-74"></a>                <span class="va">self</span>.joined_trajectories <span class="op">=</span> pickle.load(f)</span>
<span id="cb18-75"><a href="#cb18-75"></a>        <span class="cf">else</span>:</span>
<span id="cb18-76"><a href="#cb18-76"></a>            <span class="co"># this list will contain the joined trajectories, each item in the list</span></span>
<span id="cb18-77"><a href="#cb18-77"></a>            <span class="co"># is a trajectory of shape (trajectory_len, observation_dim + action_dim + reward_dim + value_dim)</span></span>
<span id="cb18-78"><a href="#cb18-78"></a>            <span class="co"># and that trajectory is one episodedata from the m_dataset</span></span>
<span id="cb18-79"><a href="#cb18-79"></a>            <span class="va">self</span>.joined_trajectories <span class="op">=</span> []</span>
<span id="cb18-80"><a href="#cb18-80"></a>            <span class="cf">for</span> episode <span class="kw">in</span> m_dataset:</span>
<span id="cb18-81"><a href="#cb18-81"></a>                <span class="va">self</span>.joined_trajectories.append(join_trajectory(env, episode, discount))</span>
<span id="cb18-82"><a href="#cb18-82"></a></span>
<span id="cb18-83"><a href="#cb18-83"></a>            <span class="bu">print</span>(<span class="ss">f"Caching dataset to </span><span class="sc">{</span>cache_path<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb18-84"><a href="#cb18-84"></a>            <span class="cf">with</span> <span class="bu">open</span>(cache_path, <span class="st">"wb"</span>) <span class="im">as</span> f:</span>
<span id="cb18-85"><a href="#cb18-85"></a>                pickle.dump(<span class="va">self</span>.joined_trajectories, f)</span>
<span id="cb18-86"><a href="#cb18-86"></a></span>
<span id="cb18-87"><a href="#cb18-87"></a>        <span class="va">self</span>.discretizer <span class="op">=</span> KBinsDiscretizer(</span>
<span id="cb18-88"><a href="#cb18-88"></a>            n_bins<span class="op">=</span>max_bins,</span>
<span id="cb18-89"><a href="#cb18-89"></a>            strategy<span class="op">=</span>strategy,</span>
<span id="cb18-90"><a href="#cb18-90"></a>            <span class="co"># concatenate all the trajectories</span></span>
<span id="cb18-91"><a href="#cb18-91"></a>            <span class="co"># shape (n_samples * trajectory_len, observation_dim + action_dim + reward_dim + value_dim)</span></span>
<span id="cb18-92"><a href="#cb18-92"></a>            dataset<span class="op">=</span>np.concatenate(<span class="va">self</span>.joined_trajectories, axis<span class="op">=</span><span class="dv">0</span>),</span>
<span id="cb18-93"><a href="#cb18-93"></a>        )</span>
<span id="cb18-94"><a href="#cb18-94"></a></span>
<span id="cb18-95"><a href="#cb18-95"></a>        <span class="co"># we need a dataset for training sequence model</span></span>
<span id="cb18-96"><a href="#cb18-96"></a>        <span class="co"># given that we need a sequence of n_transitions, we need to generate</span></span>
<span id="cb18-97"><a href="#cb18-97"></a>        <span class="co"># indices such that we can get n_transitions from each trajectory</span></span>
<span id="cb18-98"><a href="#cb18-98"></a>        indices <span class="op">=</span> []</span>
<span id="cb18-99"><a href="#cb18-99"></a>        <span class="cf">for</span> traj_idx, joined_trajectory <span class="kw">in</span> <span class="bu">enumerate</span>(<span class="va">self</span>.joined_trajectories):</span>
<span id="cb18-100"><a href="#cb18-100"></a>            traj_len <span class="op">=</span> joined_trajectory.shape[<span class="dv">0</span>]</span>
<span id="cb18-101"><a href="#cb18-101"></a>            end <span class="op">=</span> traj_len <span class="op">-</span> <span class="dv">1</span></span>
<span id="cb18-102"><a href="#cb18-102"></a>            <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(end):</span>
<span id="cb18-103"><a href="#cb18-103"></a>                indices.append((traj_idx, i, i <span class="op">+</span> n_transitions))</span>
<span id="cb18-104"><a href="#cb18-104"></a></span>
<span id="cb18-105"><a href="#cb18-105"></a>        <span class="va">self</span>.indices <span class="op">=</span> np.array(indices)</span>
<span id="cb18-106"><a href="#cb18-106"></a></span>
<span id="cb18-107"><a href="#cb18-107"></a>    <span class="kw">def</span> <span class="fu">__len__</span>(<span class="va">self</span>):</span>
<span id="cb18-108"><a href="#cb18-108"></a>        <span class="cf">return</span> <span class="bu">len</span>(<span class="va">self</span>.indices)</span>
<span id="cb18-109"><a href="#cb18-109"></a></span>
<span id="cb18-110"><a href="#cb18-110"></a>    <span class="kw">def</span> <span class="fu">__getitem__</span>(<span class="va">self</span>, idx):</span>
<span id="cb18-111"><a href="#cb18-111"></a>        traj_idx, start, end <span class="op">=</span> <span class="va">self</span>.indices[idx]</span>
<span id="cb18-112"><a href="#cb18-112"></a>        <span class="co"># sample a sequence of n_transitions from trajectory at traj_idx</span></span>
<span id="cb18-113"><a href="#cb18-113"></a>        joined <span class="op">=</span> <span class="va">self</span>.joined_trajectories[traj_idx][start:end]</span>
<span id="cb18-114"><a href="#cb18-114"></a>        loss_pad_mask <span class="op">=</span> np.ones((<span class="va">self</span>.n_transitions, joined.shape[<span class="op">-</span><span class="dv">1</span>]), dtype<span class="op">=</span>np.<span class="bu">long</span>)</span>
<span id="cb18-115"><a href="#cb18-115"></a>        <span class="co"># some sequences may be shorter than n_transitions, pad them with zeros</span></span>
<span id="cb18-116"><a href="#cb18-116"></a>        <span class="co"># and set the mask to zero for the padded part, this mask will be used</span></span>
<span id="cb18-117"><a href="#cb18-117"></a>        <span class="co"># to mask the loss when calculating the loss</span></span>
<span id="cb18-118"><a href="#cb18-118"></a>        <span class="cf">if</span> joined.shape[<span class="dv">0</span>] <span class="op">&lt;</span> <span class="va">self</span>.n_transitions:</span>
<span id="cb18-119"><a href="#cb18-119"></a>            <span class="co"># pad along dimension 0, zero padding at the beginning</span></span>
<span id="cb18-120"><a href="#cb18-120"></a>            <span class="co"># and (self.n_transitions - joined.shape[0]) padding at the end</span></span>
<span id="cb18-121"><a href="#cb18-121"></a>            joined <span class="op">=</span> np.pad(</span>
<span id="cb18-122"><a href="#cb18-122"></a>                joined,</span>
<span id="cb18-123"><a href="#cb18-123"></a>                ((<span class="dv">0</span>, <span class="va">self</span>.n_transitions <span class="op">-</span> joined.shape[<span class="dv">0</span>]), (<span class="dv">0</span>, <span class="dv">0</span>)),</span>
<span id="cb18-124"><a href="#cb18-124"></a>                mode<span class="op">=</span><span class="st">"constant"</span>,</span>
<span id="cb18-125"><a href="#cb18-125"></a>                constant_values<span class="op">=</span><span class="dv">0</span>,</span>
<span id="cb18-126"><a href="#cb18-126"></a>            )</span>
<span id="cb18-127"><a href="#cb18-127"></a>            loss_pad_mask[joined.shape[<span class="dv">0</span>] :] <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb18-128"><a href="#cb18-128"></a></span>
<span id="cb18-129"><a href="#cb18-129"></a>        <span class="co"># since transformer model expects discrete values, we need to encode the</span></span>
<span id="cb18-130"><a href="#cb18-130"></a>        <span class="co"># continuous values into discrete bins</span></span>
<span id="cb18-131"><a href="#cb18-131"></a>        <span class="co"># shape (n_transitions, transition_dim) -&gt; (n_transitions, transition_dim)</span></span>
<span id="cb18-132"><a href="#cb18-132"></a>        joined_discretized <span class="op">=</span> <span class="va">self</span>.discretizer.encode(joined)</span>
<span id="cb18-133"><a href="#cb18-133"></a>        <span class="co"># shape (n_transitions, transition_dim) -&gt; (n_transitions * transition_dim)</span></span>
<span id="cb18-134"><a href="#cb18-134"></a>        <span class="co"># i'e [s1, a1, r1, v1, s2, a2, r2, v2, ...]</span></span>
<span id="cb18-135"><a href="#cb18-135"></a>        joined_discretized <span class="op">=</span> joined_discretized.reshape(<span class="op">-</span><span class="dv">1</span>).astype(np.<span class="bu">long</span>)</span>
<span id="cb18-136"><a href="#cb18-136"></a>        loss_pad_mask <span class="op">=</span> loss_pad_mask.reshape(<span class="op">-</span><span class="dv">1</span>)</span>
<span id="cb18-137"><a href="#cb18-137"></a>        <span class="co"># return input, target, and mask</span></span>
<span id="cb18-138"><a href="#cb18-138"></a>        <span class="co"># since sequence model predicts the next token, target is the next token in the sequence</span></span>
<span id="cb18-139"><a href="#cb18-139"></a>        <span class="cf">return</span> joined_discretized[:<span class="op">-</span><span class="dv">1</span>], joined_discretized[<span class="dv">1</span>:], loss_pad_mask[:<span class="op">-</span><span class="dv">1</span>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="cell-24" class="cell" data-execution_count="9">
<div class="sourceCode cell-code" id="cb19"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb19-1"><a href="#cb19-1"></a>dataset <span class="op">=</span> DiscretizeDataset(</span>
<span id="cb19-2"><a href="#cb19-2"></a>    env<span class="op">=</span>env,</span>
<span id="cb19-3"><a href="#cb19-3"></a>    m_dataset<span class="op">=</span>m_dataset,</span>
<span id="cb19-4"><a href="#cb19-4"></a>    n_transitions<span class="op">=</span>n_transitions,</span>
<span id="cb19-5"><a href="#cb19-5"></a>    discount<span class="op">=</span>discount_factor,</span>
<span id="cb19-6"><a href="#cb19-6"></a>    max_bins<span class="op">=</span>max_bins,</span>
<span id="cb19-7"><a href="#cb19-7"></a>    strategy<span class="op">=</span>strategy,</span>
<span id="cb19-8"><a href="#cb19-8"></a>    cache_path<span class="op">=</span>checkpoint_path,</span>
<span id="cb19-9"><a href="#cb19-9"></a>    load_checkpoint<span class="op">=</span>load_checkpoint,</span>
<span id="cb19-10"><a href="#cb19-10"></a>)</span>
<span id="cb19-11"><a href="#cb19-11"></a></span>
<span id="cb19-12"><a href="#cb19-12"></a><span class="bu">print</span>(<span class="ss">f"Length of dataset: </span><span class="sc">{</span><span class="bu">len</span>(dataset)<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb19-13"><a href="#cb19-13"></a><span class="bu">print</span>(<span class="ss">f"Shape of input: </span><span class="sc">{</span>dataset[<span class="dv">0</span>][<span class="dv">0</span>]<span class="sc">.</span>shape<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb19-14"><a href="#cb19-14"></a><span class="bu">print</span>(<span class="ss">f"Shape of target: </span><span class="sc">{</span>dataset[<span class="dv">0</span>][<span class="dv">1</span>]<span class="sc">.</span>shape<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb19-15"><a href="#cb19-15"></a><span class="bu">print</span>(<span class="ss">f"Shape of mask: </span><span class="sc">{</span>dataset[<span class="dv">0</span>][<span class="dv">2</span>]<span class="sc">.</span>shape<span class="sc">}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Caching dataset to data/mujoco/halfcheetah/expert-v0/joined_trajectories_10_100_uniform_10.pkl
Length of dataset: 9990
Shape of input: (249,)
Shape of target: (249,)
Shape of mask: (249,)</code></pre>
</div>
</div>
<p>Let’s inspect one <code>input</code>, <code>target</code>, and <code>mask</code>. The call to <code>dataset[0]</code> fetches the first record from the dataset. For brevity, we will show only the first 10 elements. Notice how the <code>target</code> is simply the <code>input</code> shifted by 1. This approach ensures compatibility with sequence modeling, similar to how it is done in NLP. Mask value of <code>1</code> signifies that the token should be part of loss calculation.</p>
<div id="cell-26" class="cell" data-execution_count="10">
<details class="code-fold">
<summary>Test the DiscretizeDataset class</summary>
<div class="sourceCode cell-code" id="cb21"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb21-1"><a href="#cb21-1"></a><span class="co"># show input, target, and mask for the first item in the dataset</span></span>
<span id="cb21-2"><a href="#cb21-2"></a><span class="bu">print</span>(<span class="ss">f"Input: </span><span class="sc">{</span>dataset[<span class="dv">0</span>][<span class="dv">0</span>][:<span class="dv">10</span>]<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb21-3"><a href="#cb21-3"></a><span class="bu">print</span>(<span class="ss">f"Target: </span><span class="sc">{</span>dataset[<span class="dv">0</span>][<span class="dv">1</span>][:<span class="dv">10</span>]<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb21-4"><a href="#cb21-4"></a><span class="bu">print</span>(<span class="ss">f"Mask: </span><span class="sc">{</span>dataset[<span class="dv">0</span>][<span class="dv">2</span>][:<span class="dv">10</span>]<span class="sc">}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>Input: [38 34 42 55 40 56 43 48  5 41]
Target: [34 42 55 40 56 43 48  5 41 38]
Mask: [1 1 1 1 1 1 1 1 1 1]</code></pre>
</div>
</div>
<div id="cell-27" class="cell" data-execution_count="11">
<details class="code-fold">
<summary>utility functions</summary>
<div class="sourceCode cell-code" id="cb23"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb23-1"><a href="#cb23-1"></a><span class="kw">def</span> round_to_multiple(number, multiple):</span>
<span id="cb23-2"><a href="#cb23-2"></a>    <span class="co">"""</span></span>
<span id="cb23-3"><a href="#cb23-3"></a><span class="co">    Rounds a given number up to the nearest multiple of a specified value.</span></span>
<span id="cb23-4"><a href="#cb23-4"></a></span>
<span id="cb23-5"><a href="#cb23-5"></a><span class="co">    Args:</span></span>
<span id="cb23-6"><a href="#cb23-6"></a><span class="co">        number (int or float): The number to be rounded.</span></span>
<span id="cb23-7"><a href="#cb23-7"></a><span class="co">        multiple (int or float): The multiple to which the number should be rounded.</span></span>
<span id="cb23-8"><a href="#cb23-8"></a></span>
<span id="cb23-9"><a href="#cb23-9"></a><span class="co">    Returns:</span></span>
<span id="cb23-10"><a href="#cb23-10"></a><span class="co">        int or float: The number rounded up to the nearest multiple of the specified value.</span></span>
<span id="cb23-11"><a href="#cb23-11"></a><span class="co">    """</span></span>
<span id="cb23-12"><a href="#cb23-12"></a>    pad <span class="op">=</span> (multiple <span class="op">-</span> number <span class="op">%</span> multiple) <span class="op">%</span> multiple</span>
<span id="cb23-13"><a href="#cb23-13"></a>    <span class="cf">return</span> number <span class="op">+</span> pad</span>
<span id="cb23-14"><a href="#cb23-14"></a></span>
<span id="cb23-15"><a href="#cb23-15"></a></span>
<span id="cb23-16"><a href="#cb23-16"></a><span class="co"># Test the round_to_multiple function</span></span>
<span id="cb23-17"><a href="#cb23-17"></a><span class="cf">assert</span> round_to_multiple(<span class="dv">5</span>, <span class="dv">3</span>) <span class="op">==</span> <span class="dv">6</span></span>
<span id="cb23-18"><a href="#cb23-18"></a><span class="cf">assert</span> round_to_multiple(<span class="dv">6</span>, <span class="dv">3</span>) <span class="op">==</span> <span class="dv">6</span></span>
<span id="cb23-19"><a href="#cb23-19"></a><span class="cf">assert</span> round_to_multiple(<span class="dv">7</span>, <span class="dv">3</span>) <span class="op">==</span> <span class="dv">9</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<div id="cell-28" class="cell" data-execution_count="12">
<details class="code-fold">
<summary>Schedule the learning rate - linear warmup and cosine decay karpathy/minGPT</summary>
<div class="sourceCode cell-code" id="cb24"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb24-1"><a href="#cb24-1"></a><span class="kw">def</span> weight_decay_groups(</span>
<span id="cb24-2"><a href="#cb24-2"></a>    model, whitelist_modules, blacklist_modules, blacklist_named<span class="op">=</span><span class="va">None</span></span>
<span id="cb24-3"><a href="#cb24-3"></a>):</span>
<span id="cb24-4"><a href="#cb24-4"></a>    <span class="co"># from https://github.com/karpathy/minGPT</span></span>
<span id="cb24-5"><a href="#cb24-5"></a>    decay, no_decay <span class="op">=</span> <span class="bu">set</span>(), <span class="bu">set</span>()</span>
<span id="cb24-6"><a href="#cb24-6"></a></span>
<span id="cb24-7"><a href="#cb24-7"></a>    <span class="cf">for</span> mn, m <span class="kw">in</span> model.named_modules():</span>
<span id="cb24-8"><a href="#cb24-8"></a>        <span class="cf">for</span> pn, p <span class="kw">in</span> m.named_parameters():</span>
<span id="cb24-9"><a href="#cb24-9"></a>            fpn <span class="op">=</span> <span class="st">"</span><span class="sc">%s</span><span class="st">.</span><span class="sc">%s</span><span class="st">"</span> <span class="op">%</span> (mn, pn) <span class="cf">if</span> mn <span class="cf">else</span> pn  <span class="co"># full param name</span></span>
<span id="cb24-10"><a href="#cb24-10"></a></span>
<span id="cb24-11"><a href="#cb24-11"></a>            <span class="co"># starts with for rnn's, endswith other</span></span>
<span id="cb24-12"><a href="#cb24-12"></a>            <span class="cf">if</span> pn.startswith(<span class="st">"bias"</span>) <span class="kw">or</span> pn.endswith(<span class="st">"bias"</span>):</span>
<span id="cb24-13"><a href="#cb24-13"></a>                <span class="co"># all biases will not be decayed</span></span>
<span id="cb24-14"><a href="#cb24-14"></a>                no_decay.add(fpn)</span>
<span id="cb24-15"><a href="#cb24-15"></a>            <span class="cf">elif</span> (pn.startswith(<span class="st">"weight"</span>) <span class="kw">or</span> pn.endswith(<span class="st">"weight"</span>)) <span class="kw">and</span> <span class="bu">isinstance</span>(</span>
<span id="cb24-16"><a href="#cb24-16"></a>                m, blacklist_modules</span>
<span id="cb24-17"><a href="#cb24-17"></a>            ):</span>
<span id="cb24-18"><a href="#cb24-18"></a>                <span class="co"># weights of blacklist modules will NOT be weight decayed</span></span>
<span id="cb24-19"><a href="#cb24-19"></a>                no_decay.add(fpn)</span>
<span id="cb24-20"><a href="#cb24-20"></a>            <span class="cf">elif</span> (pn.startswith(<span class="st">"weight"</span>) <span class="kw">or</span> pn.endswith(<span class="st">"weight"</span>)) <span class="kw">and</span> <span class="bu">isinstance</span>(</span>
<span id="cb24-21"><a href="#cb24-21"></a>                m, whitelist_modules</span>
<span id="cb24-22"><a href="#cb24-22"></a>            ):</span>
<span id="cb24-23"><a href="#cb24-23"></a>                <span class="co"># weights of whitelist modules will be weight decayed</span></span>
<span id="cb24-24"><a href="#cb24-24"></a>                decay.add(fpn)</span>
<span id="cb24-25"><a href="#cb24-25"></a></span>
<span id="cb24-26"><a href="#cb24-26"></a>    <span class="cf">if</span> blacklist_named <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span>:</span>
<span id="cb24-27"><a href="#cb24-27"></a>        <span class="cf">for</span> name <span class="kw">in</span> blacklist_named:</span>
<span id="cb24-28"><a href="#cb24-28"></a>            no_decay.add(name)  <span class="co"># also no decay</span></span>
<span id="cb24-29"><a href="#cb24-29"></a></span>
<span id="cb24-30"><a href="#cb24-30"></a>    <span class="co"># validate that we considered every parameter</span></span>
<span id="cb24-31"><a href="#cb24-31"></a>    param_dict <span class="op">=</span> {pn: p <span class="cf">for</span> pn, p <span class="kw">in</span> model.named_parameters()}</span>
<span id="cb24-32"><a href="#cb24-32"></a>    inter_params <span class="op">=</span> decay <span class="op">&amp;</span> no_decay</span>
<span id="cb24-33"><a href="#cb24-33"></a>    union_params <span class="op">=</span> decay <span class="op">|</span> no_decay</span>
<span id="cb24-34"><a href="#cb24-34"></a>    <span class="cf">if</span> <span class="bu">len</span>(inter_params) <span class="op">!=</span> <span class="dv">0</span>:</span>
<span id="cb24-35"><a href="#cb24-35"></a>        warnings.warn(</span>
<span id="cb24-36"><a href="#cb24-36"></a>            <span class="ss">f"parameters </span><span class="sc">{</span><span class="bu">str</span>(inter_params)<span class="sc">}</span><span class="ss"> made it into both decay/no_decay sets! They will be added to only no_decay by default."</span></span>
<span id="cb24-37"><a href="#cb24-37"></a>        )</span>
<span id="cb24-38"><a href="#cb24-38"></a>        decay <span class="op">=</span> decay <span class="op">-</span> no_decay</span>
<span id="cb24-39"><a href="#cb24-39"></a></span>
<span id="cb24-40"><a href="#cb24-40"></a>    inter_params <span class="op">=</span> decay <span class="op">&amp;</span> no_decay</span>
<span id="cb24-41"><a href="#cb24-41"></a>    union_params <span class="op">=</span> decay <span class="op">|</span> no_decay</span>
<span id="cb24-42"><a href="#cb24-42"></a>    <span class="cf">if</span> <span class="bu">len</span>(param_dict.keys() <span class="op">-</span> union_params) <span class="op">!=</span> <span class="dv">0</span>:</span>
<span id="cb24-43"><a href="#cb24-43"></a>        warnings.warn(</span>
<span id="cb24-44"><a href="#cb24-44"></a>            <span class="ss">f"parameters </span><span class="sc">{</span><span class="bu">str</span>(param_dict.keys() <span class="op">-</span> union_params)<span class="sc">}</span><span class="ss"> were not separated into either decay/no_decay set! They will be added to decay by default."</span></span>
<span id="cb24-45"><a href="#cb24-45"></a>        )</span>
<span id="cb24-46"><a href="#cb24-46"></a>        decay <span class="op">=</span> decay <span class="op">|</span> (param_dict.keys() <span class="op">-</span> union_params)</span>
<span id="cb24-47"><a href="#cb24-47"></a></span>
<span id="cb24-48"><a href="#cb24-48"></a>    optim_groups <span class="op">=</span> {</span>
<span id="cb24-49"><a href="#cb24-49"></a>        <span class="st">"decay"</span>: [param_dict[pn] <span class="cf">for</span> pn <span class="kw">in</span> <span class="bu">sorted</span>(<span class="bu">list</span>(decay))],</span>
<span id="cb24-50"><a href="#cb24-50"></a>        <span class="st">"nodecay"</span>: [param_dict[pn] <span class="cf">for</span> pn <span class="kw">in</span> <span class="bu">sorted</span>(<span class="bu">list</span>(no_decay))],</span>
<span id="cb24-51"><a href="#cb24-51"></a>    }</span>
<span id="cb24-52"><a href="#cb24-52"></a>    <span class="cf">return</span> optim_groups</span>
<span id="cb24-53"><a href="#cb24-53"></a></span>
<span id="cb24-54"><a href="#cb24-54"></a></span>
<span id="cb24-55"><a href="#cb24-55"></a><span class="kw">class</span> GPTScheduler:</span>
<span id="cb24-56"><a href="#cb24-56"></a>    <span class="co">"""</span></span>
<span id="cb24-57"><a href="#cb24-57"></a><span class="co">    Linear warmup to optimizer inital_lr for #warmup_tokens,</span></span>
<span id="cb24-58"><a href="#cb24-58"></a><span class="co">    then cosine decay to inital_lr * final_lr_ratio for the rest #final_tokens</span></span>
<span id="cb24-59"><a href="#cb24-59"></a><span class="co">    source: https://github.com/karpathy/minGPT</span></span>
<span id="cb24-60"><a href="#cb24-60"></a><span class="co">    """</span></span>
<span id="cb24-61"><a href="#cb24-61"></a></span>
<span id="cb24-62"><a href="#cb24-62"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(</span>
<span id="cb24-63"><a href="#cb24-63"></a>        <span class="va">self</span>, optimizer, warmup_tokens, final_tokens, final_lr_ratio<span class="op">=</span><span class="fl">0.1</span>, decay<span class="op">=</span><span class="va">True</span></span>
<span id="cb24-64"><a href="#cb24-64"></a>    ):</span>
<span id="cb24-65"><a href="#cb24-65"></a>        <span class="va">self</span>.optimizer <span class="op">=</span> optimizer</span>
<span id="cb24-66"><a href="#cb24-66"></a>        <span class="co"># assuming that lr same for all group</span></span>
<span id="cb24-67"><a href="#cb24-67"></a>        <span class="va">self</span>.init_lr <span class="op">=</span> optimizer.param_groups[<span class="dv">0</span>][<span class="st">"lr"</span>]</span>
<span id="cb24-68"><a href="#cb24-68"></a></span>
<span id="cb24-69"><a href="#cb24-69"></a>        <span class="va">self</span>.warmup_tokens <span class="op">=</span> warmup_tokens</span>
<span id="cb24-70"><a href="#cb24-70"></a>        <span class="va">self</span>.final_tokens <span class="op">=</span> final_tokens</span>
<span id="cb24-71"><a href="#cb24-71"></a>        <span class="va">self</span>.final_lr_ratio <span class="op">=</span> final_lr_ratio</span>
<span id="cb24-72"><a href="#cb24-72"></a>        <span class="va">self</span>.decay <span class="op">=</span> decay</span>
<span id="cb24-73"><a href="#cb24-73"></a></span>
<span id="cb24-74"><a href="#cb24-74"></a>        <span class="va">self</span>.tokens_count <span class="op">=</span> <span class="fl">0.0</span></span>
<span id="cb24-75"><a href="#cb24-75"></a></span>
<span id="cb24-76"><a href="#cb24-76"></a>    <span class="kw">def</span> step(<span class="va">self</span>, batch_size):</span>
<span id="cb24-77"><a href="#cb24-77"></a>        lr_mult <span class="op">=</span> <span class="va">self</span>.__get_lr_multiplier(batch_size)</span>
<span id="cb24-78"><a href="#cb24-78"></a></span>
<span id="cb24-79"><a href="#cb24-79"></a>        <span class="cf">for</span> group <span class="kw">in</span> <span class="va">self</span>.optimizer.param_groups:</span>
<span id="cb24-80"><a href="#cb24-80"></a>            group[<span class="st">"lr"</span>] <span class="op">=</span> <span class="va">self</span>.init_lr <span class="op">*</span> lr_mult</span>
<span id="cb24-81"><a href="#cb24-81"></a></span>
<span id="cb24-82"><a href="#cb24-82"></a>    <span class="kw">def</span> get_current_lr(<span class="va">self</span>):</span>
<span id="cb24-83"><a href="#cb24-83"></a>        lr_mult <span class="op">=</span> <span class="va">self</span>.__get_lr_multiplier(<span class="fl">0.0</span>)</span>
<span id="cb24-84"><a href="#cb24-84"></a>        <span class="cf">return</span> <span class="va">self</span>.init_lr <span class="op">*</span> lr_mult</span>
<span id="cb24-85"><a href="#cb24-85"></a></span>
<span id="cb24-86"><a href="#cb24-86"></a>    <span class="kw">def</span> __get_lr_multiplier(<span class="va">self</span>, batch_size):</span>
<span id="cb24-87"><a href="#cb24-87"></a>        <span class="va">self</span>.tokens_count <span class="op">+=</span> batch_size</span>
<span id="cb24-88"><a href="#cb24-88"></a></span>
<span id="cb24-89"><a href="#cb24-89"></a>        <span class="cf">assert</span> (</span>
<span id="cb24-90"><a href="#cb24-90"></a>            <span class="va">self</span>.tokens_count <span class="op">&lt;=</span> <span class="va">self</span>.final_tokens</span>
<span id="cb24-91"><a href="#cb24-91"></a>        ), <span class="ss">f"number of tokens </span><span class="sc">{</span><span class="va">self</span><span class="sc">.</span>tokens_count<span class="sc">}</span><span class="ss"> already bigger than number of tokens for one cycle"</span></span>
<span id="cb24-92"><a href="#cb24-92"></a></span>
<span id="cb24-93"><a href="#cb24-93"></a>        <span class="cf">if</span> <span class="va">self</span>.tokens_count <span class="op">&lt;</span> <span class="va">self</span>.warmup_tokens:</span>
<span id="cb24-94"><a href="#cb24-94"></a>            lr_mult <span class="op">=</span> <span class="bu">float</span>(<span class="va">self</span>.tokens_count) <span class="op">/</span> <span class="bu">float</span>(<span class="bu">max</span>(<span class="dv">1</span>, <span class="va">self</span>.warmup_tokens))</span>
<span id="cb24-95"><a href="#cb24-95"></a>        <span class="cf">elif</span> <span class="va">self</span>.tokens_count <span class="op">&gt;=</span> <span class="va">self</span>.warmup_tokens <span class="kw">and</span> <span class="va">self</span>.decay:</span>
<span id="cb24-96"><a href="#cb24-96"></a>            tokens_passed <span class="op">=</span> <span class="va">self</span>.tokens_count <span class="op">-</span> <span class="va">self</span>.warmup_tokens</span>
<span id="cb24-97"><a href="#cb24-97"></a>            tokens_left <span class="op">=</span> <span class="va">self</span>.final_tokens <span class="op">-</span> <span class="va">self</span>.warmup_tokens</span>
<span id="cb24-98"><a href="#cb24-98"></a></span>
<span id="cb24-99"><a href="#cb24-99"></a>            progress <span class="op">=</span> <span class="bu">float</span>(tokens_passed) <span class="op">/</span> <span class="bu">float</span>(<span class="bu">max</span>(<span class="dv">1</span>, tokens_left))</span>
<span id="cb24-100"><a href="#cb24-100"></a>            lr_mult <span class="op">=</span> <span class="bu">max</span>(</span>
<span id="cb24-101"><a href="#cb24-101"></a>                <span class="va">self</span>.final_lr_ratio, <span class="fl">0.5</span> <span class="op">*</span> (<span class="fl">1.0</span> <span class="op">+</span> math.cos(math.pi <span class="op">*</span> progress))</span>
<span id="cb24-102"><a href="#cb24-102"></a>            )</span>
<span id="cb24-103"><a href="#cb24-103"></a>        <span class="cf">else</span>:</span>
<span id="cb24-104"><a href="#cb24-104"></a>            lr_mult <span class="op">=</span> <span class="fl">1.0</span></span>
<span id="cb24-105"><a href="#cb24-105"></a></span>
<span id="cb24-106"><a href="#cb24-106"></a>        <span class="cf">return</span> lr_mult</span>
<span id="cb24-107"><a href="#cb24-107"></a></span>
<span id="cb24-108"><a href="#cb24-108"></a>    <span class="kw">def</span> state_dict(<span class="va">self</span>):</span>
<span id="cb24-109"><a href="#cb24-109"></a>        <span class="co"># just for checkpoint callback</span></span>
<span id="cb24-110"><a href="#cb24-110"></a>        <span class="cf">pass</span></span>
<span id="cb24-111"><a href="#cb24-111"></a></span>
<span id="cb24-112"><a href="#cb24-112"></a></span>
<span id="cb24-113"><a href="#cb24-113"></a><span class="kw">def</span> get_optimizer(model, weight_decay, learning_rate, betas):</span>
<span id="cb24-114"><a href="#cb24-114"></a>    param_groups <span class="op">=</span> weight_decay_groups(</span>
<span id="cb24-115"><a href="#cb24-115"></a>        model<span class="op">=</span>model,</span>
<span id="cb24-116"><a href="#cb24-116"></a>        whitelist_modules<span class="op">=</span>(torch.nn.Linear, torch.nn.MultiheadAttention, EinLinear),</span>
<span id="cb24-117"><a href="#cb24-117"></a>        blacklist_modules<span class="op">=</span>(torch.nn.LayerNorm, torch.nn.Embedding),</span>
<span id="cb24-118"><a href="#cb24-118"></a>        blacklist_named<span class="op">=</span>(<span class="st">"positional_embedding"</span>,),</span>
<span id="cb24-119"><a href="#cb24-119"></a>    )</span>
<span id="cb24-120"><a href="#cb24-120"></a>    optim_groups <span class="op">=</span> [</span>
<span id="cb24-121"><a href="#cb24-121"></a>        {<span class="st">"params"</span>: param_groups[<span class="st">"decay"</span>], <span class="st">"weight_decay"</span>: weight_decay},</span>
<span id="cb24-122"><a href="#cb24-122"></a>        {<span class="st">"params"</span>: param_groups[<span class="st">"nodecay"</span>], <span class="st">"weight_decay"</span>: <span class="fl">0.0</span>},</span>
<span id="cb24-123"><a href="#cb24-123"></a>    ]</span>
<span id="cb24-124"><a href="#cb24-124"></a>    optimizer <span class="op">=</span> torch.optim.AdamW(optim_groups, lr<span class="op">=</span>learning_rate, betas<span class="op">=</span>betas)</span>
<span id="cb24-125"><a href="#cb24-125"></a></span>
<span id="cb24-126"><a href="#cb24-126"></a>    <span class="cf">return</span> optimizer</span>
<span id="cb24-127"><a href="#cb24-127"></a></span>
<span id="cb24-128"><a href="#cb24-128"></a></span>
<span id="cb24-129"><a href="#cb24-129"></a><span class="kw">def</span> get_scheduler(optimizer, warmup_tokens, final_tokens):</span>
<span id="cb24-130"><a href="#cb24-130"></a>    scheduler <span class="op">=</span> GPTScheduler(</span>
<span id="cb24-131"><a href="#cb24-131"></a>        optimizer,</span>
<span id="cb24-132"><a href="#cb24-132"></a>        warmup_tokens<span class="op">=</span>warmup_tokens,</span>
<span id="cb24-133"><a href="#cb24-133"></a>        final_tokens<span class="op">=</span>final_tokens,</span>
<span id="cb24-134"><a href="#cb24-134"></a>        decay<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb24-135"><a href="#cb24-135"></a>    )</span>
<span id="cb24-136"><a href="#cb24-136"></a>    <span class="cf">return</span> scheduler</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
</section>
</section>
</section>
<section id="model" class="level2" data-number="8">
<h2 data-number="8" class="anchored" data-anchor-id="model"><span class="header-section-number">8</span> Model</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="img/offline_rl/tt_model.png" class="img-fluid figure-img"></p>
<figcaption>TT Model</figcaption>
</figure>
</div>
<section id="tokenization-in-tt-why-and-how-offsetting-is-done" class="level3" data-number="8.1">
<h3 data-number="8.1" class="anchored" data-anchor-id="tokenization-in-tt-why-and-how-offsetting-is-done"><span class="header-section-number">8.1</span> Tokenization in TT: Why and How Offsetting is Done</h3>
<p>In traditional NLP Transformers, each token comes from a single vocabulary (e.g., words or subwords). However, in TT, we deal with multiple types of tokens—states, actions, rewards, and values—each with a shared vocabulary size (determined by the number of discretization bins <code>max_bins</code>).</p>
<p>Since we have multiple token types, we need a way to differentiate them. This is done using offsetting, where each token type is assigned a different section of the vocabulary. Kinda of like local vocab and global vocab.</p>
<section id="how-offsetting-works" class="level4" data-number="8.1.1">
<h4 data-number="8.1.1" class="anchored" data-anchor-id="how-offsetting-works"><span class="header-section-number">8.1.1</span> How Offsetting Works</h4>
<p>For a given <code>vocab_size</code>, the tokens are offset by multiples of it:</p>
<p><span class="math display">\[
\text{offsets} = [0, \text{vocab\_size}, 2 \times \text{vocab\_size}, \dots]
\]</span></p>
<p>For example, if <code>vocab_size = 10</code> and we have 4 token types (state, action, reward, value), the token indices are adjusted as follows:</p>
<ul>
<li><strong>State tokens</strong>: [0-9]</li>
<li><strong>Action tokens</strong>: [10-19]</li>
<li><strong>Reward tokens</strong>: [20-29]</li>
<li><strong>Value tokens</strong>: [30-39]</li>
</ul>
<p>This ensures that each token type is uniquely represented, preventing mix-ups between different types of information.</p>
</section>
</section>
<section id="einlinear-einstein-notation-as-a-shorthand-for-mlp" class="level3" data-number="8.2">
<h3 data-number="8.2" class="anchored" data-anchor-id="einlinear-einstein-notation-as-a-shorthand-for-mlp"><span class="header-section-number">8.2</span> EinLinear: Einstein Notation as a Shorthand for MLP</h3>
<p>Einstein summation notation (einsum) is a compact and efficient way of writing tensor operations. In <code>EinLinear</code>, we use <code>torch.einsum()</code> instead of the standard <code>torch.matmul()</code>, making the computation more explicit and flexible.</p>
<section id="how-einlinear-works" class="level4" data-number="8.2.1">
<h4 data-number="8.2.1" class="anchored" data-anchor-id="how-einlinear-works"><span class="header-section-number">8.2.1</span> How EinLinear Works</h4>
<p>A regular MLP applies a linear transformation:</p>
<p><span class="math display">\[
Y = XW^T + b
\]</span></p>
<p>For multiple models (e.g., if we use separate linear layers for different token types), <code>EinLinear</code> performs batched linear transformations efficiently:</p>
<div class="sourceCode" id="cb25"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb25-1"><a href="#cb25-1"></a>output <span class="op">=</span> torch.einsum(<span class="st">"eoi,bei-&gt;beo"</span>, <span class="va">self</span>.weight, x)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>where:</p>
<ul>
<li>eoi represents the weight tensor (n_models, out_features, in_features).</li>
<li>bei represents the input tensor (batch_size, n_models, in_features).</li>
</ul>
<p>The result is (batch_size, n_models, out_features).</p>
<p>This is just a compact way of writing matrix multiplication across multiple models, saving computation time and improving clarity.</p>
</section>
</section>
<section id="causal-masking-why-and-how" class="level3" data-number="8.3">
<h3 data-number="8.3" class="anchored" data-anchor-id="causal-masking-why-and-how"><span class="header-section-number">8.3</span> Causal Masking: Why and How?</h3>
<p>Transformers process entire sequences at once, but in RL, future information must not be leaked to the model during training. This is handled via causal masking.</p>
<section id="types-of-masking-in-tt" class="level4" data-number="8.3.1">
<h4 data-number="8.3.1" class="anchored" data-anchor-id="types-of-masking-in-tt"><span class="header-section-number">8.3.1</span> Types of Masking in TT</h4>
<section id="self-causal-masking" class="level5" data-number="8.3.1.1">
<h5 data-number="8.3.1.1" class="anchored" data-anchor-id="self-causal-masking"><span class="header-section-number">8.3.1.1</span> Self-Causal Masking</h5>
<ul>
<li>Ensures each token only attends to past tokens.</li>
<li>Implemented using a lower triangular mask (future tokens are masked out).</li>
<li>Prevents information leakage during training.</li>
</ul>
</section>
<section id="value-masking" class="level5" data-number="8.3.1.2">
<h5 data-number="8.3.1.2" class="anchored" data-anchor-id="value-masking"><span class="header-section-number">8.3.1.2</span> Value Masking</h5>
<ul>
<li>In TT, reward-to-go (RTG) is included as a token.</li>
<li>RTG contains future information, so it must not be attended to by other tokens.</li>
<li>The mask explicitly blocks RTG tokens during self-attention.</li>
</ul>
</section>
</section>
</section>
<section id="kv-cache-why-and-how-it-works" class="level3" data-number="8.4">
<h3 data-number="8.4" class="anchored" data-anchor-id="kv-cache-why-and-how-it-works"><span class="header-section-number">8.4</span> KV Cache: Why and How It Works</h3>
<p>In inference, processing one token at a time (autoregressive decoding) is inefficient if we recompute self-attention for all previous tokens at every step. Key-Value (KV) Caching solves this by storing past computations, reducing redundant work.</p>
<section id="how-kv-cache-works" class="level4" data-number="8.4.1">
<h4 data-number="8.4.1" class="anchored" data-anchor-id="how-kv-cache-works"><span class="header-section-number">8.4.1</span> How KV Cache Works</h4>
<ul>
<li>During inference, previously computed key-value (K-V) pairs are stored.</li>
<li>When a new token arrives, we append its K-V pairs instead of recomputing for all tokens.</li>
<li>This makes generation much faster.</li>
</ul>
<div id="cell-30" class="cell" data-execution_count="13">
<div class="sourceCode cell-code" id="cb26"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb26-1"><a href="#cb26-1"></a><span class="kw">class</span> Block(nn.Module):</span>
<span id="cb26-2"><a href="#cb26-2"></a>    <span class="co"># Transformer block</span></span>
<span id="cb26-3"><a href="#cb26-3"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(</span>
<span id="cb26-4"><a href="#cb26-4"></a>        <span class="va">self</span>,</span>
<span id="cb26-5"><a href="#cb26-5"></a>        seq_len,</span>
<span id="cb26-6"><a href="#cb26-6"></a>        embedding_dim: <span class="bu">int</span>,</span>
<span id="cb26-7"><a href="#cb26-7"></a>        transition_dim: <span class="bu">int</span>,</span>
<span id="cb26-8"><a href="#cb26-8"></a>        n_heads: <span class="bu">int</span>,</span>
<span id="cb26-9"><a href="#cb26-9"></a>        attention_dropout: <span class="bu">float</span>,</span>
<span id="cb26-10"><a href="#cb26-10"></a>        residual_dropout: <span class="bu">float</span>,</span>
<span id="cb26-11"><a href="#cb26-11"></a>    ):</span>
<span id="cb26-12"><a href="#cb26-12"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>()</span>
<span id="cb26-13"><a href="#cb26-13"></a>        <span class="va">self</span>.attn <span class="op">=</span> nn.MultiheadAttention(</span>
<span id="cb26-14"><a href="#cb26-14"></a>            embedding_dim, n_heads, batch_first<span class="op">=</span><span class="va">True</span>, dropout<span class="op">=</span>attention_dropout</span>
<span id="cb26-15"><a href="#cb26-15"></a>        )</span>
<span id="cb26-16"><a href="#cb26-16"></a>        <span class="va">self</span>.attn_norm <span class="op">=</span> nn.LayerNorm(embedding_dim)</span>
<span id="cb26-17"><a href="#cb26-17"></a></span>
<span id="cb26-18"><a href="#cb26-18"></a>        <span class="va">self</span>.fc_norm <span class="op">=</span> nn.LayerNorm(embedding_dim)</span>
<span id="cb26-19"><a href="#cb26-19"></a></span>
<span id="cb26-20"><a href="#cb26-20"></a>        <span class="va">self</span>.drop <span class="op">=</span> nn.Dropout(residual_dropout)</span>
<span id="cb26-21"><a href="#cb26-21"></a></span>
<span id="cb26-22"><a href="#cb26-22"></a>        <span class="va">self</span>.mlp <span class="op">=</span> nn.Sequential(</span>
<span id="cb26-23"><a href="#cb26-23"></a>            nn.Linear(embedding_dim, embedding_dim <span class="op">*</span> <span class="dv">4</span>),</span>
<span id="cb26-24"><a href="#cb26-24"></a>            nn.GELU(),</span>
<span id="cb26-25"><a href="#cb26-25"></a>            nn.Linear(embedding_dim <span class="op">*</span> <span class="dv">4</span>, embedding_dim),</span>
<span id="cb26-26"><a href="#cb26-26"></a>            nn.Dropout(residual_dropout),</span>
<span id="cb26-27"><a href="#cb26-27"></a>        )</span>
<span id="cb26-28"><a href="#cb26-28"></a>        <span class="va">self</span>.seq_len <span class="op">=</span> seq_len</span>
<span id="cb26-29"><a href="#cb26-29"></a></span>
<span id="cb26-30"><a href="#cb26-30"></a>        <span class="co"># mask value of true means that the value is not allowed to be attended to</span></span>
<span id="cb26-31"><a href="#cb26-31"></a>        mask <span class="op">=</span> <span class="op">~</span>torch.tril(torch.ones(seq_len, seq_len)).<span class="bu">bool</span>()</span>
<span id="cb26-32"><a href="#cb26-32"></a>        <span class="co"># transition_dim - 1 stores rewards to go, we don't want to attend to them because they contain future information</span></span>
<span id="cb26-33"><a href="#cb26-33"></a>        mask[:, transition_dim <span class="op">-</span> <span class="dv">1</span> :: transition_dim] <span class="op">=</span> <span class="va">True</span></span>
<span id="cb26-34"><a href="#cb26-34"></a>        <span class="va">self</span>.register_buffer(<span class="st">"mask"</span>, mask)</span>
<span id="cb26-35"><a href="#cb26-35"></a></span>
<span id="cb26-36"><a href="#cb26-36"></a>    <span class="kw">def</span> forward(</span>
<span id="cb26-37"><a href="#cb26-37"></a>        <span class="va">self</span>, x: torch.Tensor, kv_cache: Optional[torch.Tensor] <span class="op">=</span> <span class="va">None</span></span>
<span id="cb26-38"><a href="#cb26-38"></a>    ) <span class="op">-&gt;</span> torch.Tensor:</span>
<span id="cb26-39"><a href="#cb26-39"></a>        <span class="co"># x shape (batch_size, n_tokens, embedding_dim) in prefill mode else (batch_size, 1, embedding_dim)</span></span>
<span id="cb26-40"><a href="#cb26-40"></a>        <span class="co"># kv_cache shape (batch_size, n_tokens, embedding_dim) in inference mode else None</span></span>
<span id="cb26-41"><a href="#cb26-41"></a>        _, n_tokens, _ <span class="op">=</span> x.shape</span>
<span id="cb26-42"><a href="#cb26-42"></a></span>
<span id="cb26-43"><a href="#cb26-43"></a>        <span class="co"># normalize the input before passing it to the attention layer</span></span>
<span id="cb26-44"><a href="#cb26-44"></a>        x_norm <span class="op">=</span> <span class="va">self</span>.attn_norm(x)</span>
<span id="cb26-45"><a href="#cb26-45"></a></span>
<span id="cb26-46"><a href="#cb26-46"></a>        <span class="cf">if</span> kv_cache <span class="kw">is</span> <span class="va">None</span>:</span>
<span id="cb26-47"><a href="#cb26-47"></a>            <span class="co"># when kv_cache is None, we are in prefill mode</span></span>
<span id="cb26-48"><a href="#cb26-48"></a></span>
<span id="cb26-49"><a href="#cb26-49"></a>            <span class="co"># attn_mask shape (seq_len, seq_len), but incoming shape is (batch_size, n_tokens, embedding_dim)</span></span>
<span id="cb26-50"><a href="#cb26-50"></a>            <span class="co"># so filter the mask to the correct size (n_tokens, n_tokens)</span></span>
<span id="cb26-51"><a href="#cb26-51"></a>            attn_mask <span class="op">=</span> <span class="va">self</span>.mask[:n_tokens, :n_tokens]</span>
<span id="cb26-52"><a href="#cb26-52"></a>            q, k, v <span class="op">=</span> x_norm, x_norm, x_norm</span>
<span id="cb26-53"><a href="#cb26-53"></a>        <span class="cf">else</span>:</span>
<span id="cb26-54"><a href="#cb26-54"></a>            <span class="cf">assert</span> n_tokens <span class="op">==</span> <span class="dv">1</span>, <span class="st">"kv_cache can only be None with a single token"</span></span>
<span id="cb26-55"><a href="#cb26-55"></a>            <span class="co"># +1 because we are adding a new token</span></span>
<span id="cb26-56"><a href="#cb26-56"></a>            <span class="cf">assert</span> kv_cache.shape[<span class="dv">1</span>] <span class="op">+</span> <span class="dv">1</span> <span class="op">&lt;=</span> <span class="va">self</span>.seq_len, <span class="st">"kv_cache is too large"</span></span>
<span id="cb26-57"><a href="#cb26-57"></a></span>
<span id="cb26-58"><a href="#cb26-58"></a>            <span class="co"># attn_mask is None because we are running in inference mode, processing one token at a time</span></span>
<span id="cb26-59"><a href="#cb26-59"></a>            <span class="co"># and this token is not allowed to attend to future tokens</span></span>
<span id="cb26-60"><a href="#cb26-60"></a>            attn_mask <span class="op">=</span> <span class="va">None</span></span>
<span id="cb26-61"><a href="#cb26-61"></a>            q, k, v <span class="op">=</span> (</span>
<span id="cb26-62"><a href="#cb26-62"></a>                x_norm,</span>
<span id="cb26-63"><a href="#cb26-63"></a>                <span class="co"># shape (batch_size, n_tokens + 1, embedding_dim)</span></span>
<span id="cb26-64"><a href="#cb26-64"></a>                torch.cat([kv_cache, x_norm], dim<span class="op">=</span><span class="dv">1</span>),</span>
<span id="cb26-65"><a href="#cb26-65"></a>                torch.cat([kv_cache, x_norm], dim<span class="op">=</span><span class="dv">1</span>),</span>
<span id="cb26-66"><a href="#cb26-66"></a>            )</span>
<span id="cb26-67"><a href="#cb26-67"></a></span>
<span id="cb26-68"><a href="#cb26-68"></a>        new_kv_cache <span class="op">=</span> k</span>
<span id="cb26-69"><a href="#cb26-69"></a></span>
<span id="cb26-70"><a href="#cb26-70"></a>        <span class="co"># x shape (batch_size, n_tokens, embedding_dim) in prefill mode else (batch_size, 1, embedding_dim)</span></span>
<span id="cb26-71"><a href="#cb26-71"></a>        x <span class="op">=</span> x <span class="op">+</span> <span class="va">self</span>.drop(</span>
<span id="cb26-72"><a href="#cb26-72"></a>            <span class="va">self</span>.attn(q, k, v, attn_mask<span class="op">=</span>attn_mask, need_weights<span class="op">=</span><span class="va">False</span>)[<span class="dv">0</span>]</span>
<span id="cb26-73"><a href="#cb26-73"></a>        )</span>
<span id="cb26-74"><a href="#cb26-74"></a></span>
<span id="cb26-75"><a href="#cb26-75"></a>        x <span class="op">=</span> x <span class="op">+</span> <span class="va">self</span>.mlp(<span class="va">self</span>.fc_norm(x))</span>
<span id="cb26-76"><a href="#cb26-76"></a></span>
<span id="cb26-77"><a href="#cb26-77"></a>        <span class="cf">return</span> x, new_kv_cache</span>
<span id="cb26-78"><a href="#cb26-78"></a></span>
<span id="cb26-79"><a href="#cb26-79"></a></span>
<span id="cb26-80"><a href="#cb26-80"></a><span class="kw">class</span> EinLinear(nn.Module):</span>
<span id="cb26-81"><a href="#cb26-81"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(</span>
<span id="cb26-82"><a href="#cb26-82"></a>        <span class="va">self</span>, n_models: <span class="bu">int</span>, in_features: <span class="bu">int</span>, out_features: <span class="bu">int</span>, bias: <span class="bu">bool</span> <span class="op">=</span> <span class="va">True</span></span>
<span id="cb26-83"><a href="#cb26-83"></a>    ):</span>
<span id="cb26-84"><a href="#cb26-84"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>()</span>
<span id="cb26-85"><a href="#cb26-85"></a>        <span class="va">self</span>.n_models <span class="op">=</span> n_models</span>
<span id="cb26-86"><a href="#cb26-86"></a>        <span class="va">self</span>.in_features <span class="op">=</span> in_features</span>
<span id="cb26-87"><a href="#cb26-87"></a>        <span class="va">self</span>.out_features <span class="op">=</span> out_features</span>
<span id="cb26-88"><a href="#cb26-88"></a>        <span class="va">self</span>.weight <span class="op">=</span> nn.Parameter(torch.Tensor(n_models, out_features, in_features))</span>
<span id="cb26-89"><a href="#cb26-89"></a>        <span class="cf">if</span> bias:</span>
<span id="cb26-90"><a href="#cb26-90"></a>            <span class="va">self</span>.bias <span class="op">=</span> nn.Parameter(torch.Tensor(n_models, out_features))</span>
<span id="cb26-91"><a href="#cb26-91"></a>        <span class="cf">else</span>:</span>
<span id="cb26-92"><a href="#cb26-92"></a>            <span class="va">self</span>.register_parameter(<span class="st">"bias"</span>, <span class="va">None</span>)</span>
<span id="cb26-93"><a href="#cb26-93"></a>        <span class="va">self</span>.reset_parameters()</span>
<span id="cb26-94"><a href="#cb26-94"></a></span>
<span id="cb26-95"><a href="#cb26-95"></a>    <span class="kw">def</span> reset_parameters(<span class="va">self</span>):</span>
<span id="cb26-96"><a href="#cb26-96"></a>        <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="va">self</span>.n_models):</span>
<span id="cb26-97"><a href="#cb26-97"></a>            nn.init.kaiming_uniform_(<span class="va">self</span>.weight[i], a<span class="op">=</span>math.sqrt(<span class="dv">5</span>))</span>
<span id="cb26-98"><a href="#cb26-98"></a>            <span class="cf">if</span> <span class="va">self</span>.bias <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span>:</span>
<span id="cb26-99"><a href="#cb26-99"></a>                fan_in, _ <span class="op">=</span> nn.init._calculate_fan_in_and_fan_out(<span class="va">self</span>.weight[i])</span>
<span id="cb26-100"><a href="#cb26-100"></a>                bound <span class="op">=</span> <span class="dv">1</span> <span class="op">/</span> math.sqrt(fan_in)</span>
<span id="cb26-101"><a href="#cb26-101"></a>                nn.init.uniform_(<span class="va">self</span>.bias[i], <span class="op">-</span>bound, bound)</span>
<span id="cb26-102"><a href="#cb26-102"></a></span>
<span id="cb26-103"><a href="#cb26-103"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, x: torch.Tensor, model_idx: Optional[<span class="bu">int</span>] <span class="op">=</span> <span class="va">None</span>) <span class="op">-&gt;</span> torch.Tensor:</span>
<span id="cb26-104"><a href="#cb26-104"></a>        <span class="cf">if</span> model_idx <span class="kw">is</span> <span class="va">None</span>:</span>
<span id="cb26-105"><a href="#cb26-105"></a>            <span class="co"># when model_idx is None, we are in prefill mode</span></span>
<span id="cb26-106"><a href="#cb26-106"></a>            <span class="co"># (n_models, out_features, in_features) * (batch_size, n_models, in_features) -&gt; (batch_size, n_models, out_features)</span></span>
<span id="cb26-107"><a href="#cb26-107"></a>            output <span class="op">=</span> torch.einsum(<span class="st">"eoi,bei-&gt;beo"</span>, <span class="va">self</span>.weight, x)</span>
<span id="cb26-108"><a href="#cb26-108"></a>        <span class="cf">else</span>:</span>
<span id="cb26-109"><a href="#cb26-109"></a>            <span class="co"># when model_idx is not None, we are in inference mode</span></span>
<span id="cb26-110"><a href="#cb26-110"></a>            <span class="co"># shape (batch_size, in_features) * (out_features, in_features).T -&gt; (batch_size, out_features)</span></span>
<span id="cb26-111"><a href="#cb26-111"></a>            output <span class="op">=</span> x <span class="op">@</span> <span class="va">self</span>.weight[model_idx].T</span>
<span id="cb26-112"><a href="#cb26-112"></a></span>
<span id="cb26-113"><a href="#cb26-113"></a>        <span class="cf">if</span> <span class="va">self</span>.bias <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span>:</span>
<span id="cb26-114"><a href="#cb26-114"></a>            <span class="cf">raise</span> <span class="pp">RuntimeError</span>()</span>
<span id="cb26-115"><a href="#cb26-115"></a></span>
<span id="cb26-116"><a href="#cb26-116"></a>        <span class="cf">return</span> output</span>
<span id="cb26-117"><a href="#cb26-117"></a></span>
<span id="cb26-118"><a href="#cb26-118"></a></span>
<span id="cb26-119"><a href="#cb26-119"></a><span class="kw">class</span> TrajectoryTransformer(nn.Module):</span>
<span id="cb26-120"><a href="#cb26-120"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(</span>
<span id="cb26-121"><a href="#cb26-121"></a>        <span class="va">self</span>,</span>
<span id="cb26-122"><a href="#cb26-122"></a>        seq_len: <span class="bu">int</span>,</span>
<span id="cb26-123"><a href="#cb26-123"></a>        embedding_dim: <span class="bu">int</span>,</span>
<span id="cb26-124"><a href="#cb26-124"></a>        n_heads: <span class="bu">int</span>,</span>
<span id="cb26-125"><a href="#cb26-125"></a>        transition_dim: <span class="bu">int</span>,</span>
<span id="cb26-126"><a href="#cb26-126"></a>        n_blocks: <span class="bu">int</span>,</span>
<span id="cb26-127"><a href="#cb26-127"></a>        vocab_size: <span class="bu">int</span>,</span>
<span id="cb26-128"><a href="#cb26-128"></a>        dropout_embedding: <span class="bu">float</span> <span class="op">=</span> <span class="fl">0.1</span>,</span>
<span id="cb26-129"><a href="#cb26-129"></a>        attention_dropout: <span class="bu">float</span> <span class="op">=</span> <span class="fl">0.1</span>,</span>
<span id="cb26-130"><a href="#cb26-130"></a>        residual_dropout: <span class="bu">float</span> <span class="op">=</span> <span class="fl">0.1</span>,</span>
<span id="cb26-131"><a href="#cb26-131"></a>        use_sep_heads: <span class="bu">bool</span> <span class="op">=</span> <span class="va">False</span>,</span>
<span id="cb26-132"><a href="#cb26-132"></a>    ):</span>
<span id="cb26-133"><a href="#cb26-133"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>()</span>
<span id="cb26-134"><a href="#cb26-134"></a>        <span class="va">self</span>.seq_len <span class="op">=</span> seq_len</span>
<span id="cb26-135"><a href="#cb26-135"></a>        <span class="va">self</span>.embedding_dim <span class="op">=</span> embedding_dim</span>
<span id="cb26-136"><a href="#cb26-136"></a>        <span class="va">self</span>.n_heads <span class="op">=</span> n_heads</span>
<span id="cb26-137"><a href="#cb26-137"></a>        <span class="va">self</span>.transition_dim <span class="op">=</span> transition_dim</span>
<span id="cb26-138"><a href="#cb26-138"></a>        <span class="va">self</span>.n_blocks <span class="op">=</span> n_blocks</span>
<span id="cb26-139"><a href="#cb26-139"></a>        <span class="va">self</span>.vocab_size <span class="op">=</span> vocab_size</span>
<span id="cb26-140"><a href="#cb26-140"></a></span>
<span id="cb26-141"><a href="#cb26-141"></a>        <span class="co"># our input contains transition_dim types of tokens and each token is from a vocab of size vocab_size</span></span>
<span id="cb26-142"><a href="#cb26-142"></a>        <span class="co"># so the total number of tokens is transition_dim * vocab_size</span></span>
<span id="cb26-143"><a href="#cb26-143"></a>        <span class="va">self</span>.token_embedding <span class="op">=</span> nn.Embedding(</span>
<span id="cb26-144"><a href="#cb26-144"></a>            vocab_size <span class="op">*</span> transition_dim, <span class="va">self</span>.embedding_dim</span>
<span id="cb26-145"><a href="#cb26-145"></a>        )</span>
<span id="cb26-146"><a href="#cb26-146"></a>        <span class="co"># learnable positional embedding</span></span>
<span id="cb26-147"><a href="#cb26-147"></a>        <span class="va">self</span>.positional_embedding <span class="op">=</span> nn.Parameter(</span>
<span id="cb26-148"><a href="#cb26-148"></a>            torch.zeros(<span class="dv">1</span>, seq_len, <span class="va">self</span>.embedding_dim)</span>
<span id="cb26-149"><a href="#cb26-149"></a>        )</span>
<span id="cb26-150"><a href="#cb26-150"></a></span>
<span id="cb26-151"><a href="#cb26-151"></a>        <span class="va">self</span>.dropout_embedding <span class="op">=</span> nn.Dropout(dropout_embedding)</span>
<span id="cb26-152"><a href="#cb26-152"></a></span>
<span id="cb26-153"><a href="#cb26-153"></a>        <span class="co"># create n_blocks of transformer blocks</span></span>
<span id="cb26-154"><a href="#cb26-154"></a>        <span class="va">self</span>.blocks <span class="op">=</span> nn.ModuleList(</span>
<span id="cb26-155"><a href="#cb26-155"></a>            [</span>
<span id="cb26-156"><a href="#cb26-156"></a>                Block(</span>
<span id="cb26-157"><a href="#cb26-157"></a>                    <span class="va">self</span>.seq_len,</span>
<span id="cb26-158"><a href="#cb26-158"></a>                    <span class="va">self</span>.embedding_dim,</span>
<span id="cb26-159"><a href="#cb26-159"></a>                    <span class="va">self</span>.transition_dim,</span>
<span id="cb26-160"><a href="#cb26-160"></a>                    <span class="va">self</span>.n_heads,</span>
<span id="cb26-161"><a href="#cb26-161"></a>                    attention_dropout,</span>
<span id="cb26-162"><a href="#cb26-162"></a>                    residual_dropout,</span>
<span id="cb26-163"><a href="#cb26-163"></a>                )</span>
<span id="cb26-164"><a href="#cb26-164"></a>                <span class="cf">for</span> _ <span class="kw">in</span> <span class="bu">range</span>(<span class="va">self</span>.n_blocks)</span>
<span id="cb26-165"><a href="#cb26-165"></a>            ]</span>
<span id="cb26-166"><a href="#cb26-166"></a>        )</span>
<span id="cb26-167"><a href="#cb26-167"></a></span>
<span id="cb26-168"><a href="#cb26-168"></a>        <span class="va">self</span>.norm <span class="op">=</span> nn.LayerNorm(<span class="va">self</span>.embedding_dim)</span>
<span id="cb26-169"><a href="#cb26-169"></a></span>
<span id="cb26-170"><a href="#cb26-170"></a>        <span class="va">self</span>.use_sep_heads <span class="op">=</span> use_sep_heads</span>
<span id="cb26-171"><a href="#cb26-171"></a></span>
<span id="cb26-172"><a href="#cb26-172"></a>        <span class="cf">if</span> <span class="kw">not</span> <span class="va">self</span>.use_sep_heads:</span>
<span id="cb26-173"><a href="#cb26-173"></a>            <span class="co"># project the output of the transformer to the vocab size</span></span>
<span id="cb26-174"><a href="#cb26-174"></a>            <span class="co"># since each token type is from a vocab of size vocab_size</span></span>
<span id="cb26-175"><a href="#cb26-175"></a>            <span class="co"># we can do this. But for instance if every token type used different</span></span>
<span id="cb26-176"><a href="#cb26-176"></a>            <span class="co"># number of bins, then we would have handled this differently. But dont worry</span></span>
<span id="cb26-177"><a href="#cb26-177"></a>            <span class="co"># that is not the case here.</span></span>
<span id="cb26-178"><a href="#cb26-178"></a>            <span class="va">self</span>.fc <span class="op">=</span> nn.Linear(<span class="va">self</span>.embedding_dim, vocab_size)</span>
<span id="cb26-179"><a href="#cb26-179"></a>        <span class="cf">else</span>:</span>
<span id="cb26-180"><a href="#cb26-180"></a>            <span class="va">self</span>.fc <span class="op">=</span> EinLinear(</span>
<span id="cb26-181"><a href="#cb26-181"></a>                <span class="va">self</span>.transition_dim, <span class="va">self</span>.embedding_dim, vocab_size, bias<span class="op">=</span><span class="va">False</span></span>
<span id="cb26-182"><a href="#cb26-182"></a>            )</span>
<span id="cb26-183"><a href="#cb26-183"></a></span>
<span id="cb26-184"><a href="#cb26-184"></a>        <span class="co"># self.apply is a crazy function that applies the given function recursively to every submodule</span></span>
<span id="cb26-185"><a href="#cb26-185"></a>        <span class="va">self</span>.<span class="bu">apply</span>(<span class="va">self</span>._init_weights)</span>
<span id="cb26-186"><a href="#cb26-186"></a></span>
<span id="cb26-187"><a href="#cb26-187"></a>    <span class="kw">def</span> _init_weights(<span class="va">self</span>, module):</span>
<span id="cb26-188"><a href="#cb26-188"></a>        <span class="co"># standard practice in transformer models</span></span>
<span id="cb26-189"><a href="#cb26-189"></a>        <span class="cf">if</span> <span class="bu">isinstance</span>(module, (nn.Linear, nn.Embedding)):</span>
<span id="cb26-190"><a href="#cb26-190"></a>            torch.nn.init.xavier_uniform_(module.weight)</span>
<span id="cb26-191"><a href="#cb26-191"></a>            <span class="cf">if</span> <span class="bu">isinstance</span>(module, (nn.Linear)) <span class="kw">and</span> module.bias <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span>:</span>
<span id="cb26-192"><a href="#cb26-192"></a>                torch.nn.init.constant_(module.bias, <span class="fl">0.0</span>)</span>
<span id="cb26-193"><a href="#cb26-193"></a>        <span class="cf">elif</span> <span class="bu">isinstance</span>(module, nn.LayerNorm):</span>
<span id="cb26-194"><a href="#cb26-194"></a>            torch.nn.init.constant_(module.bias, <span class="fl">0.0</span>)</span>
<span id="cb26-195"><a href="#cb26-195"></a>            torch.nn.init.constant_(module.weight, <span class="fl">1.0</span>)</span>
<span id="cb26-196"><a href="#cb26-196"></a>        <span class="cf">elif</span> <span class="bu">isinstance</span>(module, TrajectoryTransformer):</span>
<span id="cb26-197"><a href="#cb26-197"></a>            torch.nn.init.normal_(module.positional_embedding, mean<span class="op">=</span><span class="fl">0.0</span>, std<span class="op">=</span><span class="fl">0.02</span>)</span>
<span id="cb26-198"><a href="#cb26-198"></a></span>
<span id="cb26-199"><a href="#cb26-199"></a>    <span class="kw">def</span> get_seq_len(<span class="va">self</span>):</span>
<span id="cb26-200"><a href="#cb26-200"></a>        <span class="cf">return</span> <span class="va">self</span>.seq_len</span>
<span id="cb26-201"><a href="#cb26-201"></a></span>
<span id="cb26-202"><a href="#cb26-202"></a>    <span class="kw">def</span> _pad_to_full_transition(<span class="va">self</span>, tokens: torch.Tensor) <span class="op">-&gt;</span> torch.Tensor:</span>
<span id="cb26-203"><a href="#cb26-203"></a>        <span class="co"># pad the tokens to full transition_dim</span></span>
<span id="cb26-204"><a href="#cb26-204"></a>        batch_size, n_tokens, _ <span class="op">=</span> tokens.shape</span>
<span id="cb26-205"><a href="#cb26-205"></a>        n_pad <span class="op">=</span> round_to_multiple(n_tokens, <span class="va">self</span>.transition_dim) <span class="op">-</span> n_tokens</span>
<span id="cb26-206"><a href="#cb26-206"></a>        padding <span class="op">=</span> torch.zeros(</span>
<span id="cb26-207"><a href="#cb26-207"></a>            batch_size, n_pad, <span class="va">self</span>.embedding_dim, device<span class="op">=</span>tokens.device</span>
<span id="cb26-208"><a href="#cb26-208"></a>        )</span>
<span id="cb26-209"><a href="#cb26-209"></a>        x_pad <span class="op">=</span> torch.cat([tokens, padding], dim<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb26-210"><a href="#cb26-210"></a>        <span class="cf">return</span> x_pad, n_pad</span>
<span id="cb26-211"><a href="#cb26-211"></a></span>
<span id="cb26-212"><a href="#cb26-212"></a>    <span class="kw">def</span> _offset_tokens(</span>
<span id="cb26-213"><a href="#cb26-213"></a>        <span class="va">self</span>, tokens: torch.Tensor, kv_caches: Optional[List] <span class="op">=</span> <span class="va">None</span></span>
<span id="cb26-214"><a href="#cb26-214"></a>    ) <span class="op">-&gt;</span> torch.Tensor:</span>
<span id="cb26-215"><a href="#cb26-215"></a>        <span class="co"># for beginners, this function may be a bit confusing. So let me explain</span></span>
<span id="cb26-216"><a href="#cb26-216"></a></span>
<span id="cb26-217"><a href="#cb26-217"></a>        <span class="co"># our input consists of transition_dim types of tokens</span></span>
<span id="cb26-218"><a href="#cb26-218"></a>        <span class="co"># and each token is from a vocab of size vocab_size. So total</span></span>
<span id="cb26-219"><a href="#cb26-219"></a>        <span class="co"># there are transition_dim * vocab_size unique tokens. In contrast</span></span>
<span id="cb26-220"><a href="#cb26-220"></a>        <span class="co"># to NLP where we have just one token type(the word) and each word</span></span>
<span id="cb26-221"><a href="#cb26-221"></a>        <span class="co"># is from a vocab of size vocab_size (50k in llama).</span></span>
<span id="cb26-222"><a href="#cb26-222"></a>        <span class="co"># So to bridge this gap, we need to project each token's local vocab</span></span>
<span id="cb26-223"><a href="#cb26-223"></a>        <span class="co"># into the global vocab space. And the way we do this is by offsetting</span></span>
<span id="cb26-224"><a href="#cb26-224"></a>        <span class="co"># each token type by a factor of vocab_size.</span></span>
<span id="cb26-225"><a href="#cb26-225"></a>        <span class="co"># eg. if we have 3 token types and vocab_size is 10, then the tokens</span></span>
<span id="cb26-226"><a href="#cb26-226"></a>        <span class="co"># will be offset by [0, 10, 20] respectively.</span></span>
<span id="cb26-227"><a href="#cb26-227"></a>        <span class="co"># given input [2, 6, 3, 1, 2, 5] and vocab_size 10,</span></span>
<span id="cb26-228"><a href="#cb26-228"></a>        <span class="co"># the output will be [2, 16, 23, 11, 12, 25]</span></span>
<span id="cb26-229"><a href="#cb26-229"></a></span>
<span id="cb26-230"><a href="#cb26-230"></a>        n_tokens <span class="op">=</span> tokens.shape[<span class="dv">1</span>] <span class="cf">if</span> kv_caches <span class="kw">is</span> <span class="va">None</span> <span class="cf">else</span> kv_caches[<span class="dv">0</span>].shape[<span class="dv">1</span>] <span class="op">+</span> <span class="dv">1</span></span>
<span id="cb26-231"><a href="#cb26-231"></a>        <span class="co"># calculate the number of transitions in the input</span></span>
<span id="cb26-232"><a href="#cb26-232"></a>        n_transition <span class="op">=</span> <span class="bu">int</span>(np.ceil(n_tokens <span class="op">/</span> <span class="va">self</span>.transition_dim))</span>
<span id="cb26-233"><a href="#cb26-233"></a></span>
<span id="cb26-234"><a href="#cb26-234"></a>        <span class="co"># if transition_dim is 4, and vocab_size is 10, then the offsets will be</span></span>
<span id="cb26-235"><a href="#cb26-235"></a>        <span class="co"># [0, 10, 20, 30]</span></span>
<span id="cb26-236"><a href="#cb26-236"></a>        <span class="co"># shape (transition_dim,)</span></span>
<span id="cb26-237"><a href="#cb26-237"></a>        offsets <span class="op">=</span> (</span>
<span id="cb26-238"><a href="#cb26-238"></a>            torch.arange(<span class="va">self</span>.transition_dim, device<span class="op">=</span>tokens.device) <span class="op">*</span> <span class="va">self</span>.vocab_size</span>
<span id="cb26-239"><a href="#cb26-239"></a>        )</span>
<span id="cb26-240"><a href="#cb26-240"></a>        <span class="co"># repeat the offset n_transition times</span></span>
<span id="cb26-241"><a href="#cb26-241"></a>        <span class="co"># shape (n_transition * transition_dim,)</span></span>
<span id="cb26-242"><a href="#cb26-242"></a>        offsets <span class="op">=</span> offsets.repeat(n_transition)</span>
<span id="cb26-243"><a href="#cb26-243"></a>        <span class="cf">if</span> kv_caches <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span>:</span>
<span id="cb26-244"><a href="#cb26-244"></a>            <span class="co"># in inference mode, we need to offset the last token only</span></span>
<span id="cb26-245"><a href="#cb26-245"></a>            offset_idx <span class="op">=</span> offsets[:n_tokens][<span class="op">-</span><span class="dv">1</span>] <span class="op">+</span> tokens</span>
<span id="cb26-246"><a href="#cb26-246"></a>        <span class="cf">else</span>:</span>
<span id="cb26-247"><a href="#cb26-247"></a>            <span class="co"># add the offsets to the tokens, and truncate the tokens to n_tokens</span></span>
<span id="cb26-248"><a href="#cb26-248"></a>            offset_idx <span class="op">=</span> offsets[:n_tokens] <span class="op">+</span> tokens</span>
<span id="cb26-249"><a href="#cb26-249"></a>        <span class="cf">return</span> offset_idx</span>
<span id="cb26-250"><a href="#cb26-250"></a></span>
<span id="cb26-251"><a href="#cb26-251"></a>    <span class="kw">def</span> forward(</span>
<span id="cb26-252"><a href="#cb26-252"></a>        <span class="va">self</span>, tokens: torch.Tensor, kv_caches: Optional[List] <span class="op">=</span> <span class="va">None</span></span>
<span id="cb26-253"><a href="#cb26-253"></a>    ) <span class="op">-&gt;</span> torch.Tensor:</span>
<span id="cb26-254"><a href="#cb26-254"></a>        <span class="co"># tokens shape (batch_size, n_tokens) in prefill mode else (batch_size, 1)</span></span>
<span id="cb26-255"><a href="#cb26-255"></a>        batch_size, n_tokens <span class="op">=</span> tokens.shape</span>
<span id="cb26-256"><a href="#cb26-256"></a>        <span class="cf">assert</span> (</span>
<span id="cb26-257"><a href="#cb26-257"></a>            n_tokens <span class="op">&lt;=</span> <span class="va">self</span>.seq_len</span>
<span id="cb26-258"><a href="#cb26-258"></a>        ), <span class="ss">f"n_tokens </span><span class="sc">{</span>n_tokens<span class="sc">}</span><span class="ss"> is greater than seq_len </span><span class="sc">{</span><span class="va">self</span><span class="sc">.</span>seq_len<span class="sc">}</span><span class="ss">"</span></span>
<span id="cb26-259"><a href="#cb26-259"></a></span>
<span id="cb26-260"><a href="#cb26-260"></a>        <span class="cf">if</span> kv_caches <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span>:</span>
<span id="cb26-261"><a href="#cb26-261"></a>            <span class="cf">assert</span> n_tokens <span class="op">==</span> <span class="dv">1</span>, <span class="st">"kv_caches can only be used with a single token"</span></span>
<span id="cb26-262"><a href="#cb26-262"></a></span>
<span id="cb26-263"><a href="#cb26-263"></a>        <span class="co"># project each token into their vocab space, this is similar to tokenization</span></span>
<span id="cb26-264"><a href="#cb26-264"></a>        <span class="co"># in NLP where we project each word into their vocab space</span></span>
<span id="cb26-265"><a href="#cb26-265"></a>        <span class="co"># (batch_size, n_tokens)</span></span>
<span id="cb26-266"><a href="#cb26-266"></a>        offset_idx <span class="op">=</span> <span class="va">self</span>._offset_tokens(tokens, kv_caches)</span>
<span id="cb26-267"><a href="#cb26-267"></a></span>
<span id="cb26-268"><a href="#cb26-268"></a>        <span class="co"># (batch_size, n_tokens) -&gt; (batch_size, n_tokens, embedding_dim)</span></span>
<span id="cb26-269"><a href="#cb26-269"></a>        tokens <span class="op">=</span> <span class="va">self</span>.token_embedding(offset_idx)</span>
<span id="cb26-270"><a href="#cb26-270"></a></span>
<span id="cb26-271"><a href="#cb26-271"></a>        <span class="cf">if</span> kv_caches <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span>:</span>
<span id="cb26-272"><a href="#cb26-272"></a>            <span class="co"># in inference mode</span></span>
<span id="cb26-273"><a href="#cb26-273"></a>            idx <span class="op">=</span> kv_caches[<span class="dv">0</span>].shape[<span class="dv">1</span>]</span>
<span id="cb26-274"><a href="#cb26-274"></a>            <span class="co"># (1, 1, embedding_dim)</span></span>
<span id="cb26-275"><a href="#cb26-275"></a>            positional_embedding <span class="op">=</span> <span class="va">self</span>.positional_embedding[:, idx : idx <span class="op">+</span> <span class="dv">1</span>]</span>
<span id="cb26-276"><a href="#cb26-276"></a>        <span class="cf">else</span>:</span>
<span id="cb26-277"><a href="#cb26-277"></a>            <span class="co"># in prefill mode</span></span>
<span id="cb26-278"><a href="#cb26-278"></a>            <span class="co"># initialize kv_caches to None</span></span>
<span id="cb26-279"><a href="#cb26-279"></a>            kv_caches <span class="op">=</span> [<span class="va">None</span> <span class="cf">for</span> _ <span class="kw">in</span> <span class="bu">range</span>(<span class="va">self</span>.n_blocks)]</span>
<span id="cb26-280"><a href="#cb26-280"></a>            <span class="co"># (1, n_tokens, embedding_dim)</span></span>
<span id="cb26-281"><a href="#cb26-281"></a>            positional_embedding <span class="op">=</span> <span class="va">self</span>.positional_embedding[:, :n_tokens]</span>
<span id="cb26-282"><a href="#cb26-282"></a></span>
<span id="cb26-283"><a href="#cb26-283"></a>        <span class="co"># (batch_size, n_tokens, embedding_dim) -&gt; (batch_size, n_tokens, embedding_dim)</span></span>
<span id="cb26-284"><a href="#cb26-284"></a>        tokens <span class="op">=</span> <span class="va">self</span>.dropout_embedding(tokens <span class="op">+</span> positional_embedding)</span>
<span id="cb26-285"><a href="#cb26-285"></a></span>
<span id="cb26-286"><a href="#cb26-286"></a>        new_kv_caches <span class="op">=</span> []</span>
<span id="cb26-287"><a href="#cb26-287"></a>        <span class="cf">for</span> block, kv_cache <span class="kw">in</span> <span class="bu">zip</span>(<span class="va">self</span>.blocks, kv_caches):</span>
<span id="cb26-288"><a href="#cb26-288"></a>            tokens, new_kv_cache <span class="op">=</span> block(tokens, kv_cache)</span>
<span id="cb26-289"><a href="#cb26-289"></a>            new_kv_caches.append(new_kv_cache)</span>
<span id="cb26-290"><a href="#cb26-290"></a></span>
<span id="cb26-291"><a href="#cb26-291"></a>        <span class="co"># (batch_size, n_tokens, embedding_dim) -&gt; (batch_size, n_tokens, embedding_dim)</span></span>
<span id="cb26-292"><a href="#cb26-292"></a>        tokens <span class="op">=</span> <span class="va">self</span>.norm(tokens)</span>
<span id="cb26-293"><a href="#cb26-293"></a></span>
<span id="cb26-294"><a href="#cb26-294"></a>        <span class="cf">if</span> <span class="va">self</span>.use_sep_heads:</span>
<span id="cb26-295"><a href="#cb26-295"></a>            <span class="co"># by using separate heads, we can route each token type to a different module</span></span>
<span id="cb26-296"><a href="#cb26-296"></a>            <span class="co"># this can be useful when each token type uses different number of bins or</span></span>
<span id="cb26-297"><a href="#cb26-297"></a>            <span class="co"># we want to give more capacity for the model to learn.</span></span>
<span id="cb26-298"><a href="#cb26-298"></a>            <span class="cf">if</span> kv_caches[<span class="dv">0</span>] <span class="kw">is</span> <span class="va">None</span>:</span>
<span id="cb26-299"><a href="#cb26-299"></a>                <span class="co"># in prefill mode, we need to calculate the logits for each token type</span></span>
<span id="cb26-300"><a href="#cb26-300"></a>                <span class="co"># (batch_size, n_tokens, embedding_dim) -&gt; (batch_size, n_tokens + n_pad, embedding_dim)</span></span>
<span id="cb26-301"><a href="#cb26-301"></a>                x_pad, n_pad <span class="op">=</span> <span class="va">self</span>._pad_to_full_transition(tokens)</span>
<span id="cb26-302"><a href="#cb26-302"></a>                <span class="co"># (batch_size, n_tokens + n_pad, vocab_size) -&gt; (batch_size * n_transitions, transition_dim, embedding_dim)</span></span>
<span id="cb26-303"><a href="#cb26-303"></a>                x_pad <span class="op">=</span> x_pad.view(<span class="op">-</span><span class="dv">1</span>, <span class="va">self</span>.transition_dim, <span class="va">self</span>.embedding_dim)</span>
<span id="cb26-304"><a href="#cb26-304"></a>                <span class="co"># (batch_size * n_transitions, transition_dim, embedding_dim) -&gt; (batch_size * n_transitions, transition_dim, vocab_size)</span></span>
<span id="cb26-305"><a href="#cb26-305"></a>                logits <span class="op">=</span> <span class="va">self</span>.fc(x_pad, model_idx<span class="op">=</span><span class="va">None</span>)</span>
<span id="cb26-306"><a href="#cb26-306"></a>                <span class="co"># (batch_size * n_transitions, transition_dim, vocab_size) -&gt; (batch_size, n_tokens + n_pad, vocab_size)</span></span>
<span id="cb26-307"><a href="#cb26-307"></a>                logits <span class="op">=</span> logits.reshape(batch_size, n_tokens <span class="op">+</span> n_pad, <span class="va">self</span>.vocab_size)</span>
<span id="cb26-308"><a href="#cb26-308"></a>                <span class="co"># truncate the logits to n_tokens</span></span>
<span id="cb26-309"><a href="#cb26-309"></a>                logits <span class="op">=</span> logits[:, :n_tokens, :]</span>
<span id="cb26-310"><a href="#cb26-310"></a>            <span class="cf">else</span>:</span>
<span id="cb26-311"><a href="#cb26-311"></a>                <span class="co"># in inference mode, we need to calculate the logits for the last token type</span></span>
<span id="cb26-312"><a href="#cb26-312"></a>                <span class="co"># infer the model index to route the token to the correct model.</span></span>
<span id="cb26-313"><a href="#cb26-313"></a>                cache_size <span class="op">=</span> kv_cache[<span class="dv">0</span>].shape[<span class="dv">1</span>]</span>
<span id="cb26-314"><a href="#cb26-314"></a>                model_idx <span class="op">=</span> cache_size <span class="op">%</span> <span class="va">self</span>.transition_dim</span>
<span id="cb26-315"><a href="#cb26-315"></a>                <span class="co"># (batch_size, 1, embedding_dim) -&gt; (batch_size, embedding_dim) -&gt; (batch_size, vocab_size) -&gt; (batch_size, 1, vocab_size)</span></span>
<span id="cb26-316"><a href="#cb26-316"></a>                logits <span class="op">=</span> <span class="va">self</span>.fc(tokens.squeeze(<span class="dv">1</span>), model_idx).unsqueeze(<span class="dv">1</span>)</span>
<span id="cb26-317"><a href="#cb26-317"></a>        <span class="cf">else</span>:</span>
<span id="cb26-318"><a href="#cb26-318"></a>            <span class="co"># (batch_size, n_tokens, embedding_dim) -&gt; (batch_size, n_tokens, vocab_size)</span></span>
<span id="cb26-319"><a href="#cb26-319"></a>            logits <span class="op">=</span> <span class="va">self</span>.fc(tokens)</span>
<span id="cb26-320"><a href="#cb26-320"></a>        <span class="cf">return</span> logits, new_kv_caches</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
</section>
</section>
<section id="sampling-techniques" class="level2" data-number="9">
<h2 data-number="9" class="anchored" data-anchor-id="sampling-techniques"><span class="header-section-number">9</span> Sampling Techniques</h2>
<p>When generating sequences in TT, selecting the next token is crucial for controlling exploration vs.&nbsp;exploitation in trajectory rollouts. The code implements three sampling strategies:</p>
<section id="greedy-sampling" class="level3" data-number="9.1">
<h3 data-number="9.1" class="anchored" data-anchor-id="greedy-sampling"><span class="header-section-number">9.1</span> Greedy Sampling</h3>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="img/offline_rl/greedy.jpeg" class="img-fluid figure-img"></p>
<figcaption><a href="https://huggingface.co/blog/how-to-generate#greedy-search">Greedy - huggingface</a></figcaption>
</figure>
</div>
<section id="how-it-works" class="level4" data-number="9.1.1">
<h4 data-number="9.1.1" class="anchored" data-anchor-id="how-it-works"><span class="header-section-number">9.1.1</span> How It Works:</h4>
<ul>
<li>Always picks the token with the highest probability (argmax).</li>
<li>No randomness; always chooses the most likely action.</li>
</ul>
</section>
<section id="pros" class="level4" data-number="9.1.2">
<h4 data-number="9.1.2" class="anchored" data-anchor-id="pros"><span class="header-section-number">9.1.2</span> Pros:</h4>
<ul>
<li>Deterministic (same input → same output).</li>
<li>Exploits the model’s knowledge effectively.</li>
</ul>
</section>
<section id="cons" class="level4" data-number="9.1.3">
<h4 data-number="9.1.3" class="anchored" data-anchor-id="cons"><span class="header-section-number">9.1.3</span> Cons:</h4>
<ul>
<li>Can lead to suboptimal decisions (local optima).</li>
<li>Lacks diversity—may get stuck in repetitive or unnatural trajectories.</li>
</ul>
</section>
<section id="use-case-in-tt" class="level4" data-number="9.1.4">
<h4 data-number="9.1.4" class="anchored" data-anchor-id="use-case-in-tt"><span class="header-section-number">9.1.4</span> Use Case in TT:</h4>
<ul>
<li>Best suited for deterministic policy rollouts where maximizing likelihood is preferred.</li>
<li>Not ideal for exploration-driven RL tasks.</li>
</ul>
</section>
</section>
<section id="top-k-sampling" class="level3" data-number="9.2">
<h3 data-number="9.2" class="anchored" data-anchor-id="top-k-sampling"><span class="header-section-number">9.2</span> Top-K Sampling</h3>
<section id="how-it-works-1" class="level4" data-number="9.2.1">
<h4 data-number="9.2.1" class="anchored" data-anchor-id="how-it-works-1"><span class="header-section-number">9.2.1</span> How It Works:</h4>
<ul>
<li>Filters logits by keeping only the top-K most probable tokens and sets the rest to -inf.</li>
<li>Sampling is then performed only among these top-K tokens.</li>
</ul>
</section>
<section id="pros-1" class="level4" data-number="9.2.2">
<h4 data-number="9.2.2" class="anchored" data-anchor-id="pros-1"><span class="header-section-number">9.2.2</span> Pros:</h4>
<ul>
<li>Reduces randomness while still allowing diversity.</li>
<li>Prevents sampling from extremely unlikely tokens.</li>
</ul>
</section>
<section id="cons-1" class="level4" data-number="9.2.3">
<h4 data-number="9.2.3" class="anchored" data-anchor-id="cons-1"><span class="header-section-number">9.2.3</span> Cons:</h4>
<ul>
<li>Limits exploration to the top-K tokens.</li>
<li>Requires tuning K—too low may restrict diversity, too high may introduce poor samples.</li>
</ul>
</section>
<section id="use-case-in-tt-1" class="level4" data-number="9.2.4">
<h4 data-number="9.2.4" class="anchored" data-anchor-id="use-case-in-tt-1"><span class="header-section-number">9.2.4</span> Use Case in TT:</h4>
<ul>
<li>Helps balance exploration and exploitation, useful in stochastic policy rollouts.</li>
<li>Ideal for trajectory prediction where diverse outcomes are needed.</li>
</ul>
</section>
</section>
<section id="temperature-scaling" class="level3" data-number="9.3">
<h3 data-number="9.3" class="anchored" data-anchor-id="temperature-scaling"><span class="header-section-number">9.3</span> Temperature Scaling</h3>
<section id="how-it-works-2" class="level4" data-number="9.3.1">
<h4 data-number="9.3.1" class="anchored" data-anchor-id="how-it-works-2"><span class="header-section-number">9.3.1</span> How It Works:</h4>
<ul>
<li>Adjusts the sharpness of the probability distribution by dividing logits by a temperature factor (T) before applying softmax.
<ul>
<li>High T (T &gt; 1.0): More uniform distribution (increases exploration).</li>
<li>Low T (T &lt; 1.0): Peaked distribution (increases exploitation).</li>
</ul></li>
</ul>
<p>By combining these techniques, TT can generate diverse, high-quality trajectories while maintaining stability and performance.</p>
<div id="cell-32" class="cell" data-execution_count="14">
<div class="sourceCode cell-code" id="cb27"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb27-1"><a href="#cb27-1"></a><span class="kw">def</span> sample_token_from_logits(</span>
<span id="cb27-2"><a href="#cb27-2"></a>    logits: torch.Tensor,</span>
<span id="cb27-3"><a href="#cb27-3"></a>    temperature: <span class="bu">float</span> <span class="op">=</span> <span class="fl">1.0</span>,</span>
<span id="cb27-4"><a href="#cb27-4"></a>    greedy: <span class="bu">bool</span> <span class="op">=</span> <span class="va">False</span>,</span>
<span id="cb27-5"><a href="#cb27-5"></a>    top_k: Optional[<span class="bu">int</span>] <span class="op">=</span> <span class="va">None</span>,</span>
<span id="cb27-6"><a href="#cb27-6"></a>) <span class="op">-&gt;</span> torch.Tensor:</span>
<span id="cb27-7"><a href="#cb27-7"></a>    <span class="co">"""</span></span>
<span id="cb27-8"><a href="#cb27-8"></a><span class="co">    This function return exactly one token from the logits.</span></span>
<span id="cb27-9"><a href="#cb27-9"></a><span class="co">    We have options to sample from the logits using</span></span>
<span id="cb27-10"><a href="#cb27-10"></a><span class="co">    1. Greedy sampling</span></span>
<span id="cb27-11"><a href="#cb27-11"></a><span class="co">    2. Top-k sampling</span></span>
<span id="cb27-12"><a href="#cb27-12"></a><span class="co">    3. Temperature scaling</span></span>
<span id="cb27-13"><a href="#cb27-13"></a></span>
<span id="cb27-14"><a href="#cb27-14"></a><span class="co">    """</span></span>
<span id="cb27-15"><a href="#cb27-15"></a>    <span class="co"># logits shape (batch_size, vocab_size) representing the logits of the next token</span></span>
<span id="cb27-16"><a href="#cb27-16"></a></span>
<span id="cb27-17"><a href="#cb27-17"></a>    <span class="co"># Apply temperature scaling, the higher the temperature, the more uniform the distribution</span></span>
<span id="cb27-18"><a href="#cb27-18"></a>    <span class="co"># the lower the temperature, the more peaked the distribution</span></span>
<span id="cb27-19"><a href="#cb27-19"></a>    <span class="cf">if</span> temperature <span class="op">!=</span> <span class="fl">1.0</span>:</span>
<span id="cb27-20"><a href="#cb27-20"></a>        logits <span class="op">=</span> logits <span class="op">/</span> temperature</span>
<span id="cb27-21"><a href="#cb27-21"></a></span>
<span id="cb27-22"><a href="#cb27-22"></a>    <span class="cf">if</span> top_k <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span>:</span>
<span id="cb27-23"><a href="#cb27-23"></a>        <span class="co"># Apply top-k sampling</span></span>
<span id="cb27-24"><a href="#cb27-24"></a>        <span class="co"># (batch_size, vocab_size) -&gt; (batch_size, top_k)</span></span>
<span id="cb27-25"><a href="#cb27-25"></a>        v, indices <span class="op">=</span> torch.topk(logits, top_k, dim<span class="op">=-</span><span class="dv">1</span>)</span>
<span id="cb27-26"><a href="#cb27-26"></a></span>
<span id="cb27-27"><a href="#cb27-27"></a>        <span class="co"># Next instruction is a bit tricky, but it simply selects the top-k tokens</span></span>
<span id="cb27-28"><a href="#cb27-28"></a>        <span class="co"># set all logits to -inf except the top-k indices</span></span>
<span id="cb27-29"><a href="#cb27-29"></a>        <span class="co"># v[:, [-1]] might be a bit confusing, but it simply selects the last element</span></span>
<span id="cb27-30"><a href="#cb27-30"></a>        <span class="co"># along dim=1, and the result is a tensor of shape (batch_size, 1)</span></span>
<span id="cb27-31"><a href="#cb27-31"></a>        logits[logits <span class="op">&lt;</span> v[:, [<span class="op">-</span><span class="dv">1</span>]]] <span class="op">=</span> <span class="op">-</span><span class="bu">float</span>(<span class="st">"Inf"</span>)</span>
<span id="cb27-32"><a href="#cb27-32"></a>    <span class="co"># Calculate the probabilities from the logits</span></span>
<span id="cb27-33"><a href="#cb27-33"></a>    probs <span class="op">=</span> F.softmax(logits, dim<span class="op">=-</span><span class="dv">1</span>)</span>
<span id="cb27-34"><a href="#cb27-34"></a>    <span class="cf">if</span> <span class="kw">not</span> greedy:</span>
<span id="cb27-35"><a href="#cb27-35"></a>        <span class="co"># Sample from the top-k indices</span></span>
<span id="cb27-36"><a href="#cb27-36"></a>        <span class="co"># (batch_size, top_k) -&gt; (batch_size, 1)</span></span>
<span id="cb27-37"><a href="#cb27-37"></a>        idx <span class="op">=</span> torch.multinomial(probs, num_samples<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb27-38"><a href="#cb27-38"></a>    <span class="cf">else</span>:</span>
<span id="cb27-39"><a href="#cb27-39"></a>        <span class="co"># Greedy sampling</span></span>
<span id="cb27-40"><a href="#cb27-40"></a>        _, idx <span class="op">=</span> torch.<span class="bu">max</span>(probs, dim<span class="op">=-</span><span class="dv">1</span>)</span>
<span id="cb27-41"><a href="#cb27-41"></a>    <span class="cf">return</span> idx</span>
<span id="cb27-42"><a href="#cb27-42"></a></span>
<span id="cb27-43"><a href="#cb27-43"></a></span>
<span id="cb27-44"><a href="#cb27-44"></a><span class="kw">def</span> sample_tokens(</span>
<span id="cb27-45"><a href="#cb27-45"></a>    model: nn.Module,</span>
<span id="cb27-46"><a href="#cb27-46"></a>    context: nn.Module,</span>
<span id="cb27-47"><a href="#cb27-47"></a>    kv_caches: Optional[List],</span>
<span id="cb27-48"><a href="#cb27-48"></a>    n_steps: <span class="bu">int</span>,</span>
<span id="cb27-49"><a href="#cb27-49"></a>    temperature: <span class="bu">float</span> <span class="op">=</span> <span class="fl">1.0</span>,</span>
<span id="cb27-50"><a href="#cb27-50"></a>    greedy: <span class="bu">bool</span> <span class="op">=</span> <span class="va">False</span>,</span>
<span id="cb27-51"><a href="#cb27-51"></a>    top_k: Optional[<span class="bu">int</span>] <span class="op">=</span> <span class="va">None</span>,</span>
<span id="cb27-52"><a href="#cb27-52"></a>) <span class="op">-&gt;</span> torch.Tensor:</span>
<span id="cb27-53"><a href="#cb27-53"></a>    <span class="co">"""</span></span>
<span id="cb27-54"><a href="#cb27-54"></a><span class="co">    Sample a sequence of tokens from the model.</span></span>
<span id="cb27-55"><a href="#cb27-55"></a></span>
<span id="cb27-56"><a href="#cb27-56"></a><span class="co">    Args:</span></span>
<span id="cb27-57"><a href="#cb27-57"></a><span class="co">        model (nn.Module): The model to sample from.</span></span>
<span id="cb27-58"><a href="#cb27-58"></a><span class="co">        context (nn.Module): The context to condition the sampling on.</span></span>
<span id="cb27-59"><a href="#cb27-59"></a><span class="co">            shape (batch_size, n_tokens).</span></span>
<span id="cb27-60"><a href="#cb27-60"></a><span class="co">        n_steps (int): The number of steps to sample.</span></span>
<span id="cb27-61"><a href="#cb27-61"></a><span class="co">        temperature (float): The temperature scaling factor.</span></span>
<span id="cb27-62"><a href="#cb27-62"></a><span class="co">        greedy (bool): Whether to sample greedily.</span></span>
<span id="cb27-63"><a href="#cb27-63"></a><span class="co">        top_k (Optional[int]): The top-k sampling parameter.</span></span>
<span id="cb27-64"><a href="#cb27-64"></a></span>
<span id="cb27-65"><a href="#cb27-65"></a><span class="co">    Returns:</span></span>
<span id="cb27-66"><a href="#cb27-66"></a><span class="co">        torch.Tensor: The sampled tokens.</span></span>
<span id="cb27-67"><a href="#cb27-67"></a><span class="co">    """</span></span>
<span id="cb27-68"><a href="#cb27-68"></a>    <span class="co"># tensor to store the logits of the next   sampled tokens</span></span>
<span id="cb27-69"><a href="#cb27-69"></a>    raw_logits <span class="op">=</span> torch.zeros(</span>
<span id="cb27-70"><a href="#cb27-70"></a>        context.shape[<span class="dv">0</span>], n_steps, vocab_size, device<span class="op">=</span>context.device</span>
<span id="cb27-71"><a href="#cb27-71"></a>    )</span>
<span id="cb27-72"><a href="#cb27-72"></a>    <span class="cf">if</span> kv_caches <span class="kw">is</span> <span class="va">None</span>:</span>
<span id="cb27-73"><a href="#cb27-73"></a>        <span class="co"># when kv_caches is None, we are in prefilling step</span></span>
<span id="cb27-74"><a href="#cb27-74"></a>        logits, kv_caches <span class="op">=</span> model(context, kv_caches)</span>
<span id="cb27-75"><a href="#cb27-75"></a>        <span class="co"># Sample the next token</span></span>
<span id="cb27-76"><a href="#cb27-76"></a>        <span class="co"># (batch_size, 1)</span></span>
<span id="cb27-77"><a href="#cb27-77"></a>        token <span class="op">=</span> sample_token_from_logits(</span>
<span id="cb27-78"><a href="#cb27-78"></a>            logits[:, <span class="op">-</span><span class="dv">1</span>], temperature<span class="op">=</span>temperature, greedy<span class="op">=</span>greedy, top_k<span class="op">=</span>top_k</span>
<span id="cb27-79"><a href="#cb27-79"></a>        )</span>
<span id="cb27-80"><a href="#cb27-80"></a></span>
<span id="cb27-81"><a href="#cb27-81"></a>        context <span class="op">=</span> torch.cat([context, token], dim<span class="op">=-</span><span class="dv">1</span>)</span>
<span id="cb27-82"><a href="#cb27-82"></a></span>
<span id="cb27-83"><a href="#cb27-83"></a>        raw_logits[:, <span class="dv">0</span>] <span class="op">=</span> logits[:, <span class="op">-</span><span class="dv">1</span>]</span>
<span id="cb27-84"><a href="#cb27-84"></a>        <span class="co"># since we already did one step, we need to sample n_steps - 1</span></span>
<span id="cb27-85"><a href="#cb27-85"></a>        steps <span class="op">=</span> <span class="bu">range</span>(<span class="dv">1</span>, n_steps)</span>
<span id="cb27-86"><a href="#cb27-86"></a>    <span class="cf">else</span>:</span>
<span id="cb27-87"><a href="#cb27-87"></a>        steps <span class="op">=</span> <span class="bu">range</span>(n_steps)</span>
<span id="cb27-88"><a href="#cb27-88"></a></span>
<span id="cb27-89"><a href="#cb27-89"></a>    <span class="cf">for</span> i <span class="kw">in</span> steps:</span>
<span id="cb27-90"><a href="#cb27-90"></a>        <span class="co"># crop the context so that it doesn't exceed the seq_len</span></span>
<span id="cb27-91"><a href="#cb27-91"></a>        curr_context_len <span class="op">=</span> context.shape[<span class="dv">1</span>]</span>
<span id="cb27-92"><a href="#cb27-92"></a>        n_crop <span class="op">=</span> round_to_multiple(</span>
<span id="cb27-93"><a href="#cb27-93"></a>            <span class="bu">max</span>(<span class="dv">0</span>, curr_context_len <span class="op">-</span> model.get_seq_len()), transition_dim</span>
<span id="cb27-94"><a href="#cb27-94"></a>        )</span>
<span id="cb27-95"><a href="#cb27-95"></a>        <span class="cf">if</span> n_crop <span class="op">&gt;</span> <span class="dv">0</span>:</span>
<span id="cb27-96"><a href="#cb27-96"></a>            <span class="co"># since we are cropping from the left, we need to update the kv_caches</span></span>
<span id="cb27-97"><a href="#cb27-97"></a>            kv_caches <span class="op">=</span> [kv[:, n_crop:] <span class="cf">for</span> kv <span class="kw">in</span> kv_caches]</span>
<span id="cb27-98"><a href="#cb27-98"></a>        <span class="co"># Get the model's prediction</span></span>
<span id="cb27-99"><a href="#cb27-99"></a>        <span class="co"># (batch_size, 1) -&gt; (batch_size, 1, vocab_size)</span></span>
<span id="cb27-100"><a href="#cb27-100"></a>        logits, kv_caches <span class="op">=</span> model(context[:, <span class="op">-</span><span class="dv">1</span>:], kv_caches)</span>
<span id="cb27-101"><a href="#cb27-101"></a>        <span class="co"># Sample the next token</span></span>
<span id="cb27-102"><a href="#cb27-102"></a>        <span class="co"># (batch_size, 1)</span></span>
<span id="cb27-103"><a href="#cb27-103"></a>        token <span class="op">=</span> sample_token_from_logits(</span>
<span id="cb27-104"><a href="#cb27-104"></a>            logits[:, <span class="op">-</span><span class="dv">1</span>], temperature<span class="op">=</span>temperature, greedy<span class="op">=</span>greedy, top_k<span class="op">=</span>top_k</span>
<span id="cb27-105"><a href="#cb27-105"></a>        )</span>
<span id="cb27-106"><a href="#cb27-106"></a></span>
<span id="cb27-107"><a href="#cb27-107"></a>        context <span class="op">=</span> torch.cat([context, token], dim<span class="op">=-</span><span class="dv">1</span>)</span>
<span id="cb27-108"><a href="#cb27-108"></a></span>
<span id="cb27-109"><a href="#cb27-109"></a>        raw_logits[:, i] <span class="op">=</span> logits[:, <span class="op">-</span><span class="dv">1</span>]</span>
<span id="cb27-110"><a href="#cb27-110"></a>    <span class="cf">return</span> context, kv_caches, raw_logits</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
</section>
</section>
<section id="beam-search" class="level2" data-number="10">
<h2 data-number="10" class="anchored" data-anchor-id="beam-search"><span class="header-section-number">10</span> Beam Search</h2>
<p>Beam search is a search algorithm used in sequence generation tasks (e.g., NLP, trajectory modeling) to find the most probable sequence by maintaining multiple candidate sequences (beams) at each step. Instead of greedily picking the best token at each step (as in greedy decoding), beam search explores multiple top-k candidates, allowing better long-horizon decision-making.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="img/offline_rl/beam_search.png" class="img-fluid figure-img"></p>
<figcaption><a href="https://huggingface.co/blog/how-to-generate#beam-search">beam search - huggingface</a></figcaption>
</figure>
</div>
<p>In TT, beam search is used to generate high-reward trajectories by optimizing reward-to-go (RTG) during rollout. The goal is to predict future actions that maximize cumulative rewards.</p>
<section id="how-beam-search-works-in-tt" class="level3" data-number="10.1">
<h3 data-number="10.1" class="anchored" data-anchor-id="how-beam-search-works-in-tt"><span class="header-section-number">10.1</span> How Beam Search Works in TT:</h3>
<ol type="1">
<li><strong>Initialize multiple beams</strong>: Start with an initial state and maintain multiple possible trajectory candidates.</li>
<li><strong>Expand beams</strong>: At each step, sample the top-k most probable tokens (actions) based on model predictions.</li>
<li><strong>Score beams</strong>: Rank the expanded beams using reward-to-go (RTG) as the scoring function.</li>
<li><strong>Prune beams</strong>: Keep only the top-k highest-scoring beams, discarding the rest.</li>
<li><strong>Repeat until termination</strong>: Continue the process until a trajectory reaches the desired length or terminal state.</li>
</ol>
<p>The implementation may appear complex because it supports vectorized/batched beam search, meaning the context tensor’s first dimension represents <code>batch_size</code>. This allows multiple independent rollouts to be processed in parallel, significantly improving efficiency.</p>
</section>
<section id="understanding-stochasticity-in-beam-search" class="level3" data-number="10.2">
<h3 data-number="10.2" class="anchored" data-anchor-id="understanding-stochasticity-in-beam-search"><span class="header-section-number">10.2</span> Understanding Stochasticity in Beam Search</h3>
<p>Beam search is typically deterministic, but in TT, stochasticity is introduced through parameters like:</p>
<ul>
<li><strong>obs_top_k, act_top_k, rew_top_k</strong>: Restrict the set of sampled tokens to the top-k most probable ones, controlling exploration.</li>
<li><strong>temperature</strong>: Adjusts how uniform or peaked the probability distribution is. Higher values encourage exploration, lower values favor exploitation.</li>
<li><strong>greedy</strong>: If <code>True</code>, always picks the most probable token (deterministic); otherwise, sampling introduces randomness.</li>
</ul>
<section id="key-clarification" class="level4" data-number="10.2.1">
<h4 data-number="10.2.1" class="anchored" data-anchor-id="key-clarification"><span class="header-section-number">10.2.1</span> Key Clarification:</h4>
<ul>
<li><strong>Higher stochasticity</strong>: More diverse plans are explored.</li>
<li><strong>Lower stochasticity</strong>: The model converges to a narrower, more deterministic trajectory.</li>
</ul>
</section>
</section>
<section id="beam-search-objectives-in-tt" class="level3" data-number="10.3">
<h3 data-number="10.3" class="anchored" data-anchor-id="beam-search-objectives-in-tt"><span class="header-section-number">10.3</span> Beam Search Objectives in TT</h3>
<p>Beam search in TT can be performed based on different objectives:</p>
<section id="reward-maximization-implemented-here" class="level4" data-number="10.3.1">
<h4 data-number="10.3.1" class="anchored" data-anchor-id="reward-maximization-implemented-here"><span class="header-section-number">10.3.1</span> Reward Maximization (Implemented Here)</h4>
<ul>
<li>Selects plans that maximize Reward-to-Go (RTG).</li>
<li>The search prioritizes high-return trajectories, making this useful for decision-time planning in offline RL.</li>
</ul>
</section>
<section id="policy-cloning-alternative-objective" class="level4" data-number="10.3.2">
<h4 data-number="10.3.2" class="anchored" data-anchor-id="policy-cloning-alternative-objective"><span class="header-section-number">10.3.2</span> Policy Cloning (Alternative Objective)</h4>
<ul>
<li>Mimics the dataset used to train TT.</li>
<li>Instead of maximizing rewards, the model selects the most likely action from its learned distribution.</li>
<li>Achieved by maximizing action likelihood rather than RTG.</li>
<li>This effectively reproduces the behavior of the dataset, rather than searching for the highest return.</li>
</ul>
<div id="cell-34" class="cell">
<div class="sourceCode cell-code" id="cb28"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb28-1"><a href="#cb28-1"></a><span class="co"># This functions are probably the most important functions in this notebook and</span></span>
<span id="cb28-2"><a href="#cb28-2"></a><span class="co"># also the most complex.</span></span>
<span id="cb28-3"><a href="#cb28-3"></a></span>
<span id="cb28-4"><a href="#cb28-4"></a></span>
<span id="cb28-5"><a href="#cb28-5"></a><span class="kw">def</span> vec_beam_plan(</span>
<span id="cb28-6"><a href="#cb28-6"></a>    model: nn.Module,</span>
<span id="cb28-7"><a href="#cb28-7"></a>    discretizer: KBinsDiscretizer,</span>
<span id="cb28-8"><a href="#cb28-8"></a>    context: torch.Tensor,</span>
<span id="cb28-9"><a href="#cb28-9"></a>    beam_width: <span class="bu">int</span>,</span>
<span id="cb28-10"><a href="#cb28-10"></a>    beam_steps: <span class="bu">int</span>,</span>
<span id="cb28-11"><a href="#cb28-11"></a>    beam_context: <span class="bu">int</span>,</span>
<span id="cb28-12"><a href="#cb28-12"></a>    sample_expansion: <span class="bu">int</span>,</span>
<span id="cb28-13"><a href="#cb28-13"></a>    observation_dim: <span class="bu">int</span>,</span>
<span id="cb28-14"><a href="#cb28-14"></a>    action_dim: <span class="bu">int</span>,</span>
<span id="cb28-15"><a href="#cb28-15"></a>    reward_dim: <span class="bu">int</span>,</span>
<span id="cb28-16"><a href="#cb28-16"></a>    value_dim: <span class="bu">int</span>,</span>
<span id="cb28-17"><a href="#cb28-17"></a>    transition_dim: <span class="bu">int</span>,</span>
<span id="cb28-18"><a href="#cb28-18"></a>    obs_top_k: Optional[<span class="bu">int</span>] <span class="op">=</span> <span class="va">None</span>,</span>
<span id="cb28-19"><a href="#cb28-19"></a>    act_top_k: Optional[<span class="bu">int</span>] <span class="op">=</span> <span class="va">None</span>,</span>
<span id="cb28-20"><a href="#cb28-20"></a>    rew_top_k: Optional[<span class="bu">int</span>] <span class="op">=</span> <span class="va">None</span>,</span>
<span id="cb28-21"><a href="#cb28-21"></a>    temperature: <span class="bu">float</span> <span class="op">=</span> <span class="fl">1.0</span>,</span>
<span id="cb28-22"><a href="#cb28-22"></a>    greedy: <span class="bu">bool</span> <span class="op">=</span> <span class="va">False</span>,</span>
<span id="cb28-23"><a href="#cb28-23"></a>) <span class="op">-&gt;</span> torch.Tensor:</span>
<span id="cb28-24"><a href="#cb28-24"></a>    <span class="co">"""</span></span>
<span id="cb28-25"><a href="#cb28-25"></a><span class="co">    In the most simplest terms, this function is responsible for planning a sequence of actions</span></span>
<span id="cb28-26"><a href="#cb28-26"></a><span class="co">    that maximizes the expected rewards conditioned on the context.</span></span>
<span id="cb28-27"><a href="#cb28-27"></a></span>
<span id="cb28-28"><a href="#cb28-28"></a><span class="co">    It uses beam search to explore the space of possible plans. Beam search is a heuristic search</span></span>
<span id="cb28-29"><a href="#cb28-29"></a><span class="co">    algorithm that explores a graph by expanding the most promising nodes in a limited set called the beam.</span></span>
<span id="cb28-30"><a href="#cb28-30"></a></span>
<span id="cb28-31"><a href="#cb28-31"></a><span class="co">    The concept of beam search is simple, but the implementation can be a bit tricky mainly because</span></span>
<span id="cb28-32"><a href="#cb28-32"></a><span class="co">    we are processing multiple sequences in parallel. This is where the complexity comes from.</span></span>
<span id="cb28-33"><a href="#cb28-33"></a><span class="co">    """</span></span>
<span id="cb28-34"><a href="#cb28-34"></a>    batch_size <span class="op">=</span> context.shape[<span class="dv">0</span>]</span>
<span id="cb28-35"><a href="#cb28-35"></a>    tokens_context_size <span class="op">=</span> beam_context <span class="op">*</span> transition_dim</span>
<span id="cb28-36"><a href="#cb28-36"></a>    n_crop <span class="op">=</span> round_to_multiple(</span>
<span id="cb28-37"><a href="#cb28-37"></a>        <span class="bu">max</span>(<span class="dv">0</span>, context.shape[<span class="dv">1</span>] <span class="op">-</span> tokens_context_size), transition_dim</span>
<span id="cb28-38"><a href="#cb28-38"></a>    )</span>
<span id="cb28-39"><a href="#cb28-39"></a>    context <span class="op">=</span> context[:, n_crop:]</span>
<span id="cb28-40"><a href="#cb28-40"></a>    <span class="co"># context shape (batch_size, seq_len) -&gt; (beam_width, beam_width, seq_len)</span></span>
<span id="cb28-41"><a href="#cb28-41"></a>    plan <span class="op">=</span> context.unsqueeze(<span class="dv">1</span>).repeat(<span class="dv">1</span>, beam_width, <span class="dv">1</span>)</span>
<span id="cb28-42"><a href="#cb28-42"></a></span>
<span id="cb28-43"><a href="#cb28-43"></a>    <span class="co"># tensor to store the rewards obtained from environment</span></span>
<span id="cb28-44"><a href="#cb28-44"></a>    <span class="co"># the +1 is non-intuitive, but it is because we need to store the value at t+1</span></span>
<span id="cb28-45"><a href="#cb28-45"></a>    <span class="co"># you will see this later.</span></span>
<span id="cb28-46"><a href="#cb28-46"></a>    rewards <span class="op">=</span> torch.zeros(batch_size, beam_width, beam_steps <span class="op">+</span> <span class="dv">1</span>, device<span class="op">=</span>context.device)</span>
<span id="cb28-47"><a href="#cb28-47"></a>    discounts <span class="op">=</span> discount_factor <span class="op">**</span> torch.arange(beam_steps <span class="op">+</span> <span class="dv">1</span>, device<span class="op">=</span>context.device)</span>
<span id="cb28-48"><a href="#cb28-48"></a></span>
<span id="cb28-49"><a href="#cb28-49"></a>    <span class="co"># because beam plan start with a fresh context, we need to prefill the model</span></span>
<span id="cb28-50"><a href="#cb28-50"></a>    <span class="co"># first with the context, hence kv_caches is None</span></span>
<span id="cb28-51"><a href="#cb28-51"></a>    kv_caches <span class="op">=</span> <span class="va">None</span></span>
<span id="cb28-52"><a href="#cb28-52"></a>    <span class="cf">for</span> t <span class="kw">in</span> trange(beam_steps, desc<span class="op">=</span><span class="st">"Beam Search"</span>, leave<span class="op">=</span><span class="va">False</span>):</span>
<span id="cb28-53"><a href="#cb28-53"></a>        <span class="co"># sample_expansion is not strictly necessary, but it is used to increase the number of samples</span></span>
<span id="cb28-54"><a href="#cb28-54"></a>        <span class="co">#   which should allow us to explore more diverse plans. The reason this works is because the way</span></span>
<span id="cb28-55"><a href="#cb28-55"></a>        <span class="co">#   we sample tokens is stochastic, so by sampling more tokens, we are able to explore more diverse plans.</span></span>
<span id="cb28-56"><a href="#cb28-56"></a>        <span class="co"># (batch_size, beam_width, n_tokens) -&gt; (batch_size, beam_width * sample_expansion, n_tokens)</span></span>
<span id="cb28-57"><a href="#cb28-57"></a>        <span class="co">#   -&gt; (batch_size * beam_width * sample_expansion, n_tokens)</span></span>
<span id="cb28-58"><a href="#cb28-58"></a>        plan <span class="op">=</span> plan.repeat(<span class="dv">1</span>, sample_expansion, <span class="dv">1</span>).flatten(<span class="dv">0</span>, <span class="dv">1</span>)</span>
<span id="cb28-59"><a href="#cb28-59"></a>        <span class="co"># (batch_size, beam_width, beam_steps + 1) -&gt; (batch_size * beam_width * sample_expansion, beam_steps + 1)</span></span>
<span id="cb28-60"><a href="#cb28-60"></a>        rewards <span class="op">=</span> rewards.repeat(<span class="dv">1</span>, sample_expansion, <span class="dv">1</span>).flatten(<span class="dv">0</span>, <span class="dv">1</span>)</span>
<span id="cb28-61"><a href="#cb28-61"></a></span>
<span id="cb28-62"><a href="#cb28-62"></a>        <span class="cf">if</span> kv_caches <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span>:</span>
<span id="cb28-63"><a href="#cb28-63"></a>            <span class="co"># When we are in inference mode, we need to expand the kv_caches</span></span>
<span id="cb28-64"><a href="#cb28-64"></a>            <span class="co"># (batch_size * beam_width, n_tokens, embedding_dim) -&gt; (batch_size * beam_width * sample_expansion, n_tokens, embedding_dim)</span></span>
<span id="cb28-65"><a href="#cb28-65"></a>            new_kv_caches <span class="op">=</span> []</span>
<span id="cb28-66"><a href="#cb28-66"></a>            <span class="cf">for</span> kv <span class="kw">in</span> kv_caches:</span>
<span id="cb28-67"><a href="#cb28-67"></a>                _, n_tokens, embedding_dim <span class="op">=</span> kv.shape</span>
<span id="cb28-68"><a href="#cb28-68"></a>                new_kv_cache <span class="op">=</span> (</span>
<span id="cb28-69"><a href="#cb28-69"></a>                    kv.view(batch_size, beam_width, n_tokens, embedding_dim)</span>
<span id="cb28-70"><a href="#cb28-70"></a>                    .repeat(<span class="dv">1</span>, sample_expansion, <span class="dv">1</span>, <span class="dv">1</span>)</span>
<span id="cb28-71"><a href="#cb28-71"></a>                    .flatten(<span class="dv">0</span>, <span class="dv">1</span>)</span>
<span id="cb28-72"><a href="#cb28-72"></a>                )</span>
<span id="cb28-73"><a href="#cb28-73"></a>                new_kv_caches.append(new_kv_cache)</span>
<span id="cb28-74"><a href="#cb28-74"></a>            kv_caches <span class="op">=</span> new_kv_caches</span>
<span id="cb28-75"><a href="#cb28-75"></a></span>
<span id="cb28-76"><a href="#cb28-76"></a>        <span class="co"># sample actions</span></span>
<span id="cb28-77"><a href="#cb28-77"></a>        <span class="co"># plan (batch_size * beam_width * sample_expansion, n_tokens) -&gt; (batch_size * beam_width * sample_expansion, n_tokens + action_dim)</span></span>
<span id="cb28-78"><a href="#cb28-78"></a>        <span class="co"># kv_caches is updated with the new action tokens</span></span>
<span id="cb28-79"><a href="#cb28-79"></a>        plan, kv_caches, _ <span class="op">=</span> sample_tokens(</span>
<span id="cb28-80"><a href="#cb28-80"></a>            model,</span>
<span id="cb28-81"><a href="#cb28-81"></a>            plan,</span>
<span id="cb28-82"><a href="#cb28-82"></a>            kv_caches,</span>
<span id="cb28-83"><a href="#cb28-83"></a>            n_steps<span class="op">=</span>action_dim,</span>
<span id="cb28-84"><a href="#cb28-84"></a>            top_k<span class="op">=</span>act_top_k,</span>
<span id="cb28-85"><a href="#cb28-85"></a>            temperature<span class="op">=</span>temperature,</span>
<span id="cb28-86"><a href="#cb28-86"></a>            greedy<span class="op">=</span>greedy,</span>
<span id="cb28-87"><a href="#cb28-87"></a>        )</span>
<span id="cb28-88"><a href="#cb28-88"></a></span>
<span id="cb28-89"><a href="#cb28-89"></a>        <span class="co"># sample rewards and values</span></span>
<span id="cb28-90"><a href="#cb28-90"></a>        <span class="co"># plan (batch_size * beam_width * sample_expansion, n_tokens) -&gt; (batch_size * beam_width * sample_expansion, n_tokens + reward_dim + value_dim)</span></span>
<span id="cb28-91"><a href="#cb28-91"></a>        <span class="co"># kv_caches is updated with the new reward and value tokens</span></span>
<span id="cb28-92"><a href="#cb28-92"></a>        <span class="co"># logits shape (batch_size * beam_width * sample_expansion, reward_dim + value_dim, vocab_size)</span></span>
<span id="cb28-93"><a href="#cb28-93"></a>        plan, kv_caches, logits <span class="op">=</span> sample_tokens(</span>
<span id="cb28-94"><a href="#cb28-94"></a>            model,</span>
<span id="cb28-95"><a href="#cb28-95"></a>            plan,</span>
<span id="cb28-96"><a href="#cb28-96"></a>            kv_caches,</span>
<span id="cb28-97"><a href="#cb28-97"></a>            n_steps<span class="op">=</span>reward_dim <span class="op">+</span> value_dim,</span>
<span id="cb28-98"><a href="#cb28-98"></a>            top_k<span class="op">=</span>rew_top_k,</span>
<span id="cb28-99"><a href="#cb28-99"></a>            temperature<span class="op">=</span>temperature,</span>
<span id="cb28-100"><a href="#cb28-100"></a>            greedy<span class="op">=</span>greedy,</span>
<span id="cb28-101"><a href="#cb28-101"></a>        )</span>
<span id="cb28-102"><a href="#cb28-102"></a></span>
<span id="cb28-103"><a href="#cb28-103"></a>        <span class="co"># calculate probabilities from logits</span></span>
<span id="cb28-104"><a href="#cb28-104"></a>        probs <span class="op">=</span> F.softmax(logits, dim<span class="op">=-</span><span class="dv">1</span>)</span>
<span id="cb28-105"><a href="#cb28-105"></a></span>
<span id="cb28-106"><a href="#cb28-106"></a>        <span class="co"># calculate the expected rewards and values</span></span>
<span id="cb28-107"><a href="#cb28-107"></a>        <span class="co"># (batch_size * beam_width * sample_expansion, reward_dim + value_dim, vocab_size)</span></span>
<span id="cb28-108"><a href="#cb28-108"></a>        <span class="co">#   -&gt; (batch_size * beam_width * sample_expansion, reward_dim + value_dim)</span></span>
<span id="cb28-109"><a href="#cb28-109"></a>        rewards_and_values <span class="op">=</span> discretizer.expectation(</span>
<span id="cb28-110"><a href="#cb28-110"></a>            probs, subslice<span class="op">=</span>(transition_dim <span class="op">-</span> reward_dim <span class="op">-</span> value_dim, transition_dim)</span>
<span id="cb28-111"><a href="#cb28-111"></a>        )</span>
<span id="cb28-112"><a href="#cb28-112"></a></span>
<span id="cb28-113"><a href="#cb28-113"></a>        rewards[..., t : t <span class="op">+</span> reward_dim <span class="op">+</span> value_dim] <span class="op">=</span> rewards_and_values</span>
<span id="cb28-114"><a href="#cb28-114"></a>        <span class="co"># Did you notice that rewards contains rewards at t and values at t+1, why?</span></span>
<span id="cb28-115"><a href="#cb28-115"></a>        <span class="co">#   This is only a trick to make it easier to calculate the value at t. In the next step, the value at t+1</span></span>
<span id="cb28-116"><a href="#cb28-116"></a>        <span class="co">#   will be overwritten by the actual reward at t+1.</span></span>
<span id="cb28-117"><a href="#cb28-117"></a></span>
<span id="cb28-118"><a href="#cb28-118"></a>        <span class="co"># Let's talk about how we calculate the value, the value here represents the rewards to go starting beginning of beam plan.</span></span>
<span id="cb28-119"><a href="#cb28-119"></a>        <span class="co">#   when we want to calculate value (rewards to go) at t, we need to consider discounted rewards from 0 to t</span></span>
<span id="cb28-120"><a href="#cb28-120"></a>        <span class="co">#   and also future discounted rewards from t+1 to end.</span></span>
<span id="cb28-121"><a href="#cb28-121"></a>        <span class="co"># (batch_size * beam_width * sample_expansion, beam_steps + 1) * (beam_steps + 1) -&gt; (batch_size * beam_width * sample_expansion)</span></span>
<span id="cb28-122"><a href="#cb28-122"></a>        <span class="co"># the reason we care of values is that it helps us to select the best plans</span></span>
<span id="cb28-123"><a href="#cb28-123"></a>        values <span class="op">=</span> (rewards <span class="op">*</span> discounts).<span class="bu">sum</span>(dim<span class="op">=-</span><span class="dv">1</span>)</span>
<span id="cb28-124"><a href="#cb28-124"></a></span>
<span id="cb28-125"><a href="#cb28-125"></a>        <span class="co"># select the top-k values</span></span>
<span id="cb28-126"><a href="#cb28-126"></a>        values, idx <span class="op">=</span> torch.topk(values.view(batch_size, <span class="op">-</span><span class="dv">1</span>), k<span class="op">=</span>beam_width, dim<span class="op">=-</span><span class="dv">1</span>)</span>
<span id="cb28-127"><a href="#cb28-127"></a>        <span class="co"># (batch_size, beam_width) -&gt; (batch_size, beam_width, 1)</span></span>
<span id="cb28-128"><a href="#cb28-128"></a>        idx <span class="op">=</span> idx.unsqueeze(<span class="op">-</span><span class="dv">1</span>)</span>
<span id="cb28-129"><a href="#cb28-129"></a></span>
<span id="cb28-130"><a href="#cb28-130"></a>        <span class="co"># shape (batch_size * beam_width * sample_expansion, beam_steps + 1) -&gt; (batch_size, beam_width * sample_expansion, beam_steps + 1)</span></span>
<span id="cb28-131"><a href="#cb28-131"></a>        rewards <span class="op">=</span> rewards.view(batch_size, beam_width <span class="op">*</span> sample_expansion, <span class="op">-</span><span class="dv">1</span>)</span>
<span id="cb28-132"><a href="#cb28-132"></a></span>
<span id="cb28-133"><a href="#cb28-133"></a>        <span class="co"># the gather operation is a bit tricky, but it is used to select the rewards corresponding to the top-k values</span></span>
<span id="cb28-134"><a href="#cb28-134"></a>        <span class="co"># for every batch, select the rewards corresponding to the top-k values</span></span>
<span id="cb28-135"><a href="#cb28-135"></a>        <span class="co"># since idx contains the indices along the beam_width * sample_expansion dimension</span></span>
<span id="cb28-136"><a href="#cb28-136"></a>        <span class="co"># we need to repeat the idx along the last dimension to match the rewards shape,</span></span>
<span id="cb28-137"><a href="#cb28-137"></a>        <span class="co"># and then use it to select the rewards</span></span>
<span id="cb28-138"><a href="#cb28-138"></a>        <span class="co"># (batch_size, beam_width * sample_expansion, beam_steps + 1) -&gt; (batch_size, beam_width, beam_steps + 1)</span></span>
<span id="cb28-139"><a href="#cb28-139"></a>        rewards <span class="op">=</span> torch.gather(rewards, <span class="dv">1</span>, idx.repeat(<span class="dv">1</span>, <span class="dv">1</span>, beam_steps <span class="op">+</span> <span class="dv">1</span>))</span>
<span id="cb28-140"><a href="#cb28-140"></a></span>
<span id="cb28-141"><a href="#cb28-141"></a>        <span class="co"># select the top-k plans</span></span>
<span id="cb28-142"><a href="#cb28-142"></a>        <span class="co"># shape (batch_size * beam_width * sample_expansion, n_tokens) -&gt; (batch_size, beam_width * sample_expansion, n_tokens)</span></span>
<span id="cb28-143"><a href="#cb28-143"></a>        plan <span class="op">=</span> plan.view(batch_size, beam_width <span class="op">*</span> sample_expansion, <span class="op">-</span><span class="dv">1</span>)</span>
<span id="cb28-144"><a href="#cb28-144"></a>        <span class="co"># shape (batch_size, beam_width * sample_expansion, n_tokens) -&gt; (batch_size, beam_width, n_tokens)</span></span>
<span id="cb28-145"><a href="#cb28-145"></a>        plan <span class="op">=</span> torch.gather(plan, <span class="dv">1</span>, idx.repeat(<span class="dv">1</span>, <span class="dv">1</span>, plan.shape[<span class="op">-</span><span class="dv">1</span>]))</span>
<span id="cb28-146"><a href="#cb28-146"></a></span>
<span id="cb28-147"><a href="#cb28-147"></a>        <span class="co"># select the top-k kv_caches</span></span>
<span id="cb28-148"><a href="#cb28-148"></a>        best_kv_caches <span class="op">=</span> []</span>
<span id="cb28-149"><a href="#cb28-149"></a>        <span class="cf">for</span> kv <span class="kw">in</span> kv_caches:</span>
<span id="cb28-150"><a href="#cb28-150"></a>            _, n_tokens, embedding_dim <span class="op">=</span> kv.shape</span>
<span id="cb28-151"><a href="#cb28-151"></a>            kv <span class="op">=</span> kv.view(</span>
<span id="cb28-152"><a href="#cb28-152"></a>                batch_size, beam_width <span class="op">*</span> sample_expansion, n_tokens, embedding_dim</span>
<span id="cb28-153"><a href="#cb28-153"></a>            )</span>
<span id="cb28-154"><a href="#cb28-154"></a>            <span class="co"># same idea as above, repeat idx along the last 2 dimensions</span></span>
<span id="cb28-155"><a href="#cb28-155"></a>            <span class="co"># kv shape (batch_size, beam_width * sample_expansion, n_tokens, embedding_dim) -&gt; (batch_size, beam_width, n_tokens, embedding_dim)</span></span>
<span id="cb28-156"><a href="#cb28-156"></a>            kv <span class="op">=</span> torch.gather(</span>
<span id="cb28-157"><a href="#cb28-157"></a>                kv, <span class="dv">1</span>, idx.unsqueeze(<span class="op">-</span><span class="dv">1</span>).repeat(<span class="dv">1</span>, <span class="dv">1</span>, n_tokens, embedding_dim)</span>
<span id="cb28-158"><a href="#cb28-158"></a>            )</span>
<span id="cb28-159"><a href="#cb28-159"></a>            best_kv_caches.append(kv.flatten(<span class="dv">0</span>, <span class="dv">1</span>))</span>
<span id="cb28-160"><a href="#cb28-160"></a></span>
<span id="cb28-161"><a href="#cb28-161"></a>        <span class="cf">if</span> t <span class="op">&lt;</span> beam_steps <span class="op">-</span> <span class="dv">1</span>:</span>
<span id="cb28-162"><a href="#cb28-162"></a>            <span class="co"># sample observations only if we are not at the last step, why?</span></span>
<span id="cb28-163"><a href="#cb28-163"></a>            <span class="co"># because beam plan has to end with a valid transition [...., obs, act, rew, val]</span></span>
<span id="cb28-164"><a href="#cb28-164"></a></span>
<span id="cb28-165"><a href="#cb28-165"></a>            <span class="co"># plan (batch_size, beam_width, n_tokens) -&gt; (batch_size * beam_width, n_tokens)</span></span>
<span id="cb28-166"><a href="#cb28-166"></a>            plan <span class="op">=</span> plan.view(batch_size <span class="op">*</span> beam_width, <span class="op">-</span><span class="dv">1</span>)</span>
<span id="cb28-167"><a href="#cb28-167"></a></span>
<span id="cb28-168"><a href="#cb28-168"></a>            <span class="co"># sample observations</span></span>
<span id="cb28-169"><a href="#cb28-169"></a>            <span class="co"># plan (batch_size * beam_width, n_tokens) -&gt; (batch_size * beam_width, n_tokens + observation_dim)</span></span>
<span id="cb28-170"><a href="#cb28-170"></a>            plan, kv_caches, _ <span class="op">=</span> sample_tokens(</span>
<span id="cb28-171"><a href="#cb28-171"></a>                model,</span>
<span id="cb28-172"><a href="#cb28-172"></a>                plan,</span>
<span id="cb28-173"><a href="#cb28-173"></a>                best_kv_caches,</span>
<span id="cb28-174"><a href="#cb28-174"></a>                n_steps<span class="op">=</span>observation_dim,</span>
<span id="cb28-175"><a href="#cb28-175"></a>                top_k<span class="op">=</span>obs_top_k,</span>
<span id="cb28-176"><a href="#cb28-176"></a>                temperature<span class="op">=</span>temperature,</span>
<span id="cb28-177"><a href="#cb28-177"></a>                greedy<span class="op">=</span>greedy,</span>
<span id="cb28-178"><a href="#cb28-178"></a>            )</span>
<span id="cb28-179"><a href="#cb28-179"></a>            <span class="co"># plan (batch_size * beam_width, n_tokens + observation_dim) -&gt; (batch_size, beam_width, n_tokens + observation_dim)</span></span>
<span id="cb28-180"><a href="#cb28-180"></a>            plan <span class="op">=</span> plan.view(batch_size, beam_width, <span class="op">-</span><span class="dv">1</span>)</span>
<span id="cb28-181"><a href="#cb28-181"></a></span>
<span id="cb28-182"><a href="#cb28-182"></a>    <span class="co"># (batch_size, beam_width) -&gt; (batch_size)</span></span>
<span id="cb28-183"><a href="#cb28-183"></a>    <span class="co"># for each batch, select the plan with the highest value and return it's index</span></span>
<span id="cb28-184"><a href="#cb28-184"></a>    argmax <span class="op">=</span> torch.argmax(values, dim<span class="op">=-</span><span class="dv">1</span>)</span>
<span id="cb28-185"><a href="#cb28-185"></a></span>
<span id="cb28-186"><a href="#cb28-186"></a>    <span class="co"># select the best plan</span></span>
<span id="cb28-187"><a href="#cb28-187"></a>    <span class="co"># (batch_size, beam_width, n_tokens) -&gt; (batch_size, n_tokens)</span></span>
<span id="cb28-188"><a href="#cb28-188"></a>    best_plan <span class="op">=</span> plan[torch.arange(batch_size), argmax]</span>
<span id="cb28-189"><a href="#cb28-189"></a>    <span class="co"># filter out the context tokens and return the best plan as obtained from the beam search</span></span>
<span id="cb28-190"><a href="#cb28-190"></a>    best_plan <span class="op">=</span> best_plan[:, context.shape[<span class="dv">1</span>] :]</span>
<span id="cb28-191"><a href="#cb28-191"></a>    <span class="cf">return</span> best_plan</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
</section>
</section>
<section id="rollout" class="level2" data-number="11">
<h2 data-number="11" class="anchored" data-anchor-id="rollout"><span class="header-section-number">11</span> Rollout</h2>
<p>A rollout in TT is the process of generating a trajectory by sampling actions, predicting future states and rewards, and interacting with the environment. The model acts as a policy, guiding decision-making by simulating future transitions based on its learned distribution of trajectories.</p>
<section id="in-the-context-of-tt-rollouts-are-used-to" class="level3" data-number="11.1">
<h3 data-number="11.1" class="anchored" data-anchor-id="in-the-context-of-tt-rollouts-are-used-to"><span class="header-section-number">11.1</span> In the context of TT, rollouts are used to:</h3>
<ul>
<li>Evaluate learned policies in an environment.</li>
<li>Simulate future trajectories without interacting with the real world (important in offline RL).</li>
<li>Plan actions over multiple time steps using beam search.</li>
</ul>
</section>
<section id="how-a-rollout-uses-the-policy-model-beam-search" class="level3" data-number="11.2">
<h3 data-number="11.2" class="anchored" data-anchor-id="how-a-rollout-uses-the-policy-model-beam-search"><span class="header-section-number">11.2</span> How a Rollout Uses the Policy Model &amp; Beam Search</h3>
<p>During a rollout, TT acts as a policy model, generating actions step-by-step in an autoregressive manner. The key steps are:</p>
<section id="conditioning-on-context" class="level4" data-number="11.2.1">
<h4 data-number="11.2.1" class="anchored" data-anchor-id="conditioning-on-context"><span class="header-section-number">11.2.1</span> Conditioning on Context</h4>
<ul>
<li>The rollout starts with a history of past states, actions, and rewards (context).</li>
<li>This context is stored in a sequence of discrete tokens.</li>
</ul>
</section>
<section id="predicting-the-next-step" class="level4" data-number="11.2.2">
<h4 data-number="11.2.2" class="anchored" data-anchor-id="predicting-the-next-step"><span class="header-section-number">11.2.2</span> Predicting the Next Step</h4>
<ul>
<li>The model samples the next token (state, action, reward) from its learned distribution.</li>
<li>This is done using beam search, which expands multiple possible future trajectories and selects the best one.</li>
</ul>
</section>
<section id="beam-search-for-improved-decision-making" class="level4" data-number="11.2.3">
<h4 data-number="11.2.3" class="anchored" data-anchor-id="beam-search-for-improved-decision-making"><span class="header-section-number">11.2.3</span> Beam Search for Improved Decision-Making</h4>
<ul>
<li>Instead of greedily picking the most probable action, TT explores multiple high-reward trajectories in parallel.</li>
<li>Beam search ranks these trajectories based on:
<ul>
<li>Reward-to-Go (RTG) (for reward-maximizing planning).</li>
<li>Likelihood of actions (for policy cloning).</li>
</ul></li>
<li>The highest-ranked trajectory is selected for rollout.</li>
</ul>
</section>
<section id="executing-the-action-updating-context" class="level4" data-number="11.2.4">
<h4 data-number="11.2.4" class="anchored" data-anchor-id="executing-the-action-updating-context"><span class="header-section-number">11.2.4</span> Executing the Action &amp; Updating Context</h4>
<ul>
<li>The chosen action is executed in the environment (or simulated).</li>
<li>The next observed state and reward are added to the context.</li>
<li>The process repeats until the trajectory reaches a termination condition.</li>
</ul>
</section>
</section>
<section id="how-rollouts-enable-long-term-planning" class="level3" data-number="11.3">
<h3 data-number="11.3" class="anchored" data-anchor-id="how-rollouts-enable-long-term-planning"><span class="header-section-number">11.3</span> How Rollouts Enable Long-Term Planning</h3>
<ul>
<li><strong>Looks Beyond Immediate Rewards</strong>: Unlike traditional RL policies, which optimize one-step actions, TT predicts entire sequences using beam search, making decisions that maximize long-term rewards.</li>
<li><strong>Handles Multi-Step Dependencies</strong>: TT’s Transformer-based architecture models long-range dependencies, ensuring that actions are chosen not just for short-term gain but for overall trajectory optimization.</li>
<li><strong>Works Without Online Interaction</strong>: Since rollouts are model-generated, TT can plan offline, leveraging historical data to simulate high-return behaviors without real-time environment interaction.</li>
</ul>
<div id="cell-36" class="cell" data-execution_count="16">
<div class="sourceCode cell-code" id="cb29"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb29-1"><a href="#cb29-1"></a><span class="at">@torch.no_grad</span>()</span>
<span id="cb29-2"><a href="#cb29-2"></a><span class="kw">def</span> vec_rollout(</span>
<span id="cb29-3"><a href="#cb29-3"></a>    model: nn.Module,</span>
<span id="cb29-4"><a href="#cb29-4"></a>    env: DummyVecEnv,</span>
<span id="cb29-5"><a href="#cb29-5"></a>    discretizer: KBinsDiscretizer,</span>
<span id="cb29-6"><a href="#cb29-6"></a>    beam_width: <span class="bu">int</span>,</span>
<span id="cb29-7"><a href="#cb29-7"></a>    beam_steps: <span class="bu">int</span>,</span>
<span id="cb29-8"><a href="#cb29-8"></a>    beam_context: <span class="bu">int</span>,</span>
<span id="cb29-9"><a href="#cb29-9"></a>    sample_expansion: <span class="bu">int</span>,</span>
<span id="cb29-10"><a href="#cb29-10"></a>    observation_dim: <span class="bu">int</span>,</span>
<span id="cb29-11"><a href="#cb29-11"></a>    action_dim: <span class="bu">int</span>,</span>
<span id="cb29-12"><a href="#cb29-12"></a>    reward_dim: <span class="bu">int</span>,</span>
<span id="cb29-13"><a href="#cb29-13"></a>    value_dim: <span class="bu">int</span>,</span>
<span id="cb29-14"><a href="#cb29-14"></a>    transition_dim: <span class="bu">int</span>,</span>
<span id="cb29-15"><a href="#cb29-15"></a>    max_steps: <span class="bu">int</span>,</span>
<span id="cb29-16"><a href="#cb29-16"></a>    plan_every: <span class="bu">int</span>,</span>
<span id="cb29-17"><a href="#cb29-17"></a>    obs_top_k: Optional[<span class="bu">int</span>] <span class="op">=</span> <span class="va">None</span>,</span>
<span id="cb29-18"><a href="#cb29-18"></a>    act_top_k: Optional[<span class="bu">int</span>] <span class="op">=</span> <span class="va">None</span>,</span>
<span id="cb29-19"><a href="#cb29-19"></a>    rew_top_k: Optional[<span class="bu">int</span>] <span class="op">=</span> <span class="va">None</span>,</span>
<span id="cb29-20"><a href="#cb29-20"></a>    temperature: <span class="bu">float</span> <span class="op">=</span> <span class="fl">1.0</span>,</span>
<span id="cb29-21"><a href="#cb29-21"></a>    greedy: <span class="bu">bool</span> <span class="op">=</span> <span class="va">False</span>,</span>
<span id="cb29-22"><a href="#cb29-22"></a>    device: torch.device <span class="op">=</span> torch.device(<span class="st">"cpu"</span>),</span>
<span id="cb29-23"><a href="#cb29-23"></a>):</span>
<span id="cb29-24"><a href="#cb29-24"></a>    <span class="co">"""</span></span>
<span id="cb29-25"><a href="#cb29-25"></a><span class="co">    What is a rollout? A rollout is a simulation of an agent interacting with the environment</span></span>
<span id="cb29-26"><a href="#cb29-26"></a><span class="co">    by following a plan. The plan is generated by the model using beam search. The model</span></span>
<span id="cb29-27"><a href="#cb29-27"></a><span class="co">    predicts the next action, reward, and observation conditioned on the context. The context</span></span>
<span id="cb29-28"><a href="#cb29-28"></a><span class="co">    is the history of the agent's interaction with the environment.</span></span>
<span id="cb29-29"><a href="#cb29-29"></a></span>
<span id="cb29-30"><a href="#cb29-30"></a><span class="co">    This function is responsible for performing a rollout using the model and the environment</span></span>
<span id="cb29-31"><a href="#cb29-31"></a><span class="co">    and returning the total rewards obtained by the agent.</span></span>
<span id="cb29-32"><a href="#cb29-32"></a></span>
<span id="cb29-33"><a href="#cb29-33"></a><span class="co">    Similar to the vec_beam_plan function, this function is a bit complex because it processes</span></span>
<span id="cb29-34"><a href="#cb29-34"></a><span class="co">    multiple sequences in parallel. The complexity comes from the fact that we are using a vectorized</span></span>
<span id="cb29-35"><a href="#cb29-35"></a><span class="co">    environment, which means that we are processing multiple environments in parallel.</span></span>
<span id="cb29-36"><a href="#cb29-36"></a><span class="co">    """</span></span>
<span id="cb29-37"><a href="#cb29-37"></a>    <span class="cf">assert</span> (</span>
<span id="cb29-38"><a href="#cb29-38"></a>        plan_every <span class="op">&lt;=</span> beam_steps</span>
<span id="cb29-39"><a href="#cb29-39"></a>    ), <span class="ss">f"plan_every </span><span class="sc">{</span>plan_every<span class="sc">}</span><span class="ss"> should be less than or equal to beam_steps </span><span class="sc">{</span>beam_steps<span class="sc">}</span><span class="ss">"</span></span>
<span id="cb29-40"><a href="#cb29-40"></a></span>
<span id="cb29-41"><a href="#cb29-41"></a>    <span class="co"># reset the environment amd get the initial observation</span></span>
<span id="cb29-42"><a href="#cb29-42"></a>    <span class="co"># in most environments, the initial observation selected randomly.</span></span>
<span id="cb29-43"><a href="#cb29-43"></a>    obs <span class="op">=</span> env.reset()</span>
<span id="cb29-44"><a href="#cb29-44"></a></span>
<span id="cb29-45"><a href="#cb29-45"></a>    <span class="co"># obs shape (num_envs, observation_dim)</span></span>
<span id="cb29-46"><a href="#cb29-46"></a>    obs <span class="op">=</span> flatten_space(obs, env.observation_space)</span>
<span id="cb29-47"><a href="#cb29-47"></a>    total_rewards <span class="op">=</span> np.zeros(env.num_envs)</span>
<span id="cb29-48"><a href="#cb29-48"></a>    context <span class="op">=</span> torch.zeros(</span>
<span id="cb29-49"><a href="#cb29-49"></a>        (env.num_envs, (max_steps <span class="op">+</span> <span class="dv">1</span>) <span class="op">*</span> transition_dim),</span>
<span id="cb29-50"><a href="#cb29-50"></a>        device<span class="op">=</span>device,</span>
<span id="cb29-51"><a href="#cb29-51"></a>        dtype<span class="op">=</span>torch.<span class="bu">long</span>,</span>
<span id="cb29-52"><a href="#cb29-52"></a>    )</span>
<span id="cb29-53"><a href="#cb29-53"></a>    <span class="co"># context_idx is used to keep track of the current index in the context</span></span>
<span id="cb29-54"><a href="#cb29-54"></a>    context_idx <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb29-55"><a href="#cb29-55"></a></span>
<span id="cb29-56"><a href="#cb29-56"></a>    <span class="co"># discretize the observation</span></span>
<span id="cb29-57"><a href="#cb29-57"></a>    <span class="co"># obs_token shape (num_envs, observation_dim)</span></span>
<span id="cb29-58"><a href="#cb29-58"></a>    obs_token <span class="op">=</span> discretizer.encode(obs, subslice<span class="op">=</span>(<span class="dv">0</span>, observation_dim))</span>
<span id="cb29-59"><a href="#cb29-59"></a></span>
<span id="cb29-60"><a href="#cb29-60"></a>    value_placeholder <span class="op">=</span> np.ones((env.num_envs, value_dim)) <span class="op">*</span> <span class="fl">1e6</span></span>
<span id="cb29-61"><a href="#cb29-61"></a></span>
<span id="cb29-62"><a href="#cb29-62"></a>    <span class="co"># update the context with the initial observation</span></span>
<span id="cb29-63"><a href="#cb29-63"></a>    context[:, :observation_dim] <span class="op">=</span> torch.tensor(obs_token, device<span class="op">=</span>device)</span>
<span id="cb29-64"><a href="#cb29-64"></a></span>
<span id="cb29-65"><a href="#cb29-65"></a>    <span class="co"># tensor to keep track of which environments are done</span></span>
<span id="cb29-66"><a href="#cb29-66"></a>    dones <span class="op">=</span> np.zeros(env.num_envs, dtype<span class="op">=</span>np.<span class="bu">bool</span>)</span>
<span id="cb29-67"><a href="#cb29-67"></a></span>
<span id="cb29-68"><a href="#cb29-68"></a>    <span class="co"># usually max_steps is set to default max_num_steps in the environment</span></span>
<span id="cb29-69"><a href="#cb29-69"></a>    <span class="cf">for</span> t <span class="kw">in</span> trange(max_steps, desc<span class="op">=</span><span class="st">"Rollout"</span>, leave<span class="op">=</span><span class="va">False</span>):</span>
<span id="cb29-70"><a href="#cb29-70"></a>        <span class="co"># Process one step in the environment</span></span>
<span id="cb29-71"><a href="#cb29-71"></a>        <span class="co"># one step consists of selecting an action, taking a step in the environment,</span></span>
<span id="cb29-72"><a href="#cb29-72"></a>        <span class="co"># and updating the context with the new observation, action, reward, and value.</span></span>
<span id="cb29-73"><a href="#cb29-73"></a>        <span class="cf">if</span> t <span class="op">%</span> plan_every <span class="op">==</span> <span class="dv">0</span>:</span>
<span id="cb29-74"><a href="#cb29-74"></a>            <span class="co"># every plan_every steps, we generate a new plan using beam search</span></span>
<span id="cb29-75"><a href="#cb29-75"></a>            <span class="co"># and store the predicted tokens in plan_buffer.</span></span>
<span id="cb29-76"><a href="#cb29-76"></a>            <span class="co"># higher plan_every means we are using the same plan for longer</span></span>
<span id="cb29-77"><a href="#cb29-77"></a>            <span class="co"># as a result, we are putting more trust in the model's prediction</span></span>
<span id="cb29-78"><a href="#cb29-78"></a>            <span class="co"># of the future states, actions, and rewards.</span></span>
<span id="cb29-79"><a href="#cb29-79"></a></span>
<span id="cb29-80"><a href="#cb29-80"></a>            context_idx <span class="op">=</span> (</span>
<span id="cb29-81"><a href="#cb29-81"></a>                ((t <span class="op">+</span> <span class="dv">1</span>) <span class="op">*</span> transition_dim) <span class="op">-</span> action_dim <span class="op">-</span> reward_dim <span class="op">-</span> value_dim</span>
<span id="cb29-82"><a href="#cb29-82"></a>            )</span>
<span id="cb29-83"><a href="#cb29-83"></a>            context_not_dones <span class="op">=</span> context[<span class="op">~</span>dones, :context_idx]</span>
<span id="cb29-84"><a href="#cb29-84"></a></span>
<span id="cb29-85"><a href="#cb29-85"></a>            <span class="co"># generate a new plan using beam search</span></span>
<span id="cb29-86"><a href="#cb29-86"></a>            <span class="co"># predicted_tokens shape (num_envs, beam_steps * transition_dim)</span></span>
<span id="cb29-87"><a href="#cb29-87"></a>            predicted_tokens <span class="op">=</span> vec_beam_plan(</span>
<span id="cb29-88"><a href="#cb29-88"></a>                model,</span>
<span id="cb29-89"><a href="#cb29-89"></a>                discretizer,</span>
<span id="cb29-90"><a href="#cb29-90"></a>                context_not_dones,</span>
<span id="cb29-91"><a href="#cb29-91"></a>                beam_width,</span>
<span id="cb29-92"><a href="#cb29-92"></a>                beam_steps,</span>
<span id="cb29-93"><a href="#cb29-93"></a>                beam_context,</span>
<span id="cb29-94"><a href="#cb29-94"></a>                sample_expansion,</span>
<span id="cb29-95"><a href="#cb29-95"></a>                observation_dim,</span>
<span id="cb29-96"><a href="#cb29-96"></a>                action_dim,</span>
<span id="cb29-97"><a href="#cb29-97"></a>                reward_dim,</span>
<span id="cb29-98"><a href="#cb29-98"></a>                value_dim,</span>
<span id="cb29-99"><a href="#cb29-99"></a>                transition_dim,</span>
<span id="cb29-100"><a href="#cb29-100"></a>                obs_top_k<span class="op">=</span>obs_top_k,</span>
<span id="cb29-101"><a href="#cb29-101"></a>                act_top_k<span class="op">=</span>act_top_k,</span>
<span id="cb29-102"><a href="#cb29-102"></a>                rew_top_k<span class="op">=</span>rew_top_k,</span>
<span id="cb29-103"><a href="#cb29-103"></a>                temperature<span class="op">=</span>temperature,</span>
<span id="cb29-104"><a href="#cb29-104"></a>                greedy<span class="op">=</span>greedy,</span>
<span id="cb29-105"><a href="#cb29-105"></a>            )</span>
<span id="cb29-106"><a href="#cb29-106"></a>            plan_buffer <span class="op">=</span> torch.zeros(</span>
<span id="cb29-107"><a href="#cb29-107"></a>                env.num_envs,</span>
<span id="cb29-108"><a href="#cb29-108"></a>                predicted_tokens.shape[<span class="op">-</span><span class="dv">1</span>],</span>
<span id="cb29-109"><a href="#cb29-109"></a>                device<span class="op">=</span>device,</span>
<span id="cb29-110"><a href="#cb29-110"></a>                dtype<span class="op">=</span>predicted_tokens.dtype,</span>
<span id="cb29-111"><a href="#cb29-111"></a>            )</span>
<span id="cb29-112"><a href="#cb29-112"></a>            plan_buffer[<span class="op">~</span>dones] <span class="op">=</span> predicted_tokens</span>
<span id="cb29-113"><a href="#cb29-113"></a>        <span class="cf">else</span>:</span>
<span id="cb29-114"><a href="#cb29-114"></a>            <span class="co"># if we are not generating a new plan, we use the plan_buffer</span></span>
<span id="cb29-115"><a href="#cb29-115"></a>            <span class="co"># to get the next transition_dim number of tokens</span></span>
<span id="cb29-116"><a href="#cb29-116"></a>            plan_buffer <span class="op">=</span> plan_buffer[:, transition_dim:]</span>
<span id="cb29-117"><a href="#cb29-117"></a></span>
<span id="cb29-118"><a href="#cb29-118"></a>        <span class="co"># get the action from the predicted tokens</span></span>
<span id="cb29-119"><a href="#cb29-119"></a>        <span class="co"># action_token shape (num_envs, action_dim)</span></span>
<span id="cb29-120"><a href="#cb29-120"></a>        action_token <span class="op">=</span> plan_buffer[:, :action_dim].cpu().numpy()</span>
<span id="cb29-121"><a href="#cb29-121"></a>        <span class="co"># decode the action</span></span>
<span id="cb29-122"><a href="#cb29-122"></a>        <span class="co"># action shape (num_envs, action_dim)</span></span>
<span id="cb29-123"><a href="#cb29-123"></a>        action <span class="op">=</span> discretizer.decode(</span>
<span id="cb29-124"><a href="#cb29-124"></a>            action_token, subslice<span class="op">=</span>(observation_dim, observation_dim <span class="op">+</span> action_dim)</span>
<span id="cb29-125"><a href="#cb29-125"></a>        )</span>
<span id="cb29-126"><a href="#cb29-126"></a>        action <span class="op">=</span> unflatten_space(action, env.action_space)</span>
<span id="cb29-127"><a href="#cb29-127"></a>        next_obs, reward, done, _ <span class="op">=</span> env.step(action)</span>
<span id="cb29-128"><a href="#cb29-128"></a>        <span class="co"># next_obs shape (num_envs, observation_dim)</span></span>
<span id="cb29-129"><a href="#cb29-129"></a>        next_obs <span class="op">=</span> flatten_space(next_obs, env.observation_space)</span>
<span id="cb29-130"><a href="#cb29-130"></a>        <span class="co"># discretize the next observation</span></span>
<span id="cb29-131"><a href="#cb29-131"></a>        <span class="co"># next_obs_token shape (num_envs, observation_dim)</span></span>
<span id="cb29-132"><a href="#cb29-132"></a>        next_obs_token <span class="op">=</span> discretizer.encode(</span>
<span id="cb29-133"><a href="#cb29-133"></a>            next_obs[<span class="op">~</span>dones], subslice<span class="op">=</span>(<span class="dv">0</span>, observation_dim)</span>
<span id="cb29-134"><a href="#cb29-134"></a>        )</span>
<span id="cb29-135"><a href="#cb29-135"></a>        <span class="co"># discretize the reward and value</span></span>
<span id="cb29-136"><a href="#cb29-136"></a>        <span class="co"># reward_value_tokens shape (num_envs, reward_dim + value_dim)</span></span>
<span id="cb29-137"><a href="#cb29-137"></a>        reward_value_tokens <span class="op">=</span> discretizer.encode(</span>
<span id="cb29-138"><a href="#cb29-138"></a>            np.hstack([reward.reshape(<span class="op">-</span><span class="dv">1</span>, reward_dim), value_placeholder]),</span>
<span id="cb29-139"><a href="#cb29-139"></a>            subslice<span class="op">=</span>(transition_dim <span class="op">-</span> reward_dim <span class="op">-</span> action_dim, transition_dim),</span>
<span id="cb29-140"><a href="#cb29-140"></a>        )</span>
<span id="cb29-141"><a href="#cb29-141"></a></span>
<span id="cb29-142"><a href="#cb29-142"></a>        <span class="co"># update the context</span></span>
<span id="cb29-143"><a href="#cb29-143"></a>        context_idx <span class="op">=</span> t <span class="op">*</span> transition_dim</span>
<span id="cb29-144"><a href="#cb29-144"></a>        <span class="co"># add action</span></span>
<span id="cb29-145"><a href="#cb29-145"></a>        context[</span>
<span id="cb29-146"><a href="#cb29-146"></a>            <span class="op">~</span>dones,</span>
<span id="cb29-147"><a href="#cb29-147"></a>            context_idx <span class="op">+</span> observation_dim : context_idx <span class="op">+</span> observation_dim <span class="op">+</span> action_dim,</span>
<span id="cb29-148"><a href="#cb29-148"></a>        ] <span class="op">=</span> torch.as_tensor(action_token[<span class="op">~</span>dones], device<span class="op">=</span>device)</span>
<span id="cb29-149"><a href="#cb29-149"></a>        <span class="co"># add reward and value</span></span>
<span id="cb29-150"><a href="#cb29-150"></a>        context[</span>
<span id="cb29-151"><a href="#cb29-151"></a>            <span class="op">~</span>dones,</span>
<span id="cb29-152"><a href="#cb29-152"></a>            context_idx <span class="op">+</span> observation_dim <span class="op">+</span> action_dim : context_idx <span class="op">+</span> transition_dim,</span>
<span id="cb29-153"><a href="#cb29-153"></a>        ] <span class="op">=</span> torch.as_tensor(reward_value_tokens[<span class="op">~</span>dones], device<span class="op">=</span>device)</span>
<span id="cb29-154"><a href="#cb29-154"></a>        <span class="co"># add next observation</span></span>
<span id="cb29-155"><a href="#cb29-155"></a>        context[</span>
<span id="cb29-156"><a href="#cb29-156"></a>            <span class="op">~</span>dones,</span>
<span id="cb29-157"><a href="#cb29-157"></a>            context_idx</span>
<span id="cb29-158"><a href="#cb29-158"></a>            <span class="op">+</span> transition_dim : context_idx</span>
<span id="cb29-159"><a href="#cb29-159"></a>            <span class="op">+</span> transition_dim</span>
<span id="cb29-160"><a href="#cb29-160"></a>            <span class="op">+</span> observation_dim,</span>
<span id="cb29-161"><a href="#cb29-161"></a>        ] <span class="op">=</span> torch.as_tensor(next_obs_token, device<span class="op">=</span>device)</span>
<span id="cb29-162"><a href="#cb29-162"></a></span>
<span id="cb29-163"><a href="#cb29-163"></a>        total_rewards[<span class="op">~</span>dones] <span class="op">+=</span> reward[<span class="op">~</span>dones]</span>
<span id="cb29-164"><a href="#cb29-164"></a></span>
<span id="cb29-165"><a href="#cb29-165"></a>        dones[done] <span class="op">=</span> <span class="va">True</span></span>
<span id="cb29-166"><a href="#cb29-166"></a>        <span class="cf">if</span> np.<span class="bu">all</span>(dones):</span>
<span id="cb29-167"><a href="#cb29-167"></a>            <span class="cf">break</span></span>
<span id="cb29-168"><a href="#cb29-168"></a>    <span class="cf">return</span> total_rewards, dones</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
</section>
<section id="model-training" class="level2" data-number="12">
<h2 data-number="12" class="anchored" data-anchor-id="model-training"><span class="header-section-number">12</span> Model Training</h2>
<section id="loss-function-cross-entropy-loss-action-weighting-and-masking" class="level3" data-number="12.1">
<h3 data-number="12.1" class="anchored" data-anchor-id="loss-function-cross-entropy-loss-action-weighting-and-masking"><span class="header-section-number">12.1</span> Loss Function: Cross-Entropy Loss, Action Weighting, and Masking</h3>
<section id="why-cross-entropy-loss" class="level4" data-number="12.1.1">
<h4 data-number="12.1.1" class="anchored" data-anchor-id="why-cross-entropy-loss"><span class="header-section-number">12.1.1</span> Why Cross-Entropy Loss?</h4>
<p>TT models trajectory prediction as a sequence modeling problem, similar to language modeling. Instead of predicting the next word, TT predicts the next token in a trajectory (state, action, reward, value). Since each token is discretized into bins, the model’s output is a classification problem over a vocabulary of discrete bins.</p>
<p>Cross-entropy loss is used because it is the standard for classification tasks:</p>
<p><span class="math display">\[
L = -\sum p_{\text{true}} \log p_{\text{pred}}
\]</span></p>
<p>where:</p>
<ul>
<li><span class="math inline">\(p_{\text{true}}\)</span> is the true probability distribution (one-hot encoded).</li>
<li><span class="math inline">\(p_{\text{pred}}\)</span> is the predicted probability distribution over the discrete bins.</li>
</ul>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="img/offline_rl/loss.png" class="img-fluid figure-img"></p>
<figcaption>Loss</figcaption>
</figure>
</div>
</section>
<section id="why-are-actions-weighted-higher" class="level4" data-number="12.1.2">
<h4 data-number="12.1.2" class="anchored" data-anchor-id="why-are-actions-weighted-higher"><span class="header-section-number">12.1.2</span> Why are Actions Weighted Higher?</h4>
<ul>
<li>Actions are weighted higher (factor of 5) because errors in action prediction have the most direct impact on trajectory optimization.</li>
<li>Since TT is used for decision-time planning, predicting incorrect actions leads to poor rollouts, making action prediction more critical than observations or rewards.</li>
</ul>
</section>
<section id="why-use-a-loss-mask" class="level4" data-number="12.1.3">
<h4 data-number="12.1.3" class="anchored" data-anchor-id="why-use-a-loss-mask"><span class="header-section-number">12.1.3</span> Why Use a Loss Mask?</h4>
<ul>
<li>The model operates on sequences of different lengths.</li>
<li>Padding is added to ensure equal sequence lengths in a batch.</li>
<li>The loss mask prevents the model from learning from padded tokens, avoiding training artifacts.</li>
</ul>
</section>
</section>
<section id="vectorized-environments-in-gym-what-and-why" class="level3" data-number="12.2">
<h3 data-number="12.2" class="anchored" data-anchor-id="vectorized-environments-in-gym-what-and-why"><span class="header-section-number">12.2</span> Vectorized Environments in Gym: What and Why?</h3>
<p>A vectorized environment (from Gym’s <code>DummyVecEnv</code>) runs multiple independent environments in parallel.</p>
<ul>
<li>Instead of rolling out one episode at a time, we can execute multiple rollouts simultaneously.</li>
<li>This provides faster evaluation by utilizing batch processing on the GPU.</li>
</ul>
</section>
<section id="learning-rate-scheduler-weight-decay-and-gradient-clipping" class="level3" data-number="12.3">
<h3 data-number="12.3" class="anchored" data-anchor-id="learning-rate-scheduler-weight-decay-and-gradient-clipping"><span class="header-section-number">12.3</span> Learning Rate Scheduler, Weight Decay, and Gradient Clipping</h3>
<section id="learning-rate-scheduler-why-its-needed" class="level4" data-number="12.3.1">
<h4 data-number="12.3.1" class="anchored" data-anchor-id="learning-rate-scheduler-why-its-needed"><span class="header-section-number">12.3.1</span> Learning Rate Scheduler: Why It’s Needed</h4>
<ul>
<li>TT is a Transformer-based model, meaning it benefits from a warmup-decay schedule.</li>
<li>Instead of keeping a fixed learning rate, the scheduler adjusts it dynamically based on the training step.</li>
<li>This prevents instability early in training and helps the model converge smoothly.</li>
</ul>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="img/offline_rl/lr_schedule.png" class="img-fluid figure-img"></p>
<figcaption>Learning Rate Schedule</figcaption>
</figure>
</div>
</section>
<section id="weight-decay-why-regularization-matters" class="level4" data-number="12.3.2">
<h4 data-number="12.3.2" class="anchored" data-anchor-id="weight-decay-why-regularization-matters"><span class="header-section-number">12.3.2</span> Weight Decay: Why Regularization Matters</h4>
<ul>
<li>Weight decay penalizes large weights, helping the model avoid overfitting.</li>
<li>Since TT learns from a fixed dataset (offline RL), overfitting is a major concern, making regularization crucial.</li>
</ul>
</section>
<section id="gradient-clipping-why-its-used" class="level4" data-number="12.3.3">
<h4 data-number="12.3.3" class="anchored" data-anchor-id="gradient-clipping-why-its-used"><span class="header-section-number">12.3.3</span> Gradient Clipping: Why It’s Used</h4>
<ul>
<li>Transformers can experience exploding gradients, especially when handling long trajectories.</li>
<li>Clipping prevents gradients from becoming too large, stabilizing training.</li>
<li>Without clipping, loss can spike suddenly, leading to divergence.</li>
</ul>
</section>
</section>
<section id="predictive-accuracy-what-it-is-and-why-its-not-important-for-tt" class="level3" data-number="12.4">
<h3 data-number="12.4" class="anchored" data-anchor-id="predictive-accuracy-what-it-is-and-why-its-not-important-for-tt"><span class="header-section-number">12.4</span> Predictive Accuracy: What It Is and Why It’s Not Important for TT</h3>
<p>Predictive accuracy measures how often the model correctly predicts the next token in a trajectory. Computed as:</p>
<p><span class="math display">\[
\text{Accuracy} = \frac{\text{Correct Predictions}}{\text{Total Predictions}}
\]</span></p>
<section id="why-its-not-crucial-for-tt" class="level4" data-number="12.4.1">
<h4 data-number="12.4.1" class="anchored" data-anchor-id="why-its-not-crucial-for-tt"><span class="header-section-number">12.4.1</span> Why It’s NOT Crucial for TT?</h4>
<ul>
<li>Unlike supervised learning, TT does not optimize for direct action prediction.</li>
<li>A high accuracy doesn’t necessarily mean better rollouts—what matters is how well the model generates high-return trajectories.</li>
<li>Used here mainly as a diagnostic tool to check if the model is learning meaningful representations.</li>
</ul>
<p>Predictive accuracy is a useful debugging metric, but rollout performance is the real measure of success in TT.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="img/offline_rl/accuracy.png" class="img-fluid figure-img"></p>
<figcaption>Predictive Accuracy</figcaption>
</figure>
</div>
</section>
</section>
<section id="evaluation-in-tt-key-metrics-purpose" class="level3" data-number="12.5">
<h3 data-number="12.5" class="anchored" data-anchor-id="evaluation-in-tt-key-metrics-purpose"><span class="header-section-number">12.5</span> Evaluation in TT: Key Metrics &amp; Purpose</h3>
<p>Model evaluation in <strong>Trajectory Transformer (TT)</strong> focuses on <strong>rollout performance</strong>, rather than accuracy or loss. Since TT is designed for <strong>trajectory generation and decision-time planning</strong>, we assess how well it produces <strong>high-return trajectories</strong>. The key metrics are:</p>
<section id="mean-reward" class="level4" data-number="12.5.1">
<h4 data-number="12.5.1" class="anchored" data-anchor-id="mean-reward"><span class="header-section-number">12.5.1</span> <strong>Mean Reward</strong></h4>
<ul>
<li>Measures the <strong>average cumulative reward</strong> across rollouts.<br>
</li>
<li>A higher mean reward indicates <strong>better trajectory optimization</strong>.<br>
</li>
<li>The trend of mean reward over training epochs suggests that training could <strong>potentially stop at ~30 epochs</strong> for this environment.</li>
</ul>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="img/offline_rl/mean_reward.png" class="img-fluid figure-img"></p>
<figcaption>Mean Rewards</figcaption>
</figure>
</div>
</section>
<section id="reward-standard-deviation-std-dev" class="level4" data-number="12.5.2">
<h4 data-number="12.5.2" class="anchored" data-anchor-id="reward-standard-deviation-std-dev"><span class="header-section-number">12.5.2</span> <strong>Reward Standard Deviation (Std Dev)</strong></h4>
<ul>
<li>Captures <strong>variability in rollouts</strong>.<br>
</li>
<li><strong>Low std</strong> means <strong>consistent performance</strong>, while <strong>high std</strong> suggests instability.</li>
</ul>
</section>
<section id="done-ratio" class="level4" data-number="12.5.3">
<h4 data-number="12.5.3" class="anchored" data-anchor-id="done-ratio"><span class="header-section-number">12.5.3</span> <strong>Done Ratio</strong></h4>
<ul>
<li>Tracks how often rollouts <strong>reach termination</strong>.<br>
</li>
<li>Only meaningful for environments with <strong>terminal conditions</strong> (e.g., <code>AntMaze</code>).<br>
</li>
<li>In environments like <strong>HalfCheetah</strong>, which do not naturally terminate, rollouts end only when <strong>max steps are reached</strong>.</li>
</ul>
</section>
<section id="mean-rollout-time" class="level4" data-number="12.5.4">
<h4 data-number="12.5.4" class="anchored" data-anchor-id="mean-rollout-time"><span class="header-section-number">12.5.4</span> <strong>Mean Rollout Time</strong></h4>
<ul>
<li>Measures <strong>inference efficiency</strong>, influenced by:
<ul>
<li><strong>Beam width</strong><br>
</li>
<li><strong>Sequence length</strong><br>
</li>
<li><strong>Sampling strategy</strong><br>
</li>
</ul></li>
<li>Faster rollouts improve <strong>real-time decision-making</strong>.</li>
</ul>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="img/offline_rl/rollout_time.png" class="img-fluid figure-img"></p>
<figcaption>Mean Rollout Time</figcaption>
</figure>
</div>
</section>
<section id="total-rewards-distribution" class="level4" data-number="12.5.5">
<h4 data-number="12.5.5" class="anchored" data-anchor-id="total-rewards-distribution"><span class="header-section-number">12.5.5</span> <strong>Total Rewards Distribution</strong></h4>
<ul>
<li>Shows the <strong>spread of rewards</strong> from multiple episodes.<br>
</li>
<li>Helps detect <strong>outliers and inconsistencies</strong> beyond the mean.<br>
</li>
<li>Over training epochs, the distribution <strong>trends upward</strong>:
<ul>
<li><strong>Early epochs:</strong> Most rollouts accumulate <strong>negative rewards</strong>.<br>
</li>
<li><strong>Later epochs:</strong> Rollouts <strong>converge to positive rewards</strong>, indicating TT <strong>learns a stable policy</strong>.</li>
</ul></li>
</ul>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="img/offline_rl/reward_distri.png" class="img-fluid figure-img"></p>
<figcaption>Rewards Distribution</figcaption>
</figure>
</div>
</section>
<section id="conclusion" class="level4" data-number="12.5.6">
<h4 data-number="12.5.6" class="anchored" data-anchor-id="conclusion"><span class="header-section-number">12.5.6</span> <strong>Conclusion</strong></h4>
<p>These metrics ensure TT is <strong>not just memorizing past data</strong>, but is truly capable of <strong>effective planning</strong>. Based on evaluation results, the trained TT model <strong>successfully navigates the environment</strong>.</p>
<p><strong>Is this the most optimal policy?</strong><br>
That question requires <strong>comparing TT with other RL methods</strong>. For further analysis, please refer to the original <strong>Trajectory Transformer paper</strong>—such comparisons are <strong>beyond the scope of this notebook</strong>.</p>
<div id="cell-38" class="cell">
<details class="code-fold">
<summary>Training loop, loss function, and evaluation functions</summary>
<div class="sourceCode cell-code" id="cb30"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb30-1"><a href="#cb30-1"></a><span class="kw">def</span> calculate_loss(</span>
<span id="cb30-2"><a href="#cb30-2"></a>    model: nn.Module,</span>
<span id="cb30-3"><a href="#cb30-3"></a>    batch: Tuple[torch.Tensor, torch.Tensor, torch.Tensor],</span>
<span id="cb30-4"><a href="#cb30-4"></a>    vocab_size: <span class="bu">int</span>,</span>
<span id="cb30-5"><a href="#cb30-5"></a>    transition_dim: <span class="bu">int</span>,</span>
<span id="cb30-6"><a href="#cb30-6"></a>    observation_dim: <span class="bu">int</span>,</span>
<span id="cb30-7"><a href="#cb30-7"></a>    action_dim: <span class="bu">int</span>,</span>
<span id="cb30-8"><a href="#cb30-8"></a>    reward_dim: <span class="bu">int</span>,</span>
<span id="cb30-9"><a href="#cb30-9"></a>    value_dim: <span class="bu">int</span>,</span>
<span id="cb30-10"><a href="#cb30-10"></a>    device: torch.device <span class="op">=</span> torch.device(<span class="st">"cpu"</span>),</span>
<span id="cb30-11"><a href="#cb30-11"></a>) <span class="op">-&gt;</span> torch.Tensor:</span>
<span id="cb30-12"><a href="#cb30-12"></a>    <span class="co"># inputs shape (batch_size, seq_len)</span></span>
<span id="cb30-13"><a href="#cb30-13"></a>    <span class="co"># targets shape (batch_size, seq_len)</span></span>
<span id="cb30-14"><a href="#cb30-14"></a>    <span class="co"># loss_pad_mask shape (batch_size, seq_len)</span></span>
<span id="cb30-15"><a href="#cb30-15"></a>    inputs, targets, loss_pad_mask <span class="op">=</span> batch</span>
<span id="cb30-16"><a href="#cb30-16"></a>    inputs <span class="op">=</span> inputs.to(device)</span>
<span id="cb30-17"><a href="#cb30-17"></a>    targets <span class="op">=</span> targets.to(device)</span>
<span id="cb30-18"><a href="#cb30-18"></a>    loss_pad_mask <span class="op">=</span> loss_pad_mask.to(device)</span>
<span id="cb30-19"><a href="#cb30-19"></a>    <span class="co"># logits shape (batch_size, seq_len, vocab_size)</span></span>
<span id="cb30-20"><a href="#cb30-20"></a>    logits, _ <span class="op">=</span> model(inputs)</span>
<span id="cb30-21"><a href="#cb30-21"></a>    <span class="co"># flatten the logits and targets to shape (batch_size * seq_len, vocab_size)</span></span>
<span id="cb30-22"><a href="#cb30-22"></a>    <span class="cf">assert</span> logits.shape[<span class="op">-</span><span class="dv">1</span>] <span class="op">==</span> vocab_size, <span class="st">"vocab_size mismatch"</span></span>
<span id="cb30-23"><a href="#cb30-23"></a>    logits <span class="op">=</span> logits.reshape(<span class="op">-</span><span class="dv">1</span>, vocab_size)</span>
<span id="cb30-24"><a href="#cb30-24"></a>    <span class="co"># flatten the targets to shape (batch_size * seq_len)</span></span>
<span id="cb30-25"><a href="#cb30-25"></a>    targets <span class="op">=</span> targets.reshape(<span class="op">-</span><span class="dv">1</span>)</span>
<span id="cb30-26"><a href="#cb30-26"></a>    <span class="co"># loss shape (batch_size * seq_len)</span></span>
<span id="cb30-27"><a href="#cb30-27"></a>    loss <span class="op">=</span> F.cross_entropy(logits, targets, reduction<span class="op">=</span><span class="st">"none"</span>)</span>
<span id="cb30-28"><a href="#cb30-28"></a>    <span class="cf">assert</span> loss.shape <span class="op">==</span> (inputs.shape[<span class="dv">0</span>] <span class="op">*</span> inputs.shape[<span class="dv">1</span>],), <span class="st">"loss shape mismatch"</span></span>
<span id="cb30-29"><a href="#cb30-29"></a></span>
<span id="cb30-30"><a href="#cb30-30"></a>    n_states <span class="op">=</span> math.ceil(inputs.shape[<span class="dv">1</span>] <span class="op">/</span> transition_dim)</span>
<span id="cb30-31"><a href="#cb30-31"></a>    <span class="co"># weights shape (observation_dim + action_dim + reward_dim + value_dim)</span></span>
<span id="cb30-32"><a href="#cb30-32"></a>    weights <span class="op">=</span> torch.cat(</span>
<span id="cb30-33"><a href="#cb30-33"></a>        [</span>
<span id="cb30-34"><a href="#cb30-34"></a>            torch.ones(observation_dim, device<span class="op">=</span>inputs.device),</span>
<span id="cb30-35"><a href="#cb30-35"></a>            torch.ones(action_dim, device<span class="op">=</span>inputs.device) <span class="op">*</span> <span class="dv">5</span>,</span>
<span id="cb30-36"><a href="#cb30-36"></a>            torch.ones(reward_dim, device<span class="op">=</span>inputs.device) <span class="op">*</span> <span class="dv">1</span>,</span>
<span id="cb30-37"><a href="#cb30-37"></a>            torch.ones(value_dim, device<span class="op">=</span>inputs.device) <span class="op">*</span> <span class="dv">1</span>,</span>
<span id="cb30-38"><a href="#cb30-38"></a>        ]</span>
<span id="cb30-39"><a href="#cb30-39"></a>    )</span>
<span id="cb30-40"><a href="#cb30-40"></a>    <span class="co"># remove the first element from weights because we are starting from the second token</span></span>
<span id="cb30-41"><a href="#cb30-41"></a>    weights <span class="op">=</span> weights.repeat(n_states)[<span class="dv">1</span>:].repeat(inputs.shape[<span class="dv">0</span>], <span class="dv">1</span>)</span>
<span id="cb30-42"><a href="#cb30-42"></a>    loss <span class="op">=</span> loss <span class="op">*</span> weights.view(<span class="op">-</span><span class="dv">1</span>)</span>
<span id="cb30-43"><a href="#cb30-43"></a>    <span class="co"># apply the loss pad mask to the loss because we don't want to calculate the loss for padded values</span></span>
<span id="cb30-44"><a href="#cb30-44"></a>    loss <span class="op">=</span> (loss <span class="op">*</span> loss_pad_mask.view(<span class="op">-</span><span class="dv">1</span>)).mean()</span>
<span id="cb30-45"><a href="#cb30-45"></a>    <span class="cf">return</span> loss</span>
<span id="cb30-46"><a href="#cb30-46"></a></span>
<span id="cb30-47"><a href="#cb30-47"></a></span>
<span id="cb30-48"><a href="#cb30-48"></a><span class="kw">def</span> vec_eval(</span>
<span id="cb30-49"><a href="#cb30-49"></a>    env: Env,</span>
<span id="cb30-50"><a href="#cb30-50"></a>    model: nn.Module,</span>
<span id="cb30-51"><a href="#cb30-51"></a>    discretizer: KBinsDiscretizer,</span>
<span id="cb30-52"><a href="#cb30-52"></a>    num_episodes: <span class="bu">int</span>,</span>
<span id="cb30-53"><a href="#cb30-53"></a>    beam_width: <span class="bu">int</span>,</span>
<span id="cb30-54"><a href="#cb30-54"></a>    beam_steps: <span class="bu">int</span>,</span>
<span id="cb30-55"><a href="#cb30-55"></a>    beam_context: <span class="bu">int</span>,</span>
<span id="cb30-56"><a href="#cb30-56"></a>    sample_expansion: <span class="bu">int</span>,</span>
<span id="cb30-57"><a href="#cb30-57"></a>    observation_dim: <span class="bu">int</span>,</span>
<span id="cb30-58"><a href="#cb30-58"></a>    action_dim: <span class="bu">int</span>,</span>
<span id="cb30-59"><a href="#cb30-59"></a>    reward_dim: <span class="bu">int</span>,</span>
<span id="cb30-60"><a href="#cb30-60"></a>    value_dim: <span class="bu">int</span>,</span>
<span id="cb30-61"><a href="#cb30-61"></a>    transition_dim: <span class="bu">int</span>,</span>
<span id="cb30-62"><a href="#cb30-62"></a>    plan_every: <span class="bu">int</span>,</span>
<span id="cb30-63"><a href="#cb30-63"></a>    obs_top_k: Optional[<span class="bu">int</span>] <span class="op">=</span> <span class="va">None</span>,</span>
<span id="cb30-64"><a href="#cb30-64"></a>    act_top_k: Optional[<span class="bu">int</span>] <span class="op">=</span> <span class="va">None</span>,</span>
<span id="cb30-65"><a href="#cb30-65"></a>    rew_top_k: Optional[<span class="bu">int</span>] <span class="op">=</span> <span class="va">None</span>,</span>
<span id="cb30-66"><a href="#cb30-66"></a>    temperature: <span class="bu">float</span> <span class="op">=</span> <span class="fl">1.0</span>,</span>
<span id="cb30-67"><a href="#cb30-67"></a>    greedy: <span class="bu">bool</span> <span class="op">=</span> <span class="va">False</span>,</span>
<span id="cb30-68"><a href="#cb30-68"></a>    device: torch.device <span class="op">=</span> torch.device(<span class="st">"cpu"</span>),</span>
<span id="cb30-69"><a href="#cb30-69"></a>):</span>
<span id="cb30-70"><a href="#cb30-70"></a>    model.<span class="bu">eval</span>()</span>
<span id="cb30-71"><a href="#cb30-71"></a></span>
<span id="cb30-72"><a href="#cb30-72"></a>    <span class="co"># create a vectorized environment, this allows us to run multiple environments in parallel</span></span>
<span id="cb30-73"><a href="#cb30-73"></a>    vec_env <span class="op">=</span> DummyVecEnv([<span class="kw">lambda</span>: gym.make(env.name) <span class="cf">for</span> _ <span class="kw">in</span> <span class="bu">range</span>(num_episodes)])</span>
<span id="cb30-74"><a href="#cb30-74"></a>    start_time <span class="op">=</span> time.time()</span>
<span id="cb30-75"><a href="#cb30-75"></a>    total_rewards, dones <span class="op">=</span> vec_rollout(</span>
<span id="cb30-76"><a href="#cb30-76"></a>        model,</span>
<span id="cb30-77"><a href="#cb30-77"></a>        vec_env,</span>
<span id="cb30-78"><a href="#cb30-78"></a>        discretizer,</span>
<span id="cb30-79"><a href="#cb30-79"></a>        beam_width,</span>
<span id="cb30-80"><a href="#cb30-80"></a>        beam_steps,</span>
<span id="cb30-81"><a href="#cb30-81"></a>        beam_context,</span>
<span id="cb30-82"><a href="#cb30-82"></a>        sample_expansion,</span>
<span id="cb30-83"><a href="#cb30-83"></a>        observation_dim,</span>
<span id="cb30-84"><a href="#cb30-84"></a>        action_dim,</span>
<span id="cb30-85"><a href="#cb30-85"></a>        reward_dim,</span>
<span id="cb30-86"><a href="#cb30-86"></a>        value_dim,</span>
<span id="cb30-87"><a href="#cb30-87"></a>        transition_dim,</span>
<span id="cb30-88"><a href="#cb30-88"></a>        (</span>
<span id="cb30-89"><a href="#cb30-89"></a>            vec_env.envs[<span class="dv">0</span>]._max_episode_steps</span>
<span id="cb30-90"><a href="#cb30-90"></a>            <span class="cf">if</span> <span class="kw">not</span> local</span>
<span id="cb30-91"><a href="#cb30-91"></a>            <span class="cf">else</span> vec_env.envs[<span class="dv">0</span>]._max_episode_steps</span>
<span id="cb30-92"><a href="#cb30-92"></a>        ),</span>
<span id="cb30-93"><a href="#cb30-93"></a>        plan_every,</span>
<span id="cb30-94"><a href="#cb30-94"></a>        obs_top_k<span class="op">=</span>obs_top_k,</span>
<span id="cb30-95"><a href="#cb30-95"></a>        act_top_k<span class="op">=</span>act_top_k,</span>
<span id="cb30-96"><a href="#cb30-96"></a>        rew_top_k<span class="op">=</span>rew_top_k,</span>
<span id="cb30-97"><a href="#cb30-97"></a>        temperature<span class="op">=</span>temperature,</span>
<span id="cb30-98"><a href="#cb30-98"></a>        greedy<span class="op">=</span>greedy,</span>
<span id="cb30-99"><a href="#cb30-99"></a>        device<span class="op">=</span>device,</span>
<span id="cb30-100"><a href="#cb30-100"></a>    )</span>
<span id="cb30-101"><a href="#cb30-101"></a>    end_time <span class="op">=</span> time.time()</span>
<span id="cb30-102"><a href="#cb30-102"></a>    mean_rewards <span class="op">=</span> np.mean(total_rewards)</span>
<span id="cb30-103"><a href="#cb30-103"></a>    std_rewards <span class="op">=</span> np.std(total_rewards)</span>
<span id="cb30-104"><a href="#cb30-104"></a></span>
<span id="cb30-105"><a href="#cb30-105"></a>    done_ratio <span class="op">=</span> np.mean(dones)</span>
<span id="cb30-106"><a href="#cb30-106"></a></span>
<span id="cb30-107"><a href="#cb30-107"></a>    model.train()</span>
<span id="cb30-108"><a href="#cb30-108"></a>    <span class="cf">return</span> (</span>
<span id="cb30-109"><a href="#cb30-109"></a>        mean_rewards,</span>
<span id="cb30-110"><a href="#cb30-110"></a>        std_rewards,</span>
<span id="cb30-111"><a href="#cb30-111"></a>        done_ratio,</span>
<span id="cb30-112"><a href="#cb30-112"></a>        end_time <span class="op">-</span> start_time,</span>
<span id="cb30-113"><a href="#cb30-113"></a>        <span class="dv">0</span>,</span>
<span id="cb30-114"><a href="#cb30-114"></a>        total_rewards,</span>
<span id="cb30-115"><a href="#cb30-115"></a>    )</span>
<span id="cb30-116"><a href="#cb30-116"></a></span>
<span id="cb30-117"><a href="#cb30-117"></a></span>
<span id="cb30-118"><a href="#cb30-118"></a><span class="at">@torch.no_grad</span>()</span>
<span id="cb30-119"><a href="#cb30-119"></a><span class="kw">def</span> calculate_predictive_accuracy(</span>
<span id="cb30-120"><a href="#cb30-120"></a>    model: nn.Module,</span>
<span id="cb30-121"><a href="#cb30-121"></a>    dataloader: Subset,</span>
<span id="cb30-122"><a href="#cb30-122"></a>    device: torch.device <span class="op">=</span> torch.device(<span class="st">"cpu"</span>),</span>
<span id="cb30-123"><a href="#cb30-123"></a>) <span class="op">-&gt;</span> <span class="bu">float</span>:</span>
<span id="cb30-124"><a href="#cb30-124"></a>    model.<span class="bu">eval</span>()</span>
<span id="cb30-125"><a href="#cb30-125"></a>    total_correct <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb30-126"><a href="#cb30-126"></a>    total_samples <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb30-127"><a href="#cb30-127"></a></span>
<span id="cb30-128"><a href="#cb30-128"></a>    <span class="co"># sample 10% of the data</span></span>
<span id="cb30-129"><a href="#cb30-129"></a>    sampling_rate <span class="op">=</span> <span class="fl">0.1</span></span>
<span id="cb30-130"><a href="#cb30-130"></a>    dataloader <span class="op">=</span> DataLoader(</span>
<span id="cb30-131"><a href="#cb30-131"></a>        dataloader.dataset,</span>
<span id="cb30-132"><a href="#cb30-132"></a>        batch_size<span class="op">=</span>dataloader.batch_size,</span>
<span id="cb30-133"><a href="#cb30-133"></a>        sampler<span class="op">=</span>SubsetRandomSampler(</span>
<span id="cb30-134"><a href="#cb30-134"></a>            np.random.choice(</span>
<span id="cb30-135"><a href="#cb30-135"></a>                <span class="bu">len</span>(dataloader.dataset),</span>
<span id="cb30-136"><a href="#cb30-136"></a>                <span class="bu">int</span>(sampling_rate <span class="op">*</span> <span class="bu">len</span>(dataloader.dataset)),</span>
<span id="cb30-137"><a href="#cb30-137"></a>                replace<span class="op">=</span><span class="va">False</span>,</span>
<span id="cb30-138"><a href="#cb30-138"></a>            )</span>
<span id="cb30-139"><a href="#cb30-139"></a>        ),</span>
<span id="cb30-140"><a href="#cb30-140"></a>    )</span>
<span id="cb30-141"><a href="#cb30-141"></a></span>
<span id="cb30-142"><a href="#cb30-142"></a>    <span class="cf">for</span> data <span class="kw">in</span> tqdm(dataloader, desc<span class="op">=</span><span class="st">"Calculating predictive accuracy"</span>, leave<span class="op">=</span><span class="va">False</span>):</span>
<span id="cb30-143"><a href="#cb30-143"></a>        x, y, mask <span class="op">=</span> data</span>
<span id="cb30-144"><a href="#cb30-144"></a>        x, y, mask <span class="op">=</span> x.to(device), y.to(device), mask.to(device)</span>
<span id="cb30-145"><a href="#cb30-145"></a>        logits, _ <span class="op">=</span> model(x)</span>
<span id="cb30-146"><a href="#cb30-146"></a>        <span class="co"># (batch_size, seq_len, vocab_size) -&gt; (batch_size * seq_len, vocab_size)</span></span>
<span id="cb30-147"><a href="#cb30-147"></a>        logits <span class="op">=</span> logits.reshape(<span class="op">-</span><span class="dv">1</span>, logits.shape[<span class="op">-</span><span class="dv">1</span>])</span>
<span id="cb30-148"><a href="#cb30-148"></a>        y <span class="op">=</span> y.reshape(<span class="op">-</span><span class="dv">1</span>)</span>
<span id="cb30-149"><a href="#cb30-149"></a>        mask <span class="op">=</span> mask.reshape(<span class="op">-</span><span class="dv">1</span>)</span>
<span id="cb30-150"><a href="#cb30-150"></a>        <span class="co"># only consider the tokens that are not masked</span></span>
<span id="cb30-151"><a href="#cb30-151"></a>        mask_idx <span class="op">=</span> mask.nonzero(as_tuple<span class="op">=</span><span class="va">True</span>)[<span class="dv">0</span>]</span>
<span id="cb30-152"><a href="#cb30-152"></a>        y <span class="op">=</span> y[mask_idx]</span>
<span id="cb30-153"><a href="#cb30-153"></a>        logits <span class="op">=</span> logits[mask_idx]</span>
<span id="cb30-154"><a href="#cb30-154"></a>        <span class="co"># (batch_size * seq_len) -&gt; (batch_size)</span></span>
<span id="cb30-155"><a href="#cb30-155"></a>        y_pred <span class="op">=</span> torch.argmax(logits, dim<span class="op">=-</span><span class="dv">1</span>)</span>
<span id="cb30-156"><a href="#cb30-156"></a>        correct <span class="op">=</span> (y_pred <span class="op">==</span> y).<span class="bu">sum</span>().item()</span>
<span id="cb30-157"><a href="#cb30-157"></a>        total_correct <span class="op">+=</span> correct</span>
<span id="cb30-158"><a href="#cb30-158"></a>        total_samples <span class="op">+=</span> y.shape[<span class="dv">0</span>]</span>
<span id="cb30-159"><a href="#cb30-159"></a>    model.train()</span>
<span id="cb30-160"><a href="#cb30-160"></a>    <span class="cf">return</span> total_correct <span class="op">/</span> total_samples</span>
<span id="cb30-161"><a href="#cb30-161"></a></span>
<span id="cb30-162"><a href="#cb30-162"></a></span>
<span id="cb30-163"><a href="#cb30-163"></a><span class="kw">def</span> train(</span>
<span id="cb30-164"><a href="#cb30-164"></a>    model: nn.Module,</span>
<span id="cb30-165"><a href="#cb30-165"></a>    train_dataloader: DataLoader,</span>
<span id="cb30-166"><a href="#cb30-166"></a>    test_dataloader: DataLoader,</span>
<span id="cb30-167"><a href="#cb30-167"></a>    discretizer: KBinsDiscretizer,</span>
<span id="cb30-168"><a href="#cb30-168"></a>    optimizer: torch.optim.Optimizer,</span>
<span id="cb30-169"><a href="#cb30-169"></a>    scheduler: GPTScheduler,</span>
<span id="cb30-170"><a href="#cb30-170"></a>    vocab_size: <span class="bu">int</span>,</span>
<span id="cb30-171"><a href="#cb30-171"></a>    n_epochs: <span class="bu">int</span>,</span>
<span id="cb30-172"><a href="#cb30-172"></a>    writer: SummaryWriter,</span>
<span id="cb30-173"><a href="#cb30-173"></a>    device: torch.device <span class="op">=</span> torch.device(<span class="st">"cpu"</span>),</span>
<span id="cb30-174"><a href="#cb30-174"></a>    eval_every: <span class="bu">int</span> <span class="op">=</span> <span class="dv">10</span>,</span>
<span id="cb30-175"><a href="#cb30-175"></a>    checkpoint_path: Optional[<span class="bu">str</span>] <span class="op">=</span> <span class="va">None</span>,</span>
<span id="cb30-176"><a href="#cb30-176"></a>    clip_grad: Optional[<span class="bu">float</span>] <span class="op">=</span> <span class="va">None</span>,</span>
<span id="cb30-177"><a href="#cb30-177"></a>):</span>
<span id="cb30-178"><a href="#cb30-178"></a>    model.train()</span>
<span id="cb30-179"><a href="#cb30-179"></a>    step <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb30-180"><a href="#cb30-180"></a>    <span class="cf">for</span> epoch <span class="kw">in</span> trange(n_epochs, desc<span class="op">=</span><span class="st">"Training"</span>):</span>
<span id="cb30-181"><a href="#cb30-181"></a>        start_time <span class="op">=</span> time.time()</span>
<span id="cb30-182"><a href="#cb30-182"></a>        total_loss <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb30-183"><a href="#cb30-183"></a>        <span class="cf">for</span> batch <span class="kw">in</span> tqdm(</span>
<span id="cb30-184"><a href="#cb30-184"></a>            train_dataloader, desc<span class="op">=</span><span class="ss">f"Epoch </span><span class="sc">{</span>epoch <span class="op">+</span> <span class="dv">1</span><span class="sc">}</span><span class="ss">/</span><span class="sc">{</span>n_epochs<span class="sc">}</span><span class="ss">"</span>, leave<span class="op">=</span><span class="va">False</span></span>
<span id="cb30-185"><a href="#cb30-185"></a>        ):</span>
<span id="cb30-186"><a href="#cb30-186"></a>            loss <span class="op">=</span> calculate_loss(</span>
<span id="cb30-187"><a href="#cb30-187"></a>                model,</span>
<span id="cb30-188"><a href="#cb30-188"></a>                batch,</span>
<span id="cb30-189"><a href="#cb30-189"></a>                vocab_size,</span>
<span id="cb30-190"><a href="#cb30-190"></a>                device<span class="op">=</span>device,</span>
<span id="cb30-191"><a href="#cb30-191"></a>                transition_dim<span class="op">=</span>transition_dim,</span>
<span id="cb30-192"><a href="#cb30-192"></a>                observation_dim<span class="op">=</span>observation_dim,</span>
<span id="cb30-193"><a href="#cb30-193"></a>                action_dim<span class="op">=</span>action_dim,</span>
<span id="cb30-194"><a href="#cb30-194"></a>                reward_dim<span class="op">=</span>reward_dim,</span>
<span id="cb30-195"><a href="#cb30-195"></a>                value_dim<span class="op">=</span>value_dim,</span>
<span id="cb30-196"><a href="#cb30-196"></a>            )</span>
<span id="cb30-197"><a href="#cb30-197"></a></span>
<span id="cb30-198"><a href="#cb30-198"></a>            _batch_tokens <span class="op">=</span> batch[<span class="dv">0</span>].reshape(<span class="op">-</span><span class="dv">1</span>).shape[<span class="dv">0</span>]</span>
<span id="cb30-199"><a href="#cb30-199"></a></span>
<span id="cb30-200"><a href="#cb30-200"></a>            <span class="co"># write learning rate to tensorboard</span></span>
<span id="cb30-201"><a href="#cb30-201"></a>            writer.add_scalar(<span class="st">"Learning rate"</span>, scheduler.get_current_lr(), step)</span>
<span id="cb30-202"><a href="#cb30-202"></a></span>
<span id="cb30-203"><a href="#cb30-203"></a>            scheduler.step(batch_size<span class="op">=</span>_batch_tokens)</span>
<span id="cb30-204"><a href="#cb30-204"></a>            optimizer.zero_grad()</span>
<span id="cb30-205"><a href="#cb30-205"></a>            loss.backward()</span>
<span id="cb30-206"><a href="#cb30-206"></a>            <span class="cf">if</span> clip_grad <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span>:</span>
<span id="cb30-207"><a href="#cb30-207"></a>                torch.nn.utils.clip_grad_norm_(model.parameters(), clip_grad)</span>
<span id="cb30-208"><a href="#cb30-208"></a>            optimizer.step()</span>
<span id="cb30-209"><a href="#cb30-209"></a></span>
<span id="cb30-210"><a href="#cb30-210"></a>            writer.add_scalar(<span class="st">"Loss/train"</span>, loss.item(), step)</span>
<span id="cb30-211"><a href="#cb30-211"></a>            total_loss <span class="op">+=</span> loss.item()</span>
<span id="cb30-212"><a href="#cb30-212"></a>            step <span class="op">+=</span> <span class="dv">1</span></span>
<span id="cb30-213"><a href="#cb30-213"></a>        writer.add_scalar(<span class="st">"Epoch"</span>, epoch, epoch)</span>
<span id="cb30-214"><a href="#cb30-214"></a>        end_time <span class="op">=</span> time.time()</span>
<span id="cb30-215"><a href="#cb30-215"></a>        writer.add_scalar(<span class="st">"Time/train"</span>, end_time <span class="op">-</span> start_time, epoch)</span>
<span id="cb30-216"><a href="#cb30-216"></a></span>
<span id="cb30-217"><a href="#cb30-217"></a>        train_accuracy <span class="op">=</span> calculate_predictive_accuracy(</span>
<span id="cb30-218"><a href="#cb30-218"></a>            model, train_dataloader, device<span class="op">=</span>device</span>
<span id="cb30-219"><a href="#cb30-219"></a>        )</span>
<span id="cb30-220"><a href="#cb30-220"></a>        <span class="cf">if</span> <span class="bu">len</span>(test_dataloader) <span class="op">&gt;</span> <span class="dv">0</span>:</span>
<span id="cb30-221"><a href="#cb30-221"></a>            test_accuracy <span class="op">=</span> calculate_predictive_accuracy(</span>
<span id="cb30-222"><a href="#cb30-222"></a>                model, test_dataloader, device<span class="op">=</span>device</span>
<span id="cb30-223"><a href="#cb30-223"></a>            )</span>
<span id="cb30-224"><a href="#cb30-224"></a>        <span class="cf">else</span>:</span>
<span id="cb30-225"><a href="#cb30-225"></a>            test_accuracy <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb30-226"><a href="#cb30-226"></a>        writer.add_scalar(<span class="st">"Accuracy/train"</span>, train_accuracy, epoch)</span>
<span id="cb30-227"><a href="#cb30-227"></a>        writer.add_scalar(<span class="st">"Accuracy/test"</span>, test_accuracy, epoch)</span>
<span id="cb30-228"><a href="#cb30-228"></a></span>
<span id="cb30-229"><a href="#cb30-229"></a>        <span class="cf">for</span> name, param <span class="kw">in</span> model.named_parameters():</span>
<span id="cb30-230"><a href="#cb30-230"></a>            <span class="cf">if</span> param.requires_grad:</span>
<span id="cb30-231"><a href="#cb30-231"></a>                writer.add_histogram(<span class="ss">f"weights/</span><span class="sc">{</span>name<span class="sc">}</span><span class="ss">"</span>, param.data.cpu().numpy(), epoch)</span>
<span id="cb30-232"><a href="#cb30-232"></a>                writer.add_histogram(</span>
<span id="cb30-233"><a href="#cb30-233"></a>                    <span class="ss">f"gradients/</span><span class="sc">{</span>name<span class="sc">}</span><span class="ss">"</span>, param.grad.cpu().numpy(), epoch</span>
<span id="cb30-234"><a href="#cb30-234"></a>                )</span>
<span id="cb30-235"><a href="#cb30-235"></a></span>
<span id="cb30-236"><a href="#cb30-236"></a>        <span class="co"># +1 because this operation is pointless to do for first epoch.</span></span>
<span id="cb30-237"><a href="#cb30-237"></a>        <span class="cf">if</span> (epoch) <span class="op">%</span> eval_every <span class="op">==</span> <span class="dv">0</span>:</span>
<span id="cb30-238"><a href="#cb30-238"></a>            start_time <span class="op">=</span> time.time()</span>
<span id="cb30-239"><a href="#cb30-239"></a></span>
<span id="cb30-240"><a href="#cb30-240"></a>            (</span>
<span id="cb30-241"><a href="#cb30-241"></a>                mean_rewards,</span>
<span id="cb30-242"><a href="#cb30-242"></a>                std_rewards,</span>
<span id="cb30-243"><a href="#cb30-243"></a>                done_ratio,</span>
<span id="cb30-244"><a href="#cb30-244"></a>                mean_rollout_time,</span>
<span id="cb30-245"><a href="#cb30-245"></a>                std_rollout_time,</span>
<span id="cb30-246"><a href="#cb30-246"></a>                total_rewards,  <span class="co"># total_rewards</span></span>
<span id="cb30-247"><a href="#cb30-247"></a>            ) <span class="op">=</span> vec_eval(</span>
<span id="cb30-248"><a href="#cb30-248"></a>                env,</span>
<span id="cb30-249"><a href="#cb30-249"></a>                model,</span>
<span id="cb30-250"><a href="#cb30-250"></a>                discretizer,</span>
<span id="cb30-251"><a href="#cb30-251"></a>                num_episodes<span class="op">=</span><span class="dv">10</span> <span class="cf">if</span> <span class="kw">not</span> local <span class="cf">else</span> <span class="dv">1</span>,</span>
<span id="cb30-252"><a href="#cb30-252"></a>                beam_width<span class="op">=</span><span class="dv">32</span> <span class="cf">if</span> <span class="kw">not</span> local <span class="cf">else</span> <span class="dv">2</span>,</span>
<span id="cb30-253"><a href="#cb30-253"></a>                beam_steps<span class="op">=</span><span class="dv">5</span> <span class="cf">if</span> <span class="kw">not</span> local <span class="cf">else</span> <span class="dv">2</span>,</span>
<span id="cb30-254"><a href="#cb30-254"></a>                beam_context<span class="op">=</span><span class="dv">5</span> <span class="cf">if</span> <span class="kw">not</span> local <span class="cf">else</span> <span class="dv">2</span>,</span>
<span id="cb30-255"><a href="#cb30-255"></a>                sample_expansion<span class="op">=</span><span class="dv">2</span> <span class="cf">if</span> <span class="kw">not</span> local <span class="cf">else</span> <span class="dv">1</span>,</span>
<span id="cb30-256"><a href="#cb30-256"></a>                observation_dim<span class="op">=</span>observation_dim,</span>
<span id="cb30-257"><a href="#cb30-257"></a>                action_dim<span class="op">=</span>action_dim,</span>
<span id="cb30-258"><a href="#cb30-258"></a>                reward_dim<span class="op">=</span>reward_dim,</span>
<span id="cb30-259"><a href="#cb30-259"></a>                value_dim<span class="op">=</span>value_dim,</span>
<span id="cb30-260"><a href="#cb30-260"></a>                transition_dim<span class="op">=</span>transition_dim,</span>
<span id="cb30-261"><a href="#cb30-261"></a>                plan_every<span class="op">=</span><span class="dv">1</span> <span class="cf">if</span> <span class="kw">not</span> local <span class="cf">else</span> <span class="dv">2</span>,</span>
<span id="cb30-262"><a href="#cb30-262"></a>                obs_top_k<span class="op">=</span><span class="dv">1</span>,</span>
<span id="cb30-263"><a href="#cb30-263"></a>                act_top_k<span class="op">=</span><span class="va">None</span>,</span>
<span id="cb30-264"><a href="#cb30-264"></a>                rew_top_k<span class="op">=</span><span class="dv">1</span>,</span>
<span id="cb30-265"><a href="#cb30-265"></a>                temperature<span class="op">=</span><span class="fl">1.0</span>,</span>
<span id="cb30-266"><a href="#cb30-266"></a>                greedy<span class="op">=</span><span class="va">False</span>,</span>
<span id="cb30-267"><a href="#cb30-267"></a>                device<span class="op">=</span>device,</span>
<span id="cb30-268"><a href="#cb30-268"></a>            )</span>
<span id="cb30-269"><a href="#cb30-269"></a>            writer.add_scalar(<span class="st">"Reward/mean"</span>, mean_rewards, epoch)</span>
<span id="cb30-270"><a href="#cb30-270"></a>            writer.add_scalar(<span class="st">"Reward/std"</span>, std_rewards, epoch)</span>
<span id="cb30-271"><a href="#cb30-271"></a>            writer.add_scalar(<span class="st">"Done ratio"</span>, done_ratio, epoch)</span>
<span id="cb30-272"><a href="#cb30-272"></a>            writer.add_scalar(<span class="st">"Rollout time/mean"</span>, mean_rollout_time, epoch)</span>
<span id="cb30-273"><a href="#cb30-273"></a>            writer.add_scalar(<span class="st">"Rollout time/std"</span>, std_rollout_time, epoch)</span>
<span id="cb30-274"><a href="#cb30-274"></a></span>
<span id="cb30-275"><a href="#cb30-275"></a>            <span class="co"># log total_rewards as histogram</span></span>
<span id="cb30-276"><a href="#cb30-276"></a>            total_rewards <span class="op">=</span> np.array(total_rewards)</span>
<span id="cb30-277"><a href="#cb30-277"></a>            writer.add_histogram(<span class="st">"Total rewards"</span>, total_rewards, epoch)</span>
<span id="cb30-278"><a href="#cb30-278"></a></span>
<span id="cb30-279"><a href="#cb30-279"></a>            end_time <span class="op">=</span> time.time()</span>
<span id="cb30-280"><a href="#cb30-280"></a>            writer.add_scalar(<span class="st">"Time/eval"</span>, end_time <span class="op">-</span> start_time, epoch)</span>
<span id="cb30-281"><a href="#cb30-281"></a></span>
<span id="cb30-282"><a href="#cb30-282"></a>        <span class="cf">if</span> checkpoint_path:</span>
<span id="cb30-283"><a href="#cb30-283"></a>            torch.save(model.state_dict(), checkpoint_path <span class="op">+</span> <span class="ss">f"model_</span><span class="sc">{</span>epoch<span class="sc">}</span><span class="ss">.pth"</span>)</span>
<span id="cb30-284"><a href="#cb30-284"></a>            torch.save(optimizer.state_dict(), checkpoint_path <span class="op">+</span> <span class="st">"optimizer.pth"</span>)</span>
<span id="cb30-285"><a href="#cb30-285"></a></span>
<span id="cb30-286"><a href="#cb30-286"></a>        writer.flush()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
</section>
</section>
<section id="hardware-training-details" class="level3" data-number="12.6">
<h3 data-number="12.6" class="anchored" data-anchor-id="hardware-training-details"><span class="header-section-number">12.6</span> Hardware &amp; Training Details</h3>
<p>This notebook was developed and tested on different hardware setups to balance ease of development and computational efficiency:</p>
<section id="development-setup" class="level4" data-number="12.6.1">
<h4 data-number="12.6.1" class="anchored" data-anchor-id="development-setup"><span class="header-section-number">12.6.1</span> Development Setup:</h4>
<ul>
<li><strong>Device</strong>: 2024 M3 MacBook Air</li>
<li><strong>Specs</strong>: 16GB RAM</li>
<li><strong>Limitation</strong>: Model training and rollouts could not run due to insufficient compute power.</li>
</ul>
</section>
<section id="final-training-rollout-setup" class="level4" data-number="12.6.2">
<h4 data-number="12.6.2" class="anchored" data-anchor-id="final-training-rollout-setup"><span class="header-section-number">12.6.2</span> Final Training &amp; Rollout Setup:</h4>
<ul>
<li><strong>Instance</strong>: Rented from <a href="https://cloud.vast.ai/">vast.ai</a> at $0.2/hr</li>
<li><strong>Specs</strong>:
<ul>
<li><strong>GPU</strong>: 1× RTX 4070S</li>
<li><strong>CPU</strong>: AMD Ryzen 9 7950X (16-Core)</li>
<li><strong>RAM</strong>: 64GB</li>
<li><strong>Storage</strong>: 49.2GB available disk space</li>
</ul></li>
</ul>
</section>
<section id="training-time" class="level4" data-number="12.6.3">
<h4 data-number="12.6.3" class="anchored" data-anchor-id="training-time"><span class="header-section-number">12.6.3</span> Training Time:</h4>
<ul>
<li>Full training, including evaluations, took approximately 10 hours.</li>
</ul>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="img/offline_rl/train_eval_time.png" class="img-fluid figure-img"></p>
<figcaption>Training/Eval Times</figcaption>
</figure>
</div>
<div id="cell-40" class="cell">
<details class="code-fold">
<summary>Main training runner</summary>
<div class="sourceCode cell-code" id="cb31"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb31-1"><a href="#cb31-1"></a><span class="bu">print</span>(<span class="ss">f"Using device: </span><span class="sc">{</span>device<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb31-2"><a href="#cb31-2"></a>writer <span class="op">=</span> SummaryWriter()</span>
<span id="cb31-3"><a href="#cb31-3"></a></span>
<span id="cb31-4"><a href="#cb31-4"></a>dataset.discretizer.to(device)</span>
<span id="cb31-5"><a href="#cb31-5"></a><span class="co"># split the dataset into train and test</span></span>
<span id="cb31-6"><a href="#cb31-6"></a>train_size <span class="op">=</span> <span class="bu">int</span>(<span class="bu">len</span>(dataset) <span class="op">*</span> <span class="fl">1.0</span>)</span>
<span id="cb31-7"><a href="#cb31-7"></a>test_size <span class="op">=</span> <span class="bu">len</span>(dataset) <span class="op">-</span> train_size</span>
<span id="cb31-8"><a href="#cb31-8"></a>train_dataset, test_dataset <span class="op">=</span> torch.utils.data.random_split(</span>
<span id="cb31-9"><a href="#cb31-9"></a>    dataset, [train_size, test_size]</span>
<span id="cb31-10"><a href="#cb31-10"></a>)</span>
<span id="cb31-11"><a href="#cb31-11"></a>train_dataloader <span class="op">=</span> DataLoader(</span>
<span id="cb31-12"><a href="#cb31-12"></a>    train_dataset,</span>
<span id="cb31-13"><a href="#cb31-13"></a>    batch_size<span class="op">=</span>batch_size,</span>
<span id="cb31-14"><a href="#cb31-14"></a>    num_workers<span class="op">=</span><span class="dv">8</span> <span class="cf">if</span> <span class="kw">not</span> local <span class="cf">else</span> <span class="dv">0</span>,</span>
<span id="cb31-15"><a href="#cb31-15"></a>    shuffle<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb31-16"><a href="#cb31-16"></a>    pin_memory<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb31-17"><a href="#cb31-17"></a>)</span>
<span id="cb31-18"><a href="#cb31-18"></a>test_dataloader <span class="op">=</span> DataLoader(</span>
<span id="cb31-19"><a href="#cb31-19"></a>    test_dataset,</span>
<span id="cb31-20"><a href="#cb31-20"></a>    batch_size<span class="op">=</span>batch_size,</span>
<span id="cb31-21"><a href="#cb31-21"></a>    shuffle<span class="op">=</span><span class="va">False</span>,</span>
<span id="cb31-22"><a href="#cb31-22"></a>)</span>
<span id="cb31-23"><a href="#cb31-23"></a>model <span class="op">=</span> TrajectoryTransformer(</span>
<span id="cb31-24"><a href="#cb31-24"></a>    seq_len,</span>
<span id="cb31-25"><a href="#cb31-25"></a>    embedding_dim,</span>
<span id="cb31-26"><a href="#cb31-26"></a>    n_heads,</span>
<span id="cb31-27"><a href="#cb31-27"></a>    transition_dim,</span>
<span id="cb31-28"><a href="#cb31-28"></a>    n_blocks,</span>
<span id="cb31-29"><a href="#cb31-29"></a>    vocab_size,</span>
<span id="cb31-30"><a href="#cb31-30"></a>    use_sep_heads<span class="op">=</span>use_sep_heads,</span>
<span id="cb31-31"><a href="#cb31-31"></a>).to(device)</span>
<span id="cb31-32"><a href="#cb31-32"></a></span>
<span id="cb31-33"><a href="#cb31-33"></a>warmup_tokens <span class="op">=</span> <span class="bu">len</span>(train_dataset) <span class="op">*</span> seq_len</span>
<span id="cb31-34"><a href="#cb31-34"></a>final_tokens <span class="op">=</span> n_epochs <span class="op">*</span> warmup_tokens</span>
<span id="cb31-35"><a href="#cb31-35"></a></span>
<span id="cb31-36"><a href="#cb31-36"></a><span class="co"># write hyper parameters</span></span>
<span id="cb31-37"><a href="#cb31-37"></a>writer.add_hparams(</span>
<span id="cb31-38"><a href="#cb31-38"></a>    {</span>
<span id="cb31-39"><a href="#cb31-39"></a>        <span class="st">"seq_len"</span>: seq_len,</span>
<span id="cb31-40"><a href="#cb31-40"></a>        <span class="st">"embedding_dim"</span>: embedding_dim,</span>
<span id="cb31-41"><a href="#cb31-41"></a>        <span class="st">"n_heads"</span>: n_heads,</span>
<span id="cb31-42"><a href="#cb31-42"></a>        <span class="st">"transition_dim"</span>: transition_dim,</span>
<span id="cb31-43"><a href="#cb31-43"></a>        <span class="st">"n_blocks"</span>: n_blocks,</span>
<span id="cb31-44"><a href="#cb31-44"></a>        <span class="st">"vocab_size"</span>: vocab_size,</span>
<span id="cb31-45"><a href="#cb31-45"></a>        <span class="st">"use_sep_heads"</span>: use_sep_heads,</span>
<span id="cb31-46"><a href="#cb31-46"></a>        <span class="st">"weight_decay"</span>: weight_decay,</span>
<span id="cb31-47"><a href="#cb31-47"></a>        <span class="st">"lr"</span>: lr,</span>
<span id="cb31-48"><a href="#cb31-48"></a>        <span class="st">"betas"</span>: torch.tensor(betas),</span>
<span id="cb31-49"><a href="#cb31-49"></a>        <span class="st">"batch_size"</span>: batch_size,</span>
<span id="cb31-50"><a href="#cb31-50"></a>        <span class="st">"n_epochs"</span>: n_epochs,</span>
<span id="cb31-51"><a href="#cb31-51"></a>        <span class="st">"eval_every"</span>: eval_every,</span>
<span id="cb31-52"><a href="#cb31-52"></a>        <span class="st">"clip_grad"</span>: clip_grad,</span>
<span id="cb31-53"><a href="#cb31-53"></a>        <span class="st">"warmup_tokens"</span>: warmup_tokens,</span>
<span id="cb31-54"><a href="#cb31-54"></a>        <span class="st">"final_tokens"</span>: final_tokens,</span>
<span id="cb31-55"><a href="#cb31-55"></a>        <span class="st">"env_name"</span>: env.name,</span>
<span id="cb31-56"><a href="#cb31-56"></a>    },</span>
<span id="cb31-57"><a href="#cb31-57"></a>    {},</span>
<span id="cb31-58"><a href="#cb31-58"></a>)</span>
<span id="cb31-59"><a href="#cb31-59"></a></span>
<span id="cb31-60"><a href="#cb31-60"></a>optimizer <span class="op">=</span> get_optimizer(model, weight_decay, lr, betas)</span>
<span id="cb31-61"><a href="#cb31-61"></a>scheduler <span class="op">=</span> get_scheduler(optimizer, warmup_tokens, final_tokens)</span>
<span id="cb31-62"><a href="#cb31-62"></a><span class="cf">if</span> load_checkpoint:</span>
<span id="cb31-63"><a href="#cb31-63"></a>    <span class="bu">print</span>(<span class="ss">f"Loading model from </span><span class="sc">{</span>checkpoint_path<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb31-64"><a href="#cb31-64"></a>    model_files <span class="op">=</span> glob.glob(checkpoint_path <span class="op">+</span> <span class="st">"model*.pth"</span>)</span>
<span id="cb31-65"><a href="#cb31-65"></a>    <span class="cf">if</span> model_files:</span>
<span id="cb31-66"><a href="#cb31-66"></a>        latest_model_file <span class="op">=</span> <span class="bu">max</span>(model_files, key<span class="op">=</span>os.path.getctime)</span>
<span id="cb31-67"><a href="#cb31-67"></a>        <span class="bu">print</span>(<span class="ss">f"Loading model from </span><span class="sc">{</span>latest_model_file<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb31-68"><a href="#cb31-68"></a>        model.load_state_dict(torch.load(latest_model_file, map_location<span class="op">=</span>device))</span>
<span id="cb31-69"><a href="#cb31-69"></a>    <span class="cf">else</span>:</span>
<span id="cb31-70"><a href="#cb31-70"></a>        <span class="bu">print</span>(<span class="st">"No model files found, starting training from scratch."</span>)</span>
<span id="cb31-71"><a href="#cb31-71"></a>        <span class="cf">raise</span> <span class="pp">ValueError</span>(<span class="st">"No model files found, starting training from scratch."</span>)</span>
<span id="cb31-72"><a href="#cb31-72"></a>    optimizer.load_state_dict(</span>
<span id="cb31-73"><a href="#cb31-73"></a>        torch.load(checkpoint_path <span class="op">+</span> <span class="st">"optimizer.pth"</span>, map_location<span class="op">=</span>device)</span>
<span id="cb31-74"><a href="#cb31-74"></a>    )</span>
<span id="cb31-75"><a href="#cb31-75"></a><span class="cf">else</span>:</span>
<span id="cb31-76"><a href="#cb31-76"></a>    train(</span>
<span id="cb31-77"><a href="#cb31-77"></a>        model,</span>
<span id="cb31-78"><a href="#cb31-78"></a>        train_dataloader,</span>
<span id="cb31-79"><a href="#cb31-79"></a>        test_dataloader,</span>
<span id="cb31-80"><a href="#cb31-80"></a>        dataset.discretizer,</span>
<span id="cb31-81"><a href="#cb31-81"></a>        optimizer,</span>
<span id="cb31-82"><a href="#cb31-82"></a>        scheduler,</span>
<span id="cb31-83"><a href="#cb31-83"></a>        vocab_size,</span>
<span id="cb31-84"><a href="#cb31-84"></a>        n_epochs,</span>
<span id="cb31-85"><a href="#cb31-85"></a>        writer,</span>
<span id="cb31-86"><a href="#cb31-86"></a>        device<span class="op">=</span>device,</span>
<span id="cb31-87"><a href="#cb31-87"></a>        eval_every<span class="op">=</span>eval_every,</span>
<span id="cb31-88"><a href="#cb31-88"></a>        checkpoint_path<span class="op">=</span>checkpoint_path,</span>
<span id="cb31-89"><a href="#cb31-89"></a>        clip_grad<span class="op">=</span>clip_grad,</span>
<span id="cb31-90"><a href="#cb31-90"></a>    )</span>
<span id="cb31-91"><a href="#cb31-91"></a>    <span class="bu">print</span>(<span class="ss">f"Saved checkpoint to </span><span class="sc">{</span>checkpoint_path<span class="sc">}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>Using device: mps</code></pre>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"76ae2b69930047a0b603bdf9480b9488","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"7eb0b250aa2a46f8ad820c5ee4dbaffe","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"5a05d35974004946810ae21091c26b89","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>/Users/abrar/Library/Caches/pypoetry/virtualenvs/blog-FROQ9Grm-py3.11/lib/python3.11/site-packages/gymnasium/envs/registration.py:525: UserWarning: WARN: Using the latest versioned environment `HalfCheetah-v5` instead of the unversioned environment `HalfCheetah`.
  logger.warn(</code></pre>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"dc0d7a781ef8458183ce0087f7927fc4","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"8a7f2511987b475c8e5043be12121139","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"a2a93391902f466d99300cce0549d966","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"0e35c2a0ee9d48adae0d8c9b51f74d79","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"00566b1244cd424e90bf6f1038ba13d5","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"3e605615d9f64fc895a7a9c55414c1b9","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"63690b6707ee494eb2177cb72171fcce","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"3635cde182d44eac97161654fa522fa6","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"6e23e3c8aedd44bcab34e46d2c8ca732","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"1deb8146d4b04cad9c8ac03629c49d66","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"d5c91ca820844413ae527b98e31b0dbf","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"3c7ff4a9545e481b9011e3a047a76203","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"4c62761cdf324a4a912b670a51034329","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"c99816e4b9754ead95c2e8602fc69b53","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"6aa8c38ec844475598bc2f3985170df9","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"838e7da033fc4ebd987169879f2cc0ab","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"608bf883842f4a2e9f4f90ab0f6410ca","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"ec6814057fbd454d941fa90cc495ad40","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"f0798e0914ce4094b1ba4815b345a23e","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"71966e731c2e4a1ab87b1f170b124099","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"96c73fb79d11481a9d21cdc508c33c4c","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"dfc9e47fefdc4911b9f5176c0cfa71f5","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"4081cdf5664149efb31a67f9cbdb3915","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"1603066b1ace4cfc9769df6d23be5396","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"76211eaabf394bafacfb403b47ad6dba","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"d5c4ce7df20143a7b31fd3b9b8e10793","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"250aded5a7094eb096053498536555af","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"7dab68062b8b49138accde8f45f83147","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"38e768ad83e84b76aa54f4f9820b5eba","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"d29380654c6e4bec87fec03e5ce1bd7a","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"c5737336b957492c9521d7435f2b1d6f","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"2ed8b4d95a954e27b27446e0a3bb4ba1","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"44c7f4d2e48843a4ab8a47243d4780a8","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"fa2ad4ddb398497692953ec745924239","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"1b971f232e06420dba7a0b7654425042","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"11dec3b7a46648dca4c44a9c48a37462","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"d172b0cb66d240de903a70b2b9e9a771","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"9d3c74a5e84549f4a3da7af9cd162e54","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"af02c70024854f27b24ca0323ff16843","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"e5439532eb8a4bd18dbb3dbae4b547e0","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"a3897f66f0ed436da3b829a42bdf2531","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"d4669771ef0c45d2a39ee4dc3f48bee1","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"d5d4e8f09e2e443e8fb03e9f47fff1f1","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"10b1dacbaa8e4633aef095a9de4d7f07","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"729e1c921bc14ee88d6cb8a4e8cc402a","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"ea0fe359342a4d6da9b7b9adeabe5b5c","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"a4c561ccff20431fb4a1af5f0b4fa8b6","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"17ec9194d1764625af768566b7ccb77d","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"fee0e4c69fc84c4184d31ccc21f83c41","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"a68f0eff938e47f383328a3c5c90469b","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"cb5cdb6005d04bed898cf4ea30c95324","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"3a1d04050f1846639f51b86dc65a1f7b","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"a9eaeeaefba7475ab520fed6d7933e08","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"45e996f1199943bf951ffc3e9261ec27","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"2d25c2cd380a4c4aa2348c3c5a2c8b7f","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"9432d72b65fc45cc9cbd8c3bd90a13e6","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"61bf7b65bba94605b1be18979be0ce8d","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"78c79cd12a6f4baf80c02fb0dbba86a6","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"63a513d0a4104e1b83988551515d6845","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"6713ea6f13dc4742996710e31dce00a9","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"7f1db34510884dd9a4b2a7abb704b6a3","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"26f58a5bdf7e4aeaae85ad3e576af547","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"39bcf704f374408aa1f376bb5ffc88ec","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"11bd6a762fdb408dae215b804a69c7b9","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"4b39236c68424154a3d574b5ddf52d3f","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"ac47b2d203a846e7841870fc563b0357","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"31143b60b5904ad29d5893a04db67079","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"e5314acb6493477b81858d0725ce188b","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"55e2af82e162447ca332a219324430f6","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"77bcf0ae53734bda8d22ba1f772c1336","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"8feb7fb1dc784f728cb022dcf882532a","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"da38cdb952aa4fe9af16db46605d6887","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"5989fcb032814f849b7f06a167b23bf4","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"e77d3ef2f8774fc2a0f82da406828080","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"bd74e09785474b14ad5d03ad0852b5fe","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"fe467b6ebef3412c8d49598dbd036fda","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"8625cbe316b04a959e251960b1b07537","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"5754570da2974e2dadf9b97daccb696e","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"678820c8890a4d17bc63b7df3dbe35f3","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"1e10ecb7c1f04554a542324549ada47b","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"d940a9c024414002b688e241d1edbfc8","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"0928b00e74254b0582088ea948eddcb0","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"6946f832769445f8955c13170b33171f","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"c7c1659789214ee9ad1ef969d6503893","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"2a3af41db75242c39c2f5b3dacf70647","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"9e20e44b4dc745da93e3aee237135a10","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"d49d059b98834c759577c3854056b4ab","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"ba22543fdf36440ca77d5d5faae570e3","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"8755d99e0f194d8fba38cd5ac0a64201","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"2f5711de9d73484bb959b7653f86bf60","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"171120f44d42468aba6db437a9402582","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"b00e88d2ba9f4327a5c549b9ef22c9b3","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"eb172f9c2a9841468239a82a36516870","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"404d6eaa453e425ca527cf3c2140f5cb","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"8b3309e151d04f6295eca464b325ef84","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"4f6dd7f5e04141e89f1acc973d8050cf","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"124aa768c0e347d39d5c4e561e7981a6","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"25ae4f29b20c4703a5f9cf2cbd4a5dd3","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"e6a0cf24cda24a22bbf9a60e0c649170","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"a8d6e6d27bf444a5afe45b21201b197b","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"0e7ed4373dff4b0487c27e663ad7199b","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"4299036a38444b87ac442ed5913a2959","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"84d85a1591fb4d7398f2e17de2375cb6","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"f143e8eff7ab4ff380e03242b2dba08e","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"d2dd781f64a74d829461206e8f84ad36","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"ef9e4306b75c461db6cda4a47e02da20","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"c964218f28d0444a82af68c5aaa5742d","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"a54dc18a33054939b26c50e81e9b70ee","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"2e71a5da88f94629adfcd973552f58b2","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"a083940e4e8f43a7a6a508e36cc9b4c7","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"4798d92f420a43d5b6d1d775fc28e9bd","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"a7076f0d025e47f4931c9e7f4f260907","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"32c404e4809b4ce382e24bdfcb62f312","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"e815de880cc34995acf799206afbc38a","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"a4d5bfa98cac4fc0b7b71e7d9c6c546b","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"6dc25ef1d7934090940a9847ebb18725","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"cf8c6511aa1446399ceba87becea5dc0","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"326e3a2164bc45f8a3ffb3925f5eb161","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"b5d3172264954c1fad8f002bc186b988","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"a3cde096386e4e9799350506566ef68c","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"b8502164b57640d289523fce6cc56d57","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"148214f408a74f8ab6f29189a2dffd0e","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"beb0c9656dcb4cdbbb6f60ab3c7c17d8","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"b89eaef585084365af6247acc5e4ffb3","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"c1afbc56e2ce46cbaf39b923ff509f12","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"29ffa1612c714c86a9b9b25afba83dbd","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"5f3161fafe8b445896eeb745e98d56be","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"6152e24a37cc4ecca65c5873b5120bce","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"6d07c6320ae64048a89527ecf9e5502d","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"451aa356a6674b36b61d49c805ba75ae","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"e1416be5d70944e08726d7c34a016c52","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"4340dffc081a4161a2efcac21eb65022","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"275854ac468444b194851edc04b9d716","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"b1dbd113b84247119b84a6e7f8c0382e","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"e5675e0402d94bc5a193ecc9130a6a4c","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"1e1885a2d62f4088ad7e808d664856fa","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"f514196ca36a4f758714300bea80a552","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"86ef02b2c44a458e9b69981f91691b41","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"f70cc4cce8bb415ab0a21d398c5300e7","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"0f6a69d66aec4ed88a3aeb579263ec08","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"52888c424cd843a1a6178136a6c7a9e5","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"70da65e03cfd4c54be84965a5c399cab","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"85cf4016c4cf4dc49a9a20490daab094","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"bb8272db1da643b88a84390e348c9f1a","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"b73477f91b824a3a959571f8e285cc17","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"17b509d6a8f54c3e8655c84586a6a0a5","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"dc95754c46e04db4a497d59cfdf00de3","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"f4079c53f050422a8c09ae5fe5f8b4c8","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"93975251a53f47a5910073f09c38235d","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"7dc8d1b8a7754c23a82d150a4d463b52","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"10593f16e1254517ad69d8a5582b4366","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"e2e50c5eca9243b18976ffea226c1f04","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"59a3627220ad40358ad9af5907878090","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"9137cf72f8cd4d4b9b2045ae3ea9f7c3","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"d7de2b9374d048cc8634b9a4a8a7faef","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"07601f09df054295adf22c29f8c1bf83","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"482ab5a04dfd46aab132fcffcad91339","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"709ceb0544d44152a47c91ce146c371e","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"9339b41176544c29912b57d42772d0fe","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"f5f7ff151a1a4d5aa0d525c56010afa4","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"a403becd42de422983cfe30351a6888b","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"48c91dcbacf34547b3fdbdb86f98e2ca","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"6b67780af72b4f99a24b16c10f40cb96","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"cd117f0991b14f45a2e27219e34202a1","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"2f4322fa599a4eb2bbbf5b93b0f7ae07","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"b23533fe434343f88e835b0a75325ef7","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"fb4e396902e0406a9cfb54d8c2d905f9","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"7a62924093384c79b10f9a6b0a97d05b","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"c5f71f9fb820413fb22290d85f8cd5c5","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"6445154851624fd6ad14b310455b12c9","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"2e1c7410268b4c168514dc35902dcf31","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"3e1dcd8930774e189085414dabaf40dd","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"85ec35ff77c24a4991c5b2ffe935f7ea","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"e5754c40440b4b0daeb7414104b0917d","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"fe071ac7ede44b75a49141ce5efc84f0","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"4b549ef471854313af3172043423ce55","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"ade199ca0c1a4415bc591d0a45f45451","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"073449974470465aaf1d5102222bf36e","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"feaa3d8e3f6f4f628ea1ec05f72a4f83","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"ff6b6c1e5c6e480bbe1594815abb4a51","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"a3dc034a13d74b558660d1ce863ff41d","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"49e1024e9e184e0ca59dfb3166a3f8dc","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"4e4d77c7100d4566a4993b352ea8ff9c","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"02d72730189f49308f56378b4c867db9","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"6470522811034b5d82c1c7c4601c0d4a","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"8d505e1671ba4803ba11ccc5618fa0d3","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"8bdae29b7b584b4bbd920a95fef4da80","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"053c698b51e647cf9cd3f2e3ffb77404","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"1f22f605a5d84f1da35253016117705e","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"58af86788060471dae00f090f839271a","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"7c91567d78ed4e399728008e2744810c","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"1cfe33202e25435c98cb67e6bcd73adb","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"65ca55e9a70f496f817782f1ca0a564f","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"9cb863193a994b8c83e4e09331743c43","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"ca0fd1f47d9f4e5d8862cbd99851595d","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"ba7a23890d8f4ac8ba30854a2aa7464c","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"dcae7f180f554fada4773584c0a6c5f9","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"1e33d905336e40f6b0e2c00af9b6b28a","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"4567e513fa074974b228bdb16ea037cb","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"77b3f85e37b34f8192f00032590bd253","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"665cb3c23a0d4090b76592869e0795ae","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"8841a0290ef54ec9aa0156fb4b65edea","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"1527109959464cbdadddd02f954a0565","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"253a9e7bdce8460d9eb7e752dd11ae13","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"b3224ed080f04e50b014ef83fc95bc6c","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"87200a6109754fcaa459bf98edfe6f0d","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"7532bffed7714ed2af56bd4657190a08","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"7c673be2875f410cb3ab37ef93140e26","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"e33e68d85f404e43a5c46039cb2e0f28","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"e73abe6d481c4682bd12f6dd70eea430","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"102f77a89db747b8b6c2d7790d581a18","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"f024599be1f04fb9b2389aed569f3ac9","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"2eab40692b414120a9fa96bf5a60168e","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"d77340e083ad41a7a6843c9956e15b03","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"dda8acb400db4eacb7c3ac024258ac19","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"9ecce34e66464585b3de7cb62e8d8a51","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"b03cf7b29fac418498bb84911fd8430c","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"4920268bb98d45efbc7a58ffa46b40b0","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"86a675f6a50a4bc69cb6bd52ba4bfdab","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"f91c71ee5bbc4e1e9711e2db83556c6a","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"e286add59fa74be1ad78d84e6faa8228","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"0eeef74b318c4b578ee01d5a969d4656","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"c39b3c8e280344879c58ca69e249499d","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"741fb9c24c934ae4a8427d65343ef11f","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"c7d8500601614e418016cbbf3157836b","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"e1c89f5547404a14ae9d9223df9a921d","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"c839c314175340799068132fcfcdd8ce","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"b88e45aeb4ad4849bc940efeba33e050","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"e803f0eb819d45efb95182bd5fd67360","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"98dcbce73c7b4893b34bf213bb53c5e1","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"aff34852d1464194a0305374ada06da1","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"c557817dbd294690bf76f2506702d1e7","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"6f0f72ed1bf642c18c8dbd58577d929d","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"f66383639c054995ad0942546fd16c38","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"f660975d155b4301b6994b28463b22bf","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"b9ae242c0a944a24b39fe920e0e82283","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"f7ff5d1da40c4649950fd9d3a9633898","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"b970fa0e3f4e4f37bde02aec333d9b09","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"b747517b6d2b4695b831868b0ccb7b0a","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"9d2ac9cf4a584fea987bca5aae23a417","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"fc9837a6aa154c17a61dd079e36053bd","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"4a9b6cb694204aa3a7790a1aa2cc9b87","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"abee3a3b46824b8d8d813ca1d380cdd0","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"be174383e8ab4771a8b147db8fefe230","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"26ca9db1c407439396f494ddacdf4370","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"a2e47f324e084d0a8123eb980f2d4f9f","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"4debbe89d61e4faabc0e51c910f20810","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"29cd4c2ad08b457dba959ca409823b11","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"cc570e5f3287436faddc93879fb22662","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"b0554bfd871f425194963357217225a4","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"ea1d3b7cbebf4511a3ebf716f2cb0e77","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"ac522c655df04b239337d828a8d3426b","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"229d585e1a624bfc90f2c538e021de9a","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"32028cb37e15446fb87e3f0285c6429f","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"06c08ca90614405d8d025b69a38c87da","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"6defaf8855d141b9a572467f852e0d71","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"47fc66df013a465a9dc9e72c7065bca3","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"b51da2fd9d664099a3743ac80c5b62c6","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"6cc146aa03024f38ae67f053f888d0df","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"44bc0bef0518424fb36b61790bf65585","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"5618a9ab6b89450894ba04aee6516c74","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"aa9ed9aec70e44b992d6db2c1c0b734e","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"084fe353979e4450a1244cbaaf5cf602","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"6f83e759e7934420a62a03d7d81f558c","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"335aa3b4aea34372a8066debac8dff78","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"cb61e31ca86a43d089ba7409fcb1782e","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"9d1bf37e15a3409c8381dd456908423f","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"80c9fa7d570046bdb87ee49251d5e5ac","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"a56a955e513544e9a7f7efaca718b236","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"2f87a6f60dd848ba8dae2049704f1ebd","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"062eac26f2564f18bf672d165d47a326","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"284f4b5bf69b4693bc2789a89d7fc5ae","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"000a8e5b24c94974b2c3049685b43a24","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"0e5dc9db28f94faf853920a066320724","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"1a3409d2294a4b4d9f9391db03e3263b","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"ef6a65a775a94462a97e65103f1b998c","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"5f0d371e009e4c128ac8fd3f0929b379","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"d28a453a2dcc4ced8f445e500b48038b","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"e5914481ea0843ccb64b855dfd50424c","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"da2f307d8e664d989c970225ada35a6e","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"4244ff854cd947a199864c98d975c4e4","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"649e265cd35d4c1f97670a90c927324a","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"9bc4044701d746188405b6f268097893","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"6b3b692af0204a0bb1994b6c5ef275ed","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"ca39d71514aa4345b91b5e153f54d8dc","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"8c2f89e3d3dc4e5b96be78312ede1dc3","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"3c773e10509d4549858b4e2e7f5f39f0","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"20e5d346183a4586b4e781bd3f1b97eb","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"4e1b5917bc5e4331b121ebd9cd4aecf2","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"38cdaac5c8ee4373babfbd108dee8dbc","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"c6281402ea354537a52a299fd351b02d","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"04506f49cd1040728a7fe0bd37524799","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"5743b3d8ba98445c9932ac2260c3aafd","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"66e7ed436a0349319a57c36c1389c6f4","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"b22beebf15664ed0a0adb4470105d081","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"c9afbd6e5d144e33b283df8aca1aadba","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"357d96fb4a474c33b892fddabba970d4","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"ff02ecf387a8417881e23db1cca6270b","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"da39ef100ffe4ef29322a0b0039e00b2","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"967c801f51a84c1caeb94589aca2ff17","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"5d255a42984a47c1a1910bfc4f73b76d","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"c628a5ae245f4c34ae2e49aca150424a","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"0b6a9b0af0fd42e78b85810dda05698e","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"3f51f0154d4046d18a062b46dedd3c88","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"8e9627be121e43b9bad0111855fe2788","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"527ab11722ad4d5fb6a7248b2b620ff6","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"4d43aa98756c467fb289132fc2dc2239","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"eaa6aa48c0c840959ae1f65dd528f11f","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"08959299cfc04f09a8b2ba6da841c46d","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"cd91dad4ce804cce90f83b67b5b5b376","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"8ec9f29e75f84f4d917d8ed65c903e87","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"3c95125c70be40eba5e3559fc11c1358","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"f38a1480ece046b19004ca73244a0f0c","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"cd1b3178089147faaac0b4b36a454621","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"447e11fe810a4e42a2d380644e77612c","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"4482121644f2402db536e5de2438220c","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"52769fc2638c43f785f3f5f2006923f8","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"25143b69237a4b2d9c8c387443a2877b","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"20b1db0d4c0d49aea6321f57325a5777","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"8037b1cd953544ef9ce1e27e0f136405","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"0323b6b4e1ca41b795176d4a00fbccb2","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"dbbb2206795045cfbd9a5f466f3334d7","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"d2334f5c1cb848818f2b3b5a0de96a18","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"b2c6de710305452bba80e7fd7b00622a","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"4d8ee9c7da7f45d5aa50fb780fcc3c49","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"cde8665449b34262b15b5e78bea1377d","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"48b56a7d8a5743c18d99d62f059f49db","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"490d3557d9b14d5fbcfa42a0cdc3ca5e","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"6bbe48ea6f0344cba241060bdd839b54","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"8b35357771264aadbb7408a38fccad6a","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"cc1e8279eaf7426da64f122fb08158ed","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"f4eff4ac71b54aa493d4ecd3a6678991","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"969945dd0158437abb275ab7db765281","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"5f056923fdb040fe8667f54254365d08","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"bfa0e5b7e975413d836d0680b18738b8","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"7de8b8d6aa5f4be89f2e037f204f0abf","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"4594def128794939a5f910614d2081ec","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"e55377c9790e4e0ba76dcc560aeb4b24","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"d45143b7af7e4d39836437d71bce22a1","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"a469b7fa03f54ecd8d8eb1f1f794cca6","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"e39dd80108f14701bcab604e930f19f2","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"425b4efa9b294f5d97eac652214ada89","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"6232e48c7b23425684ad0794359b2773","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"9a7c2278a8e8430781e2cf7fcfe0a5ec","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"34de444272e74d53b2678a3418ac9723","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"10c9e834b2c943c489542116630d7f6f","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"24a7cdece9044b3ab9f8ed0c5435e66e","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"506f9c6c9c5f4d46863486cd7b268e84","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"a6eb47ceb33443379eb602f8f0a0af69","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"6b00242f015e4c0bac8ce987d28482c6","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"61d77a9f6bd947dca645abe9288563d3","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"8c9a4638083143ddbeccbb0bb0155933","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"a039df224d0f4440843116b46733a1ca","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"b6adf34104964ce6ab4e7c2abaf176ee","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"cad02a34dedc46d1becf5645ad944a7d","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"02e2f4ad0cbf40bd89ac1e103a027962","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"db2cd8cf96404447ac9df14ad8f43571","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"9b6dfa00cf4846c0b75d16ccd7db5914","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"6769a2b55e074874a742b298b8c53a07","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"b8d31ed972474bba825b901e4e78bcad","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"4b5e1ad5126d4d5ca1801f2f259078ed","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"0ce01a0b3ed54e5e8efc5903eff8bb58","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"0b3b5629b2384e2f809a0a9679b3d046","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"3a48e5e38fee482a89bc7aa52f3bef55","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"d07f9a23342b46eea36aa4e0fb9e6b9d","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"2ee8d5ae28e842979882867e46cba27d","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"d3876eafb7074240a341837f07126958","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"a9c5bbc7651142bcbb9765828f9b7cc7","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"32a8f20ee541494c9e6de138dd1de387","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"ff50f93a0fb94b33830ab07c67f7fc1e","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"b67623bc896843ce8d030b7fd70415fc","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"8784b009fcd64bb0abaf39063bdcdeee","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"996ee0cbfcc6409581c8074b211a99c9","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"72df29eca40f45839dc36687e8e8d9a5","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"1492988e871b4498a3b4b2ea2fbe490c","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"45bba1ec3f5e47f598adadc2c5bccb20","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"e97e3e7bceec4ebd84397cbef8407d09","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"123ee228defe4719a540294defc5ebc9","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"36ff040543ff4e0f9200068e00609e6e","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"7c5b2ba8c4b846ce8486f38371b9e445","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"61b7f85a022d4fbdb1aaf75b5733cac7","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"d3f7a206255544e98c4d088257f43075","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"f891e17f7eeb41f795f80a616b36a9cf","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"1ea76467513546968d0ac949833b3f50","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"0efc2f5bf4d945798f96978da85237b6","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"e299f648af5e45329f4958efb4250e86","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"affd8288baa64f84ab45b873d7923d67","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"7fd00b4a45444d958e05d838a0b17426","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"f7e37bc5d73445f99b13ee98335fff5f","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"451ba81597474f0b9d1c468828d81559","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"ea586e01e4874428978db696016f4d90","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"4a60b56a86f845afb40912e038cdaf12","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"983f184a0976482eafbe851524d4eee5","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"e7e50e95364246c2b6b462bd953dfbd5","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"e1970aec39874b6f9ed32a4df4010075","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"b4032437e8544da6bfe1c524f5624f74","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"63a3319ca8704eb7adb28095de22eeeb","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"1c52333be16548119897d881616e1bfe","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"1a77d9110d7e4e06bd4fa71b81c23fb0","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"aed00e68c92c411d9fadb1bebfd3c929","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"3cf5022d83064b2487d0705c11767b56","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"a20758254d594cb18131ec2c8424a1dc","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"ab430a6347ed47b2a9249c906f9b61ef","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"e27d73f9ddac46c18b2bc9b92b9bc885","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"c1a5c8e76ff64c229aa953a570231716","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"cbb5fbd884d842a4988e52c5a0825394","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"655c26d85ad64c379bb6f819b4f7f58c","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"82f013f603244bb29750b6668def3f6a","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"f50ef5ea06d94e358e5e5e0e37a62bcd","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"d46f3838b16741f9aecd938ae5406e37","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"4f410584cd56487db44b3f3556749422","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"b20ef02586fd415a9ebfa445544abeb0","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"1ca3b2089c76452780e1e8686ab61073","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"f57a3bf6443c4df9ad668463f0225dc0","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"d77d4af9a45344afaf1f28ac26cfaabf","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"04e6aa7f400b42ecacd909c7f1b38182","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"563611a6f72643919f6b332bf85fc3b6","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"9d62898d32d54e35b467d20b5390c880","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"5b5c2655d4bf4284891d5c2496cbecbd","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"b66b05103dc543b5acce7449db8cba6b","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"95717dab8f4b464da9ce6abd66e453b4","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"702427f3fd1b4ed49749f2519d937d76","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"b5efecc1c3614422aaf0e25e79c7fee8","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"a9a65194a76a4d13b17a6c19f95905c6","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"23747df6c8774425be7fa35f1470d72f","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"ad6a8cde4bf943a491fb3c04199e2257","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"53d644b7276f4d46b0c3e71dc7604d1e","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"ae6f9c0bb9ea4cf38fbef67a73f446c7","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"179748ffd8074a59875161a65c53fac9","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"c475a59e9ca0468d884c3a2b863d43d1","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"f19aa36227e04a769e7abf2fe43751e8","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"13b9d498b4ba4a05b0c5c32ea1ba3c88","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"0d787e7e1a214e10bb3fb5d9d4c8967a","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"e12d75568c3a45f697b23c561cd22c9b","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"96a43907845946938907b7e92d1d246e","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"427f8ab0d99445d3a49a82aee90e41ef","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"6dbe1bae741f4d4580d13396091123db","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"71653a27ffbc4ed8a5cdadfb69c0eeca","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"3669c79b2a4a4e0a880686f5cb9f6e0e","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"e7e0324d2cfb47908e334207b46e00c1","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"ba7f35f2456344edbecf79560a30ca05","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"1addb97a5958486089aecfe2e3679f6c","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"10e78184f775498ab358085590a320d3","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"d12e5d70ac7a44458d290f91eaa35c0b","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"06a64174f8c94444805cb3a32076ef46","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"0de005ec2aa94dd7a7ea75b2344035e7","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"39c71077d9c243ed926a6279b0e2d842","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"95cba8f9e5cc401fbce1750bc7b16e6a","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"7e3a9f7df7ee426bb7b43af71f28f065","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"cda2f7bc06ed4f4a8752a02322658f71","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"451286a8a3df493e8a74b90391ed18dd","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"97bf280d196d4a739ffbb7f8101ae610","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"7ee8f2ecf50a4dca81a5a2f89dbfd49a","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"70796adcf67c4a01b8e14cadfa847263","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"d89ea651c29649978647db7ef90b1d18","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"8ce1e5b71f8e446ba8ded15405cefe4a","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"46273803c48b4582b0b57b7cbe8ad680","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"846c7fc3635b42c68dbadd5aaa1cb57c","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"98a1714a1e77442bafdc8baf5b68c13c","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"2baec2549a5f42a6bc153b0c63f78529","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"3065461320bc4fd389dec2be4f8e0d83","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"4e77662bc67245d0bbbdf08b17730ba6","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"679a7a1fefc04e678334f511f82f15d5","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"d5eb15daf8074a3dbe7d8c783ec6f474","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"36d45f46dc3b48b49a4bb1dc3fb57c9c","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"5fac426304ce4ae7b1308719faff98de","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"30037e308eaf4eb0aa203827b8071572","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"cd2a3f38970c4584a15f19698b60ac70","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"9512e11b8e074773b5ed611d9b1f00d8","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"bf6e3751794248608ca99052455a861b","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"bee1eaf2eccd44c98004ccca5445f94a","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"c6b287ccdb88443ca752898565cb515d","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"ac487c89d02a4c15af4094cef2d29b62","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"277b90b2a1074a3caa1ee082891351cf","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"efea887d7bf243daa6c7478a677fc885","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"b376e10b13b2420b8920c28df109af58","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"e6939cfa022042a090ec74e2d9be21fe","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"81c32b79a68e4e39a5f084608d2aef13","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"f7d62a9d270342b9bf87984daabe64eb","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"b9165ddfdda5413b9b9097717eb234bc","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"41613638b15143f990d44af680adc5aa","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"06852526222246e992af0807be306013","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"63357bb9b19247c0b0a5e673a28530ed","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"eafd3b68a72e453098c166c41a350968","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"48a6d930f01d4647bb7c0c46078153f6","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"a470d9c6b6f44a219ae41a67d5470beb","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"9929eef0653f40c1b8d24e42d93e2aad","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"c81f97c44f584074bbba657ab8c97d3b","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"dbee544277534ca8a4f44f3b753ff9ff","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"63108b44080b439bbdfc8637891baa46","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"272e299b7d5040eca56732343ea3a422","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"f4ad4f65d25548c69fec6a450d182352","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"0a76d6a068dd4570a162b3f08393b21a","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"8fb2c2fb69e8477596c7b661514412e6","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"97a6ec0d5e0f47beb7d838c67f65a9c7","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"2e6bf593c15e42a8b84f09ff9e4fb2d2","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"9f8bd9be4919444794b36bd259e7936f","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"2aa936aa5b4f445a8b85809cef309ea1","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"ae8b53fbc1ab4e7cab9a741e5bd2b8da","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"501239064a41443893f00e7757c1dcd7","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"587cde5310374202b7079f47485de637","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"37a636bc5a7847b9a02e56ccd41577d2","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"1a9252e00d6e4ae98bb1efbe6558e195","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"242278557e0e4cfa8c46571023855078","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"e6c80fe3eeaa43cf8c384966c2aa37a9","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"ac563d797bfe4024b6ee2ec6afd42292","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"e9bfb373ebe84de2bd157eb0ce6f6ad7","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"8ecf956afcc74bef8493fdc723b4c752","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"6f078c188e2e4790a8b3ad7ac3716b61","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Saved checkpoint to data/mujoco/halfcheetah/expert-v0/</code></pre>
</div>
</div>
</section>
</section>
</section>
<section id="future-work" class="level2" data-number="13">
<h2 data-number="13" class="anchored" data-anchor-id="future-work"><span class="header-section-number">13</span> <strong>Future Work</strong></h2>
<section id="expand-to-more-environments" class="level3" data-number="13.1">
<h3 data-number="13.1" class="anchored" data-anchor-id="expand-to-more-environments"><span class="header-section-number">13.1</span> <strong>Expand to More Environments</strong></h3>
<ul>
<li>Test TT on diverse RL tasks: locomotion (Walker2D, Humanoid), navigation (AntMaze), and robotics (FrankaKitchen), environments with visual inputs.</li>
</ul>
</section>
<section id="speed-up-rollouts" class="level3" data-number="13.2">
<h3 data-number="13.2" class="anchored" data-anchor-id="speed-up-rollouts"><span class="header-section-number">13.2</span> <strong>Speed Up Rollouts</strong></h3>
<ul>
<li>Optimize inference using:<br>
<strong>Parallel token sampling</strong> to reduce autoregressive overhead.<br>
<strong>Efficient beam search</strong> with pruning or heuristics.<br>
<strong>CUDA/TensorRT acceleration</strong> for faster execution.</li>
</ul>
</section>
<section id="improve-training-efficiency" class="level3" data-number="13.3">
<h3 data-number="13.3" class="anchored" data-anchor-id="improve-training-efficiency"><span class="header-section-number">13.3</span> <strong>Improve Training Efficiency</strong></h3>
<ul>
<li>Reduce training time using:<br>
<strong>Gradient checkpointing</strong> for memory efficiency.<br>
<strong>Flash Attention</strong> for optimized transformer computations.<br>
<strong>Mixed-precision (FP16)</strong> for faster execution.<br>
<strong>Better discretization</strong> to improve tokenization.</li>
</ul>
</section>
<section id="enable-visualization" class="level3" data-number="13.4">
<h3 data-number="13.4" class="anchored" data-anchor-id="enable-visualization"><span class="header-section-number">13.4</span> <strong>Enable Visualization</strong></h3>
<ul>
<li>Implement <code>env.render()</code> to visualize rollouts.<br>
</li>
<li>Generate trajectory videos to analyze model behavior.</li>
</ul>
</section>
<section id="benchmark-against-other-rl-methods" class="level3" data-number="13.5">
<h3 data-number="13.5" class="anchored" data-anchor-id="benchmark-against-other-rl-methods"><span class="header-section-number">13.5</span> <strong>Benchmark Against Other RL Methods</strong></h3>
<ul>
<li>Compare TT with:<br>
<strong>Decision Transformer (DT)</strong> – Sequence modeling baseline.<br>
<strong>CQL</strong> – Offline RL with conservative action selection. <strong>TD3+BC</strong> – Hybrid RL with behavioral cloning.</li>
</ul>
</section>
<section id="other-learning-techniques" class="level3" data-number="13.6">
<h3 data-number="13.6" class="anchored" data-anchor-id="other-learning-techniques"><span class="header-section-number">13.6</span> Other learning techniques</h3>
<ul>
<li>Goal conditioned</li>
<li>Imitation learning</li>
</ul>
<p>If you are interested in contributing or collaborating on any of these, please open a issue on <a href="https://github.com/abrarsheikh/blog">the github project</a>.</p>



</section>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp("https:\/\/www\.abrarsheikh\.dev");
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->




</body></html>